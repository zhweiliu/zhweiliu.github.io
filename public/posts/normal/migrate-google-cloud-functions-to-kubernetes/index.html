<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Migrate Google Cloud Functions to Kubernetes | ZhengWei Liu's blogs</title><meta name=keywords content="Google Cloud Platform,GCP,ETL Pipeline"><meta name=description content="在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。
在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求
靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄
用 Kubernetes Pod 替代 Cloud Function 環節以處理動態資料源的方法 Google Kubernetes Engine: Ingress & Service ASGI 與FastAPI Dockerize & Deployment 靜態資料源的處理方案 > Migrate Google Cloud Functions to Airflow
Design Change Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)"><meta name=author content="ZhengWei, Liu"><link rel=canonical href=https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.63521e69c4b617677029c36f8d313102e7b332fb1e281f8e0c4744b93deaeba1.js integrity="sha256-Y1IeacS2F2dwKcNvjTExAuezMvseKB+ODEdEuT3q66E=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://blog.zhengweiliu.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://blog.zhengweiliu.com/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://blog.zhengweiliu.com/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://blog.zhengweiliu.com/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://blog.zhengweiliu.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Migrate Google Cloud Functions to Kubernetes"><meta property="og:description" content="在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。
在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求
靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄
用 Kubernetes Pod 替代 Cloud Function 環節以處理動態資料源的方法 Google Kubernetes Engine: Ingress & Service ASGI 與FastAPI Dockerize & Deployment 靜態資料源的處理方案 > Migrate Google Cloud Functions to Airflow
Design Change Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/"><meta property="og:image" content="https://blog.zhengweiliu.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-01-23T05:59:52+00:00"><meta property="article:modified_time" content="2022-01-23T05:59:52+00:00"><meta property="og:site_name" content="ZhengWei Liu's blogs"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.zhengweiliu.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Migrate Google Cloud Functions to Kubernetes"><meta name=twitter:description content="在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。
在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求
靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄
用 Kubernetes Pod 替代 Cloud Function 環節以處理動態資料源的方法 Google Kubernetes Engine: Ingress & Service ASGI 與FastAPI Dockerize & Deployment 靜態資料源的處理方案 > Migrate Google Cloud Functions to Airflow
Design Change Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.zhengweiliu.com/posts/"},{"@type":"ListItem","position":2,"name":"Migrate Google Cloud Functions to Kubernetes","item":"https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Migrate Google Cloud Functions to Kubernetes","name":"Migrate Google Cloud Functions to Kubernetes","description":"在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。\n在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求\n靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄\n用 Kubernetes Pod 替代 Cloud Function 環節以處理動態資料源的方法 Google Kubernetes Engine: Ingress \u0026amp; Service ASGI 與FastAPI Dockerize \u0026amp; Deployment 靜態資料源的處理方案 \u0026gt; Migrate Google Cloud Functions to Airflow\nDesign Change Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)","keywords":["Google Cloud Platform","GCP","ETL Pipeline"],"articleBody":"在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。\n在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求\n靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄\n用 Kubernetes Pod 替代 Cloud Function 環節以處理動態資料源的方法 Google Kubernetes Engine: Ingress \u0026 Service ASGI 與FastAPI Dockerize \u0026 Deployment 靜態資料源的處理方案 \u003e Migrate Google Cloud Functions to Airflow\nDesign Change Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)\nProcess 的區塊中，若需要向外部資料源提出存取請求，如: 3rd-party API 、爬蟲、網路磁碟機等，獲取相關的資訊後才能繼續進行處理的工作，在本篇文章中則以動態資料源來稱呼這些外部資料源\n對於 Runtime 時可能遭遇錯誤的資料源，可能遇到請求被拒絕(Reject)，如: 403、404或者5系列的錯誤代碼，或是遇到請求的資源本身不存在。\nGoogle Kubernetes Engine: Ingress \u0026 Service Figure 2 使用 Kubernetes Pod 替代 Cloud Function ， 因團隊先前已採用 Google Kubernetes Engine (GKE) 進行容器化的部署，這邊也就延續團隊成果。\n我也將 Pub/Sub 的模式從 trigger 更改為 Push Message : 當 Pub/Sub Subscriber Queue 存在訊息時， Subscriber 會推送 Message 到設定好的 Webhook URL，並且遵循 Ack 等待時間有著最長 600 秒的限制。\n關於 Deployment 的部分會在稍後提到，這邊先討論 Ingress 和 Service 的設置\nService Type: NodePort\napiVersion: v1kind: Servicemetadata: name: my-servicespec: type: NodePort selector: app: MyApp ports: # By default and for convenience, the `targetPort` is set to the same value as the `port` field. - port: 80 targetPort: 80 # Optional field # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767) nodePort: 30080 Ingress\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\nname: ingress-service-backend\nannotations:\ningress.gcp.kubernetes.io/pre-shared-cert: “k8s-example-com”\nkubernetes.io/ingress.allow-http: “false”\nkubernetes.io/ingress.global-static-ip-name: k8s-example-com\nspec:\ndefaultBackend:\nservice:\nname: my-services\nport:\nnumber: 80\nrules:\n- host: k8s.example.com\nhttp:\npaths:\n- path: /my-service\npathType: Prefix\nbackend:\nservice:\nname: my-service\nport:\nnumber: 80\n這樣便能將 Ingress 和 Service 設置完成，Ingress 和 Service 需要在同一個 namespace 。\nASGI \u0026 FastAPI 考量到團隊開發大部份依賴 Python framework，因此在替代 Cloud Function HTTP Server 的選擇上，最後我採用了基於 ASGI (Asynchronous Server Gateway Interface) 的 FastAPI ，以應付團隊中除了 Pub/Sub 之外的需求。\n對於 WSGI 和 ASGI 的比較，我覺得這篇博客 WSGI与ASGI的区别与联系 說的很清楚，推薦大家可以看一下。\nFastAPI 的文件中也詳細提供了製作 Container Image 的方法，同時也提到了關於部署在 Kubernetes 上的注意事項，有一份詳細、容易使用的官方文件，也是我選擇 FastAPI 的原因之一，並且 FastAPI 也內建了 Swagger UI 和 ReDoc 兩種文件模式，這也是一個加分大項。\nDockerize \u0026 Deployment Dockerfile\n依據 FastAPI 文件提供 Dockerfile 撰寫即可，需注意在 uvicorn 的 command加上 --proxy-headers 。\nFROM python:3.8\nWORKDIR /\nCOPY ./requirements.txt /requirements.txt\nRUN pip install –no-cache-dir –upgrade -r /requirements.txt\nCOPY ./ /\nCMD [“uvicorn”, “main:app”, “–proxy-headers”, “–host”, “0.0.0.0”, “–port”, “80”]\n依需求更改 Dockerfile 時需要注意 Docker Build Cache，由於 Docker Build Image 時會一層一層的往上迭代(每一行指令就是一層)， 而每一次 Build Image 都會檢查與上一次的差異，並從影響差異的 最低層 重新迭代，如: 當 requirements.txt 內容有所變更時，即便 source code 沒有改變，該次的 Docker Build 也會從 COPY ./requirements.txt /requirements.txt` 開始從新迭代。\nMain.py\n在 main.py 提供 domain host 之後的完整 URL path ，讓 app 的 route 可以找到對應的端口，並提供 /my-service/health 給 Load Balancer 進行 health check。\nfrom typing import Optional, Dict\nfrom fastapi import (FastAPI, status)\nfrom fastapi.encoders import jsonable_encoder\nfrom pydantic import BaseModel\nclass Message(BaseModel):\nattrs: Optional[Dict] = None\ndata: str\nmessage_id: str\npublish_time: str\nclass PubSubMessage(BaseModel):\nmessage: Message\nsubscription: str\napp = FastAPI()\n@app.get('/', status_code=status.HTTP_200_OK)\ndef home():\npass\n@app.get('/my-service/health', status_code=status.HTTP_200_OK)\ndef health():\npass\n@app.post('/my-service/subscriber-webhook', status_code=status.HTTP_200_OK)\ndef subscriber_webhook(message: PubSubMessage):\nmessage_data: Dict = jsonable_encoder(message)\nreturn message_data\nDeployment\n依據 Kubertenes 官方提供的模板撰寫，再依需求進行更改即可。\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: subscriber-webhook-deployment\nlabels:\napp: subscriber-webhook\nspec:\nreplicas: 3\nselector:\nmatchLabels:\napp: subscriber-webhook\ntemplate:\nmetadata:\nlabels:\napp: subscriber-webhook\nspec:\ncontainers:\n- name: subscriber-webhook\nimage: {REPLACE_YOUR_REGISTRY}/subscriber-webhook:1.0\nports:\n- containerPort: 80\n可視需要加入 [readinessProbe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe) 或 [livenessProbe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe)\n如果有 Autoscaling 的需求，參考 Horizontal Pod Autoscaling (HPA) 與 範例 修改即可。\n","wordCount":"509","inLanguage":"en","datePublished":"2022-01-23T05:59:52.712Z","dateModified":"2022-01-23T05:59:52.712Z","author":{"@type":"Person","name":"ZhengWei, Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/"},"publisher":{"@type":"Organization","name":"ZhengWei Liu's blogs","logo":{"@type":"ImageObject","url":"https://blog.zhengweiliu.com/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.zhengweiliu.com/ accesskey=h title="Posts (Alt + H)"><img src=https://blog.zhengweiliu.com/apple-touch-icon.png alt aria-label=logo height=35>Posts</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.zhengweiliu.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.zhengweiliu.com/categories/ title=Categories><span>Categories</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.zhengweiliu.com/>Home</a>&nbsp;»&nbsp;<a href=https://blog.zhengweiliu.com/posts/>Posts</a></div><h1 class=post-title>Migrate Google Cloud Functions to Kubernetes</h1><div class=post-meta><span title='2022-01-23 05:59:52.712 +0000 UTC'>January 23, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;509 words&nbsp;·&nbsp;ZhengWei, Liu&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>在 <a href="https://medium.com/@zhweiliu/gcp-billing-analytics-b1d1edf6ad38?source=your_stories_page----------------------------------------">GCP Billing Analytics</a> 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。</p><p>在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 <a href=https://cloud.google.com/pubsub/docs/subscriber#push_pull>Pub/Sub subscriber push/pull</a> 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求</p><ol><li><code>靜態資料源</code>: 在提取資料時，可預期資料是存在且可被存取的</li><li><code>動態資料源</code>: 可能發生資料不存在，或者是無法存取的情況</li></ol><p>本篇文章是記錄</p><ul><li><a href=#1234>用 <code>Kubernetes Pod</code> 替代 <code>Cloud Function</code> 環節以處理<code>動態資料源</code>的方法</a></li><li><a href=#dee1><code>Google Kubernetes Engine: Ingress & Service</code></a></li><li><a href=#fa5e><code>ASGI 與FastAPI</code></a></li><li><a href=#b458><code>Dockerize & Deployment</code></a></li></ul><p><code>靜態資料源</code>的處理方案 > <a href="https://medium.com/@zhweiliu/migrate-google-cloud-functions-to-airflow-bde12ffec8df?source=your_stories_page----------------------------------------"><code>Migrate Google Cloud Functions to Airflow</code></a></p><h3 id=design-change><code>Design Change</code><a hidden class=anchor aria-hidden=true href=#design-change>#</a></h3><p><img loading=lazy src=/images/normal/migrate-google-cloud-functions-to-kubernetes/image_0.png alt>
Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)</p><p>Process 的區塊中，若需要向外部資料源提出存取請求，如: 3rd-party API 、爬蟲、網路磁碟機等，獲取相關的資訊後才能繼續進行處理的工作，在本篇文章中則以<code>動態資料源</code>來稱呼這些外部資料源</p><blockquote><p>對於 Runtime 時可能遭遇錯誤的資料源，可能遇到請求被拒絕(Reject)，如: 403、404或者5系列的錯誤代碼，或是遇到請求的資源本身不存在。</p></blockquote><h3 id=google-kubernetes-engine-ingress-service>Google Kubernetes Engine: Ingress & Service<a hidden class=anchor aria-hidden=true href=#google-kubernetes-engine-ingress-service>#</a></h3><p><img loading=lazy src=/images/normal/migrate-google-cloud-functions-to-kubernetes/image_1.png alt>
Figure 2 使用 Kubernetes Pod 替代 Cloud Function ， 因團隊先前已採用 Google Kubernetes Engine (GKE) 進行容器化的部署，這邊也就延續團隊成果。</p><p>我也將 Pub/Sub 的模式從 trigger 更改為 <a href=https://cloud.google.com/pubsub/docs/push>Push Message</a> : 當 Pub/Sub Subscriber Queue 存在訊息時， Subscriber 會推送 Message 到設定好的 Webhook URL，並且遵循 Ack 等待時間有著最長 600 秒的限制。</p><p>關於 Deployment 的部分會在稍後提到，這邊先討論 Ingress 和 Service 的設置</p><p>Service Type: <a href=https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport>NodePort</a></p><pre tabindex=0><code>apiVersion: v1kind: Servicemetadata:  name: my-servicespec:  type: NodePort  selector:    app: MyApp  ports:      # By default and for convenience, the `targetPort` is set to the same value as the `port` field.    - port: 80      targetPort: 80      # Optional field      # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)      nodePort: 30080
</code></pre><p><a href=https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules>Ingress</a></p><p><code>apiVersion</code>: networking.k8s.io/v1<br><code>kind</code>: Ingress<br><code>metadata</code>:<br><code>name</code>: ingress-service-backend<br><code>annotations</code>:<br>ingress.gcp.kubernetes.io/pre-shared-cert: &ldquo;k8s-example-com&rdquo;<br>kubernetes.io/ingress.allow-http: &ldquo;false&rdquo;<br>kubernetes.io/ingress.global-static-ip-name: k8s-example-com<br><code>spec</code>:<br><code>defaultBackend</code>:<br><code>service</code>:<br><code>name</code>: my-services<br><code>port</code>:<br><code>number</code>: 80<br><code>rules</code>:<br>- <code>host</code>: k8s.example.com<br><code>http</code>:<br><code>paths</code>:<br>- <code>path</code>: /my-service<br><code>pathType</code>: Prefix<br><code>backend</code>:<br><code>service</code>:<br><code>name</code>: my-service<br><code>port</code>:<br><code>number</code>: 80</p><p>這樣便能將 Ingress 和 Service 設置完成，Ingress 和 Service 需要在同一個 namespace 。</p><h3 id=asgi-fastapi>ASGI & FastAPI<a hidden class=anchor aria-hidden=true href=#asgi-fastapi>#</a></h3><p>考量到團隊開發大部份依賴 Python framework，因此在替代 Cloud Function HTTP Server 的選擇上，最後我採用了基於 ASGI (Asynchronous Server Gateway Interface) 的 <a href=https://fastapi.tiangolo.com/id/>FastAPI</a> ，以應付團隊中除了 Pub/Sub 之外的需求。</p><p>對於 WSGI 和 ASGI 的比較，我覺得這篇博客 <a href=https://blog.csdn.net/huayunhualuo/article/details/106007545>WSGI与ASGI的区别与联系</a> 說的很清楚，推薦大家可以看一下。</p><p>FastAPI 的文件中也詳細提供了<a href=https://fastapi.tiangolo.com/id/deployment/docker/#build-a-docker-image-for-fastapi>製作 Container Image</a> 的方法，同時也提到了關於<a href=https://fastapi.tiangolo.com/id/deployment/docker/#replication-number-of-processes>部署在 Kubernetes 上的注意事項</a>，有一份詳細、容易使用的官方文件，也是我選擇 FastAPI 的原因之一，並且 FastAPI 也內建了 <a href=https://fastapi.tiangolo.com/id/deployment/docker/#interactive-api-docs>Swagger UI</a> 和 <a href=https://fastapi.tiangolo.com/id/deployment/docker/#alternative-api-docs>ReDoc</a> 兩種文件模式，這也是一個加分大項。</p><h3 id=dockerize--deployment>Dockerize & Deployment<a hidden class=anchor aria-hidden=true href=#dockerize--deployment>#</a></h3><p><code>Dockerfile</code></p><p>依據 FastAPI 文件提供 <a href=https://fastapi.tiangolo.com/id/deployment/docker/#dockerfile>Dockerfile</a> 撰寫即可，需注意在 <code>uvicorn</code> 的 command加上 <code>--proxy-headers</code> 。</p><p><code>FROM</code> python:3.8</p><p><code>WORKDIR</code> /</p><p><code>COPY</code> ./requirements.txt /requirements.txt</p><p><code>RUN</code> pip install &ndash;no-cache-dir &ndash;upgrade -r /requirements.txt</p><p><code>COPY</code> ./ /</p><p><code>CMD</code> [&ldquo;uvicorn&rdquo;, &ldquo;main:app&rdquo;, &ldquo;&ndash;proxy-headers&rdquo;, &ldquo;&ndash;host&rdquo;, &ldquo;0.0.0.0&rdquo;, &ldquo;&ndash;port&rdquo;, &ldquo;80&rdquo;]</p><p>依需求更改 Dockerfile 時需要注意 Docker Build Cache，由於 Docker Build Image 時會一層一層的往上迭代(每一行指令就是一層)， 而每一次 Build Image 都會檢查與上一次的差異，並從影響差異的 <code>最低層</code> 重新迭代，如: 當 requirements.txt 內容有所變更時，即便 source code 沒有改變，該次的 Docker Build 也會從 <code>COPY</code> ./requirements.txt /requirements.txt` 開始從新迭代。</p><p><code>Main.py</code></p><p>在 main.py 提供 domain host 之後的完整 URL path ，讓 app 的 route 可以找到對應的端口，並提供 <code>/my-service/health</code> 給 Load Balancer 進行 health check。</p><p><code>from</code> typing <code>import</code> Optional, Dict<br><code>from</code> fastapi <code>import</code> (FastAPI, status)<br><code>from</code> fastapi.encoders <code>import</code> jsonable_encoder<br><code>from</code> pydantic import <code>BaseModel</code></p><p><code>class Message(BaseModel):</code><br><code>attrs</code>: Optional[Dict] = None<br><code>data</code>: str<br><code>message_id</code>: str<br><code>publish_time</code>: str</p><p><code>class PubSubMessage(BaseModel):</code><br><code>message</code>: Message<br><code>subscription</code>: str</p><p><code>app</code> = FastAPI()</p><p><a href=http://twitter.com/app title="Twitter profile for @app"><code>@app</code></a><code>.get('/', status_code=status.HTTP_200_OK)</code><br><code>def home</code>():<br>pass</p><p><a href=http://twitter.com/app title="Twitter profile for @app"><code>@app</code></a><code>.get('/my-service/health', status_code=status.HTTP_200_OK)</code><br><code>def health</code>():<br>pass</p><p><code>@app.post('/my-service/subscriber-webhook', status_code=status.HTTP_200_OK)</code><br><code>def subscriber_webhook</code>(<code>message</code>: <code>PubSubMessage</code>):<br><code>message_data</code>: Dict = jsonable_encoder(message)<br><code>return</code> message_data</p><p><code>Deployment</code></p><p>依據 <a href=https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment>Kubertenes 官方提供的模板</a>撰寫，再依需求進行更改即可。</p><p><code>apiVersion</code>: apps/v1<br><code>kind</code>: Deployment<br><code>metadata</code>:<br><code>name</code>: subscriber-webhook-deployment<br><code>labels</code>:<br><code>app</code>: subscriber-webhook<br><code>spec</code>:<br><code>replicas</code>: 3<br><code>selector</code>:<br><code>matchLabels</code>:<br><code>app</code>: subscriber-webhook<br><code>template</code>:<br><code>metadata</code>:<br><code>labels</code>:<br><code>app</code>: subscriber-webhook<br><code>spec</code>:<br><code>containers</code>:<br>- <code>name</code>: subscriber-webhook<br><code>image</code>: {REPLACE_YOUR_REGISTRY}/subscriber-webhook:1.0<br><code>ports</code>:<br>- <code>containerPort</code>: 80</p><p>可視需要加入 <code>[</code>readinessProbe<code>](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe)</code> <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe>或</a> <code>[</code>livenessProbe<code>](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-tcp-liveness-probe)</code></p><p>如果有 Autoscaling 的需求，參考 <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#default-behavior>Horizontal Pod Autoscaling (HPA)</a> 與 <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics>範例</a> 修改即可。</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://blog.zhengweiliu.com/posts/normal/customer-data-platform/><span class=title>« Prev</span><br><span>Customer Data Platform 是如何煉成的 (二)</span></a>
<a class=next href=https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-airflow/><span class=title>Next »</span><br><span>Migrate Google Cloud Functions to Airflow</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Migrate Google Cloud Functions to Kubernetes on twitter" href="https://twitter.com/intent/tweet/?text=Migrate%20Google%20Cloud%20Functions%20to%20Kubernetes&url=https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f&hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Migrate Google Cloud Functions to Kubernetes on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f&title=Migrate%20Google%20Cloud%20Functions%20to%20Kubernetes&summary=Migrate%20Google%20Cloud%20Functions%20to%20Kubernetes&source=https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Migrate Google Cloud Functions to Kubernetes on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f&title=Migrate%20Google%20Cloud%20Functions%20to%20Kubernetes"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Migrate Google Cloud Functions to Kubernetes on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Migrate Google Cloud Functions to Kubernetes on whatsapp" href="https://api.whatsapp.com/send?text=Migrate%20Google%20Cloud%20Functions%20to%20Kubernetes%20-%20https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Migrate Google Cloud Functions to Kubernetes on telegram" href="https://telegram.me/share/url?text=Migrate%20Google%20Cloud%20Functions%20to%20Kubernetes&url=https%3a%2f%2fblog.zhengweiliu.com%2fposts%2fnormal%2fmigrate-google-cloud-functions-to-kubernetes%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://blog.zhengweiliu.com/>ZhengWei Liu's blogs</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>