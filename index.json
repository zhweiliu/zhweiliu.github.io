[{"content":"é€™ç¯‡æ–‡ç« ä¸»è¦è¨˜éŒ„å€ŸåŠ© ChatGPT ä¾†ä¿®æ”¹å±¥æ­·çš„éç¨‹\nç”±æ–¼æ­£åœ¨å°‹æ‰¾æ–°çš„å·¥ä½œæ©Ÿæœƒï¼Œä½†è¦ºå¾—è‡ªå·±å¯¦åœ¨æ˜¯ä¸æ“…é•·æ’°å¯«å±¥æ­·ï¼Œä¾¿æƒ³å˜—è©¦è®“ ChatGPT å°æ–¼å·²å¯«å¥½çš„åˆç‰ˆå±¥æ­·æä¾›ä¿®æ”¹å»ºè­°ï¼› ä½†è½‰å¿µä¸€æƒ³ï¼Œä½•ä¸ä¹¾è„†è«‹ ChatGPT ç›´æ¥è¼¸å‡ºä¿®æ”¹å¥½çš„å…§å®¹ï¼Œæ–¼æ˜¯ä¾¿æœ‰äº†é€™æ¬¡å˜—è©¦ã€‚\nChatGPT ChatGPT æ˜¯ç”± OpenAI release çš„ä¸€å¥—å°è«‡å¼ AI Model (æ’°æ–‡ç•¶ä¸‹å·²è¢« Microsoft æ”¶è³¼)ï¼›ç”±æ–¼å°è«‡æºé€šçš„ç‰¹æ€§ï¼Œç›®å‰ä¹Ÿæœ‰è¨±å¤šåˆ©ç”¨ ChatGPT é€²è¡ŒäºŒæ¬¡é–‹ç™¼çš„æœå‹™èˆ‡ç”¢å“ï¼Œå¤šæ•¸æ˜¯åœ¨å„è¡Œæ¥­é ˜åŸŸä»¥æ“”ä»»åŠ©æ‰‹çš„è§’è‰²ï¼Œæä¾›ä½¿ç”¨è€…è«¸å¤šä¾¿åˆ©æ€§ã€‚\nåœ¨å¯¦éš›ä½¿ç”¨ ChatGPT çš„éç¨‹ï¼Œæˆ‘æ„Ÿè¦ºåˆ° ChatGPT æ‡‰è©²æ˜¯å…·å‚™çŸ­æœŸè¨˜æ†¶çš„ç‰¹æ€§ï¼Œè€ŒçŸ­æœŸè¨˜æ†¶åˆèƒ½å¤ è®“æˆ‘å€‘å»ºç«‹èµ·å’Œ ChatGPT çš„å…±è­˜ï¼Œä»¤ ChatGPT èƒ½å¤ æ˜ç™½ç•¶å‰å•é¡Œçš„èƒŒæ™¯ç’°å¢ƒèˆ‡å‡è¨­æ¢ä»¶ï¼Œä¿ƒä½¿ ChatGPT ç›¡å¯èƒ½çš„å›ç­”å‡ºç¬¦åˆç’°å¢ƒè¨­å®šçš„å›ç­”ã€‚\nèˆ‡ ChatGPT å»ºæ§‹å…±è­˜ æˆ‘è¦ºå¾—åœ¨éœ€è¦æºé€šä»¥åˆä½œè§£æ±ºå•é¡Œçš„æƒ…å¢ƒä¸‹ï¼Œæˆ‘å¿…é ˆå…ˆçŸ¥é“ ChatGPT æ˜¯å¦å·²å…·å‚™äº†æŸäº›åŸºç¤èƒ½åŠ›ï¼Œä»¥å¤ æ‡‰ä»˜æ¥ä¸‹ä¾†åˆä½œéç¨‹ä¸­æˆ‘æ‰€æå‡ºçš„éœ€æ±‚ï¼› å°æ­¤ï¼Œæˆ‘å° ChatGPT é€²è¡Œäº†ä»¥ä¸‹æ¸¬è©¦\næ˜¯å¦å…·å‚™ä¸Šå‚³æª”æ¡ˆåˆ° Google Driver çš„èƒ½åŠ› æ˜¯å¦å…·å‚™è¨ªå• Public Files URL çš„èƒ½åŠ› æª”æ¡ˆä¸Šå‚³æ¸¬è©¦ æˆ‘åœ¨è‡ªå·±çš„ Google Driver å»ºç«‹ä¸€å€‹å…±ç”¨æ–‡ä»¶å¤¾ï¼Œä¸¦è¨­å®šå…±ç”¨æ¬Šé™è®“çŸ¥é“é€£çµè€…å¯é€²è¡Œç·¨è¼¯ï¼Œå†å° ChatGPT æå‡ºå•é¡Œ ChatGPT ç›®å‰å°šæœªå…·å‚™ä¸Šå‚³æª”æ¡ˆçš„èƒ½åŠ›\nè¨ªå• Public Files URL æ¸¬è©¦ æˆ‘åœ¨å‰ä¸€å€‹æ¸¬è©¦ä¸­å»ºç«‹çš„å…¬ç”¨è³‡æ–™å¤¾ä¸­ä¸Šå‚³ä¸€å€‹ç°¡å–®çš„ç´”æ–‡å­—æª”æ¡ˆï¼Œæª”æ¡ˆå…§å®¹ç‚º Hello from ChatGPT! ï¼Œä¸¦å° ChatGPT æå• ChatGPT çš„è¼¸å‡ºä¸¦éæˆ‘æƒ³è¦çš„ï¼Œæ–¼æ˜¯ç¹¼çºŒå’Œ ChatGPT æºé€š ChatGPT æ­£ç¢ºè¨ªå•äº†æª”æ¡ˆé€£çµä¸¦è®€å‡ºå…§å®¹ï¼›\nåŒæ™‚ï¼Œ ChatGPT å‘Šè¨´æˆ‘ä»–é€éåŸ·è¡Œäº† Python script ä¾†ä¸‹è¼‰æª”æ¡ˆä»¥åŠè¼¸å‡ºå…§å®¹\nè®€å–å±¥æ­· æˆ‘äº‹å…ˆæº–å‚™å¥½ä¸€ä»½æ’°å¯«å®Œæˆçš„å±¥æ­·ï¼Œä¸¦å°‡å±¥æ­·è¨­å®šç‚ºå¯è¢«å…¬é–‹è¨ªå•ï¼Œä¸¦è«‹ ChatGPT è®€å–å±¥æ­·å¾Œç”¢ç”Ÿä¸€ä»½é©åˆæˆ‘çš„è‡ªå‚³ï¼› åŒæ™‚ï¼Œä¹Ÿå‘Šè¨´ ChatGPT ç›®å‰æˆ‘æƒ³å°‹æ‰¾çš„è·ç¼ºå„ªå…ˆé †åºç‚ºä½• åœ¨ ChatGPT ç”¢ç”Ÿçš„è‡ªå‚³ä¸­ï¼Œæœ‰ 80% æè¿°ç¬¦åˆæˆ‘çš„éå¾€ç¶“æ­·ã€‚\nè¿½åŠ æ¢ä»¶ä»¥ä¿®æ”¹å±¥æ­· æˆ‘é€²ä¸€æ­¥çš„è¿½åŠ ä¸€å€‹æ¢ä»¶\nå‡è¨­æ¯ä½ HR åªæœ‰ 30ç§’çš„æ™‚é–“ä¾†æŸ¥çœ‹ä¸€ä»½å±¥æ­· ä¸¦è«‹ ChatGPT ä¾æ“šæ¢ä»¶ï¼Œæå‡ºä¿®æ”¹å±¥æ­·çš„å»ºè­°ï¼Œä»¥åˆ©å¢åŠ å±¥æ­·çš„ç¨ç‰¹æ€§èˆ‡æ›å…‰åº¦\nç°¡ç•¥åˆ—å‡º ChatGPT æä¾›å¸å¼• HR ç›®å…‰çš„å»ºè­°\n1. çªé¡¯é—œéµå­— 2. çµæ§‹ç°¡æ½” 3. é‡é»çªå‡º 4. ç‰¹è‰²çªé¡¯ 5. å…·é«”æ•¸æ“š 6. ç°¡æ˜æ‰¼è¦ ä»¥åŠå°å±¥æ­·çš„ä¿®æ”¹å»ºè­°\n1. å¼·èª¿æˆæœ 2. æ›´å¥½çš„æ’ç‰ˆ 3. æ·»åŠ é—œéµå­— 4. çªå‡ºè‡ªå·±çš„æŠ€èƒ½ 5. æ›´æ–°ç°¡æ­·å…§å®¹ 6. è‡ªæˆ‘ä»‹ç´¹ èª¿æ•´è‡ªæˆ‘ä»‹ç´¹å’Œè‡ªå‚³ ä¾æ“š ChatGPT çš„å»ºè­°ï¼Œæˆ‘åˆ†åˆ¥æä¾›ç°¡å–®çš„è‡ªæˆ‘ä»‹ç´¹ã€è‡ªå‚³ä»¥åŠå·¥ä½œç¶“æ­·ï¼Œä¸¦è«‹ ChatGPT å”åŠ©ä¿®æ”¹ï¼Œä»¥ä¾¿æ›´åŠ ç¬¦åˆ HR æŸ¥çœ‹å±¥æ­·æ™‚è‘—é‡çš„é‡é»\nè‡ªæˆ‘ä»‹ç´¹ è‡ªå‚³ å·¥ä½œç¶“æ­· æˆ‘è¦ºå¾—åœ¨ ChatGPT ä¿®æ”¹éå¾Œï¼Œè®€èµ·ä¾†ç¢ºå¯¦é€šæš¢è¨±å¤šã€‚\nçµèª é€é ChatGPT è¼”åŠ©ä¿®æ”¹å±¥æ­·çš„éç¨‹ï¼Œæˆ‘è¦ºå¾—åœ¨å’Œ ChatGPT æºé€šçš„éç¨‹å…¶å¯¦æŒºé †æš¢çš„ï¼Œç°¡å–®æ‰¼è¦ä¸¦æ¸…æ¥šçš„å‘Šè¨´ ChatGPT ç•¶å‰é­é‡çš„å•é¡Œï¼Œä»¥åŠç›¸é—œçš„èƒŒæ™¯è¨­å®šèˆ‡å‡è¨­æ¢ä»¶ï¼Œé€šå¸¸éƒ½èƒ½ç²å¾—ä¸éŒ¯çš„çµæœã€‚\nå³ä½¿ç¬¬ä¸€æ¬¡è¼¸å‡ºçš„çµæœä¸¦ä¸ç¬¦åˆæˆ‘çš„æœŸå¾…ï¼Œåœ¨æ˜ç¢ºå‘ŠçŸ¥ ChatGPT å¾Œä¹Ÿèƒ½å¾—åˆ°è¼ƒç‚ºæ»¿æ„çš„çµæœã€‚\nè€Œå”¯ä¸€éœ€è¦æ³¨æ„çš„ä¸€é»ï¼Œæ˜¯ ChatGPT å‘Šè¨´æˆ‘ä»–æœƒåŸ·è¡Œä¸‹è¼‰æª”æ¡ˆçš„è¡Œç‚ºï¼Œä»¥ä¾¿è®€å–æª”æ¡ˆå…§å®¹ï¼›æœªä¾†è‹¥æœ‰ç›¸ä¼¼éœ€è¦ ChatGPT çš„å”åŠ©ï¼Œå‰‡æ‡‰è©²æ›´åŠ æ³¨æ„æ˜¯å¦å·²é¿é–‹æä¾›æ©Ÿæ•æ€§çš„è³‡æ–™ã€‚\n","permalink":"https://blog.zhengweiliu.com/posts/chatgpt/resume/","summary":"\u003cp\u003eé€é ChatGPT è¼”åŠ©ä¿®æ”¹å±¥æ­·çš„éç¨‹ï¼Œæˆ‘è¦ºå¾—åœ¨å’Œ ChatGPT æºé€šçš„éç¨‹å…¶å¯¦æŒºé †æš¢çš„ï¼Œç°¡å–®æ‰¼è¦ä¸¦æ¸…æ¥šçš„å‘Šè¨´ ChatGPT ç•¶å‰é­é‡çš„å•é¡Œï¼Œä»¥åŠç›¸é—œçš„èƒŒæ™¯è¨­å®šèˆ‡å‡è¨­æ¢ä»¶ï¼Œé€šå¸¸éƒ½èƒ½ç²å¾—ä¸éŒ¯çš„çµæœã€‚\u003c/p\u003e\n\u003cp\u003eå³ä½¿ç¬¬ä¸€æ¬¡è¼¸å‡ºçš„çµæœä¸¦ä¸ç¬¦åˆæˆ‘çš„æœŸå¾…ï¼Œåœ¨æ˜ç¢ºå‘ŠçŸ¥ ChatGPT å¾Œä¹Ÿèƒ½å¾—åˆ°è¼ƒç‚ºæ»¿æ„çš„çµæœã€‚\u003c/p\u003e\n\u003cp\u003eè€Œå”¯ä¸€éœ€è¦æ³¨æ„çš„ä¸€é»ï¼Œæ˜¯ ChatGPT å‘Šè¨´æˆ‘ä»–æœƒåŸ·è¡Œä¸‹è¼‰æª”æ¡ˆçš„è¡Œç‚ºï¼Œä»¥ä¾¿è®€å–æª”æ¡ˆå…§å®¹ï¼›æœªä¾†è‹¥æœ‰ç›¸ä¼¼éœ€è¦ ChatGPT çš„å”åŠ©ï¼Œå‰‡æ‡‰è©²æ›´åŠ æ³¨æ„æ˜¯å¦å·²é¿é–‹æä¾›æ©Ÿæ•æ€§çš„è³‡æ–™ã€‚\u003c/p\u003e\n","title":"å€ŸåŠ© ChatGPT ä¿®æ”¹å±¥æ­·"},{"content":"é€™ç¯‡æ–‡ç« æ•´ç†äº†å€‹äººä½¿ç”¨ PaperMod theme çš„è¨­å®š\nWhat is Hugo-PaperMod ? Hugo PaperMod is a theme based on hugo-paper. The goal of this project is to add more features and customization to the og theme.\nHugo-PaperMod ä½¿ç”¨ yml/yaml æ ¼å¼æä¾›æ‰€æœ‰ç¤ºä¾‹ï¼Œä½œè€…èªç‚º yaml çš„æ ¼å¼æœƒæ¯” toml å®¹æ˜“é–±è®€ã€‚\nå®‰è£æ–¹å¼ Hugo å®˜æ–¹å»ºè­°æ¡ç”¨ submodule çš„æ–¹å¼ä¾†å®‰è£ hugo themesï¼› ä½¿ç”¨ submodule ä¾†å®‰è£ Hugo-PaperMod theme\ngit submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) è‹¥è¦æ›´æ–° Hugo-PaperMod theme :\ngit submodule update --remote --merge Hugo-PaperMod ä¹Ÿæä¾›åŸºæœ¬çš„ config.yml å’Œ page.md\nFeatures Features è¨­ç½®åƒè€ƒä¾†æº æ¶ç«™â•‘ Hugoéƒ¨è½æ ¼èˆ‡PaperModä¸»é¡Œ\nå»ºç«‹ Archive åˆ©ç”¨æŒ‡ä»¤åœ¨ content ä¸‹å»ºç«‹ archive.md\nhugo new content/archive.md ç·¨è¼¯ archive.md å…§å®¹\n--- title: \u0026#34;Archive\u0026#34; layout: \u0026#34;archives\u0026#34; url: \u0026#34;/archives/\u0026#34; summary: archives --- åœ¨ config.yml çš„ menu å€å¡Šè¨­ç½® archive æŒ‰éˆ•\nmenu: main: - identifier: archives name: ğŸ“š Archives url: /archives/ weight: 10 å»ºç«‹ Search Page åœ¨ config.yml åŠ å…¥ä»¥ä¸‹è¨­å®š\noutputs: home: - HTML - RSS - JSON # is necessary åˆ©ç”¨æŒ‡ä»¤åœ¨ content ä¸‹å»ºç«‹ search.md\nhugo new content/search.md ç·¨è¼¯ search.md å…§å®¹\n--- title: \u0026#34;Search\u0026#34; # in any language you want layout: \u0026#34;search\u0026#34; # is necessary url: \u0026#34;/search/\u0026#34; # description: \u0026#34;Description for Search\u0026#34; summary: \u0026#34;search\u0026#34; placeholder: \u0026#34;placeholder text in search input box\u0026#34; --- å°æ–¼ä¸å¸Œæœ›è¢« search page æœå°‹åˆ°çš„æ–‡ç« ï¼Œå¯ä»¥åœ¨æ–‡ç« é–‹é ­çš„ archtype åŠ å…¥ä»¥ä¸‹è¨­å®š\nsearchHidden: true Setup Post Keywords åœ¨æ–‡ç« é–‹é ­çš„ archtype åŠ å…¥ä»¥ä¸‹è¨­å®š\nkeywords: [\u0026#34;keyword 1\u0026#34;, \u0026#34;keyword 2\u0026#34;, ...] Customizing Fusejs Options PaperMod é¸ç”¨ Fusejs ä½œç‚º search å…ƒä»¶ï¼Œåƒè€ƒFusejs åƒæ•¸é …ä¾†è‡ªå®šç¾© search page åŠŸèƒ½ï¼Œå¦‚\nparams: fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#34;title\u0026#34;, \u0026#34;permalink\u0026#34;, \u0026#34;summary\u0026#34;, \u0026#34;content\u0026#34;] Code Block è¨­å®š max-height åœ¨ assets/css/common/post-single.css æ·»åŠ ä¸‹é¢å…§å®¹\n.post-content pre code { max-height: 30em; } Shortcode Shortcode å¯ä»¥çœ‹ä½œæ˜¯ã€Œä¸€å°å¡Š HTML ç¨‹å¼ç‰‡æ®µã€ï¼Œèˆ‡ Hugo Template ä¸åŒçš„æ˜¯ï¼Œå‰è€…é€šå¸¸é‹ç”¨åœ¨ã€Œæ’å…¥ç‰¹å®šç”¨é€”ã€ã€ã€Œé‡è¤‡ä½¿ç”¨ã€çš„ç‰‡æ®µèªæ³•åˆ° markdown å…§å®¹ä¸­ï¼Œè€Œå¾Œè€…å‰‡æ˜¯ä½œç‚º markdown content çš„å¤–æ®¼è¼‰é«”ã€æˆ–æ˜¯ä½ˆå±€è¦åŠƒç­‰ï¼Œç”¨ä»¥æ§‹æˆæˆ‘å€‘æœ€å¾Œå‘ˆç¾çš„è¦–åœ–é é¢ (View)ã€‚ â€” ä¾†æº:iTé‚¦\næ›´è©³ç´°çš„ shortcode è¨­å®šç¯„ä¾‹å¯ä»¥åƒè€ƒ Day 22. Hugo Shortcode ä»‹ç´¹ å’Œ Hugoåšå®¢è‡ªå®šä¹‰shortcodes\nä»¥ä¸‹åƒ…æ•´ç†æˆ‘ç›®å‰æœ‰ä½¿ç”¨çš„\nPDP Shortcode åœ¨ layouts/shortcodes/ ç›®éŒ„ä¸‹å»ºç«‹ä¸€å€‹æ–°æ–‡ä»¶ pdf.htmlï¼Œè²¼ä¸Šä¸‹åˆ—å…§å®¹\n\u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; #googleslides_shortcodes { padding-bottom: 66%; position: relative; display: block; width: 100%; border-bottom: 5px solid; } #googleslides_shortcodes iframe { position: absolute; top: 0; left: 0 } \u0026lt;/style\u0026gt; \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;googleslides_shortcodes\u0026#34;\u0026gt; \u0026lt;iframe id=\u0026#34;googleSlideIframe\u0026#34; width=\u0026#34;100%\u0026#34; height=\u0026#34;100%\u0026#34; src=\u0026#34;{{ .Get \u0026#34;src\u0026#34; }}\u0026#34; frameborder=\u0026#34;0\u0026#34; allowfullscreen=\u0026#34;\u0026#34; \u0026gt; \u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ä½¿ç”¨æ–¹å¼\n{a{\u0026lt;pdf src=\u0026#34;pdfç¶²å€ | ç«™å…§ pdf ä½å€\u0026#34;\u0026gt;}} # ä½¿ç”¨çš„æ™‚å€™æŠŠå­—æ¯ a å»æ‰ï¼›é€™é‚ŠåŠ å…¥ a æ˜¯é˜²æ­¢è¢«è­˜åˆ¥ç”Ÿæ•ˆ # æŠŠ pdf file æ”¾åœ¨ static/{ç›®éŒ„å}/ ä¸‹ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ /{ç›®éŒ„å}/{æª”æ¡ˆå}.pdf æŒ‡å®šä½¿ç”¨ç«™å…§ pdf \u003c!DOCTYPE HTML\u003e Youtube Shortcode åœ¨ layouts/shortcodes/ ç›®éŒ„ä¸‹å»ºç«‹ä¸€å€‹æ–°æ–‡ä»¶ youtube.htmlï¼Œè²¼ä¸Šä¸‹åˆ—å…§å®¹\n\u0026lt;!DOCTYPE HTML\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; .youtube_shortcodes { position: relative; width: 100%; height: 0; padding-bottom: 66%; margin: auto; overflow: hidden; text-align: center; } .youtube_shortcodes iframe { position: absolute; width: 100%; height: 100%; left: 0; top: 0; } \u0026lt;/style\u0026gt; \u0026lt;title\u0026gt;\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;youtube_shortcodes\u0026#34;\u0026gt; \u0026lt;iframe class=\u0026#34;youtube-player\u0026#34; type=\u0026#34;text/html\u0026#34; width=\u0026#34;640\u0026#34; height=\u0026#34;385\u0026#34; src=\u0026#34;https://www.youtube.com/embed/{{ index .Params 0 }}?autoplay=0\u0026#34; style=\u0026#34; position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\u0026#34; allowfullscreen frameborder=\u0026#34;0\u0026#34;\u0026gt; \u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ä½¿ç”¨æ–¹å¼\n{a{\u0026lt;youtube _XbJhL7WsE8\u0026gt;}} # ä½¿ç”¨çš„æ™‚å€™æŠŠå­—æ¯ a å»æ‰ï¼›é€™é‚ŠåŠ å…¥ a æ˜¯é˜²æ­¢è¢«è­˜åˆ¥ç”Ÿæ•ˆ # _XbJhL7WsE8 æ˜¯ Youtube åˆ†äº«éˆçµä¸­çš„æœ€å¾Œä¸€æ®µè­˜åˆ¥ç¢¼ \u003c!DOCTYPE HTML\u003e Blog ç«™å…§æ–‡ç«  åœ¨ layouts/shortcodes/ ç›®éŒ„ä¸‹å»ºç«‹ä¸€å€‹æ–°æ–‡ä»¶ innerlink.htmlï¼Œè²¼ä¸Šä¸‹åˆ—å…§å®¹\n\u0026lt;div style=\u0026#34;height: 200px;margin: 1em auto;position: relative; box-shadow: 0 2px 4px rgb(0 0 0 / 25%), 0 0 2px rgb(0 0 0 / 25%); border-radius: 15px;padding: 23px;max-width: 780px;background: var(--entry);\u0026#34;\u0026gt; {{ $url := .Get \u0026#34;src\u0026#34; }} {{ with .Site.GetPage $url }} \u0026lt;div style=\u0026#34;font-size: 22px; font-weight: 600\u0026#34;\u0026gt; \u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;{{ .Permalink }}\u0026#34; style=\u0026#34;box-shadow: none\u0026#34;\u0026gt;{{ .Title }}\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;span style=\u0026#34;font-size: 14px; color: #999\u0026#34;\u0026gt; Date: {{ .Date.Format ( default \u0026#34;2006-01-02\u0026#34;) }} {{ if .Params.categories }}\u0026amp;nbsp; Categories: {{ range .Params.categories }} #{{ . }}\u0026amp;nbsp; {{ end }} \u0026lt;/span\u0026gt; \u0026lt;div style=\u0026#34;font-size: 14px; line-height: 1.825;max-height: 75px; overflow: hidden;margin-top: 5px;\u0026#34;\u0026gt; {{ .Summary | plainify}} ...... \u0026lt;/div\u0026gt; {{ end }} {{ end }} \u0026lt;/div\u0026gt; ä½¿ç”¨æ–¹å¼\n{a{\u0026lt;innerlink src=\u0026#34;posts/hugo/installation.md\u0026#34;\u0026gt;}} # ä½¿ç”¨çš„æ™‚å€™æŠŠå­—æ¯ a å»æ‰ï¼›é€™é‚ŠåŠ å…¥ a æ˜¯é˜²æ­¢è¢«è­˜åˆ¥ç”Ÿæ•ˆ # ç›´æ¥æŒ‡å®š content/posts/ ä¸‹çš„æ–‡ç« è·¯å¾‘ï¼Œçµå°¾è¦åŠ ä¸Š .md æª”å # å¡ç‰‡ç²å–çš„æ˜¯æ–‡ç« çš„ summary å…§å®¹ï¼Œé»˜èªé•·åº¦æ˜¯ 70 å€‹ä¸­æ–‡å­— Hugo å®‰è£èˆ‡éƒ¨ç½²åˆ° GitHub Pages ( Mac M2 ) Date: 2023-01-05 \u0026nbsp; Categories: #Hugo\u0026nbsp; é€™ç¯‡æ–‡ç« ä¸»è¦æä¾›åœ¨ Mac M2 ä¸Šå®‰è£ Hugo ã€åŸ·è¡Œä¸€å€‹ quick start çš„ç¤ºç¯„ç«™é»ï¼Œä¸¦è‡ªå‹•éƒ¨ç½²åˆ° GitHub Pages çš„éç¨‹ ...... Hugo Front Matter åƒæ•¸èªªæ˜ Content Summaries\nHugo generates summaries of your content. With the use of the .Summary page variable, Hugo generates summaries of content to use as a short version in summary views.\nå°‡ç›®éŒ„ (ToC) æ”¹åˆ°å´é‚Š åƒè€ƒ Hugoåšå®¢ç›®å½•æ”¾åœ¨ä¾§è¾¹ | PaperModä¸»é¢˜\næ–‡ç« å†…å®¹ä»…é™äºPaperModä¸»é¢˜ï¼Œå¯¹äºå…¶ä»–ä¸»é¢˜ä»…ä¾›å‚è€ƒ\nä¿®æ”¹ ToC é¦–å…ˆæ‰¾åˆ° layouts/partials/toc.html ï¼Œ æ›´æ›æª”æ¡ˆå…§å®¹å¦‚ä¸‹\n{{- $headers := findRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;(.|\\n])+?\u0026lt;/h[1-6]\u0026gt;\u0026#34; .Content -}} {{- $has_headers := ge (len $headers) 1 -}} {{- if $has_headers -}} \u0026lt;aside id=\u0026#34;toc-container\u0026#34; class=\u0026#34;toc-container wide\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;toc\u0026#34;\u0026gt; \u0026lt;details {{if (.Param \u0026#34;TocOpen\u0026#34;) }} open{{ end }}\u0026gt; \u0026lt;summary accesskey=\u0026#34;c\u0026#34; title=\u0026#34;(Alt + C)\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;details\u0026#34;\u0026gt;{{- i18n \u0026#34;toc\u0026#34; | default \u0026#34;Table of Contents\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;/summary\u0026gt; \u0026lt;div class=\u0026#34;inner\u0026#34;\u0026gt; {{- $largest := 6 -}} {{- range $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{- if lt $headerLevel $largest -}} {{- $largest = $headerLevel -}} {{- end -}} {{- end -}} {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice -}} \u0026lt;ul\u0026gt; {{- range seq (sub $firstHeaderLevel $largest) -}} \u0026lt;ul\u0026gt; {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (sub (add $largest .) 1) -}} {{- end -}} {{- range $i, $header := $headers -}} {{- $headerLevel := index (findRE \u0026#34;[1-6]\u0026#34; . 1) 0 -}} {{- $headerLevel := len (seq $headerLevel) -}} {{/* get id=\u0026#34;xyz\u0026#34; */}} {{- $id := index (findRE \u0026#34;(id=\\\u0026#34;(.*?)\\\u0026#34;)\u0026#34; $header 9) 0 }} {{- /* strip id=\u0026#34;\u0026#34; to leave xyz, no way to get regex capturing groups in hugo */ -}} {{- $cleanedID := replace (replace $id \u0026#34;id=\\\u0026#34;\u0026#34; \u0026#34;\u0026#34;) \u0026#34;\\\u0026#34;\u0026#34; \u0026#34;\u0026#34; }} {{- $header := replaceRE \u0026#34;\u0026lt;h[1-6].*?\u0026gt;((.|\\n])+?)\u0026lt;/h[1-6]\u0026gt;\u0026#34; \u0026#34;$1\u0026#34; $header -}} {{- if ne $i 0 -}} {{- $prevHeaderLevel := index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub $i 1)) 1) 0 -}} {{- $prevHeaderLevel := len (seq $prevHeaderLevel) -}} {{- if gt $headerLevel $prevHeaderLevel -}} {{- range seq $prevHeaderLevel (sub $headerLevel 1) -}} \u0026lt;ul\u0026gt; {{/* the first should not be recorded */}} {{- if ne $prevHeaderLevel . -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; . -}} {{- end -}} {{- end -}} {{- else -}} \u0026lt;/li\u0026gt; {{- if lt $headerLevel $prevHeaderLevel -}} {{- range seq (sub $prevHeaderLevel 1) -1 $headerLevel -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) . -}} \u0026lt;/ul\u0026gt; {{/* manually do pop item */}} {{- $tmp := $.Scratch.Get \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Delete \u0026#34;bareul\u0026#34; -}} {{- $.Scratch.Set \u0026#34;bareul\u0026#34; slice}} {{- range seq (sub (len $tmp) 1) -}} {{- $.Scratch.Add \u0026#34;bareul\u0026#34; (index $tmp (sub . 1)) -}} {{- end -}} {{- else -}} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end -}} {{- end -}} {{- end }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- else }} \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#{{- $cleanedID -}}\u0026#34; aria-label=\u0026#34;{{- $header | plainify -}}\u0026#34;\u0026gt;{{- $header | safeHTML -}}\u0026lt;/a\u0026gt; {{- end -}} {{- end -}} \u0026lt;!-- {{- $firstHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers 0) 1) 0)) -}} --\u0026gt; {{- $firstHeaderLevel := $largest }} {{- $lastHeaderLevel := len (seq (index (findRE \u0026#34;[1-6]\u0026#34; (index $headers (sub (len $headers) 1)) 1) 0)) }} \u0026lt;/li\u0026gt; {{- range seq (sub $lastHeaderLevel $firstHeaderLevel) -}} {{- if in ($.Scratch.Get \u0026#34;bareul\u0026#34;) (add . $firstHeaderLevel) }} \u0026lt;/ul\u0026gt; {{- else }} \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; {{- end -}} {{- end }} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/details\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;script\u0026gt; let activeElement; let elements; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, function (event) { checkTocPosition(); elements = document.querySelectorAll(\u0026#39;h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]\u0026#39;); // Make the first header active activeElement = elements[0]; const id = encodeURI(activeElement.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); }, false); window.addEventListener(\u0026#39;resize\u0026#39;, function(event) { checkTocPosition(); }, false); window.addEventListener(\u0026#39;scroll\u0026#39;, () =\u0026gt; { // Check if there is an object in the top half of the screen or keep the last item active activeElement = Array.from(elements).find((element) =\u0026gt; { if ((getOffsetTop(element) - window.pageYOffset) \u0026gt; 0 \u0026amp;\u0026amp; (getOffsetTop(element) - window.pageYOffset) \u0026lt; window.innerHeight/2) { return element; } }) || activeElement elements.forEach(element =\u0026gt; { const id = encodeURI(element.getAttribute(\u0026#39;id\u0026#39;)).toLowerCase(); if (element === activeElement){ document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.add(\u0026#39;active\u0026#39;); } else { document.querySelector(`.inner ul li a[href=\u0026#34;#${id}\u0026#34;]`).classList.remove(\u0026#39;active\u0026#39;); } }) }, false); const main = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--article-width\u0026#39;), 10); const toc = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--toc-width\u0026#39;), 10); const gap = parseInt(getComputedStyle(document.body).getPropertyValue(\u0026#39;--gap\u0026#39;), 10); function checkTocPosition() { const width = document.body.scrollWidth; if (width - main - (toc * 2) - (gap * 4) \u0026gt; 0) { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.add(\u0026#34;wide\u0026#34;); } else { document.getElementById(\u0026#34;toc-container\u0026#34;).classList.remove(\u0026#34;wide\u0026#34;); } } function getOffsetTop(element) { if (!element.getClientRects().length) { return 0; } let rect = element.getBoundingClientRect(); let win = element.ownerDocument.defaultView; return rect.top + win.pageYOffset; } \u0026lt;/script\u0026gt; {{- end }} ç„¶å¾Œç¢ºèª layouts/_default/single.html æ˜¯å¦æœ‰å¼•å…¥ä½¿ç”¨ toc.html ã€‚ é€™é‚Šé è¨­æ˜¯æœ‰å¼•å…¥çš„ï¼Œä½œè€…å¯«å‡ºä¾†æ˜¯é˜²æ­¢æœ‰äººè‡ªå®šç¾©æ–‡ä»¶åç¨±ï¼Œå°è‡´è¨­å®šå¤±æ•—\n{{- if (.Param \u0026#34;ShowToc\u0026#34;) }} {{- partial \u0026#34;toc.html\u0026#34; . }} {{- end }} ä¿®æ”¹ CSS æ‰¾åˆ° css/extended/blank.css ï¼Œ æ›´æ›æª”æ¡ˆå…§å®¹å¦‚ä¸‹\n:root { --nav-width: 1380px; --article-width: 650px; --toc-width: 300px; } .toc { margin: 0 2px 40px 2px; border: 1px solid var(--border); background: var(--entry); border-radius: var(--radius); padding: 0.4em; } .toc-container.wide { position: absolute; height: 100%; border-right: 1px solid var(--border); left: calc((var(--toc-width) + var(--gap)) * -1); top: calc(var(--gap) * 2); width: var(--toc-width); } .wide .toc { position: sticky; top: var(--gap); border: unset; background: unset; border-radius: unset; width: 100%; margin: 0 2px 40px 2px; } .toc details summary { cursor: zoom-in; margin-inline-start: 20px; padding: 12px 0; } .toc details[open] summary { font-weight: 500; } .toc-container.wide .toc .inner { margin: 0; } .active { font-size: 110%; font-weight: 600; } .toc ul { list-style-type: circle; } .toc .inner { margin: 0 0 0 20px; padding: 0px 15px 15px 20px; font-size: 16px; /*ç›®å½•æ˜¾ç¤ºé«˜åº¦*/ max-height: 83vh; overflow-y: auto; } .toc .inner::-webkit-scrollbar-thumb { /*æ»šåŠ¨æ¡*/ background: var(--border); border: 7px solid var(--theme); border-radius: var(--radius); } .toc li ul { margin-inline-start: calc(var(--gap) * 0.5); list-style-type: none; } .toc li { list-style: none; font-size: 0.95rem; padding-bottom: 5px; } .toc li a:hover { color: var(--secondary); } ","permalink":"https://blog.zhengweiliu.com/posts/hugo/papermod/","summary":"é€™ç¯‡æ–‡ç« æ•´ç†äº†å€‹äººä½¿ç”¨ PaperMod theme çš„è¨­å®š","title":"Hugo-PaperMod theme è¨­å®š"},{"content":"é€™ç¯‡æ–‡ç« ä¸»è¦æä¾› GitHub Pages è¨­å®š custom domain çš„éç¨‹\nGitHub Pages æä¾›äº†å¯ä»¥è¨­å®š custom domain çš„æ–¹æ³•ï¼Œå› æ­¤æƒ³è¦é€é custom domain è¨­å®šï¼Œå°‡ GitHub Pages çš„ URL æ›´æ”¹ç‚ºè‡ªå·±çš„ domainã€‚\nç”³è«‹ Domain æœ‰å¾ˆå¤š provider æä¾›è¨»å†Š domain çš„æœå‹™ï¼Œå¦‚ Google Domainã€Go Daddy ç­‰ç­‰ã€‚\næˆ‘è‡ªå·±æ˜¯åœ¨ GoDaddy ä¸Šè³¼è²· Domain ï¼Œ å› æ­¤é€™ç¯‡æ–‡ç« è¨˜éŒ„çš„æ˜¯åœ¨ Go Daddy ä¸Šçš„è¨­å®šæ–¹å¼ã€‚\nGitHub Pages Custom Domain æ ¹æ“š GitHub Pages çš„æ–‡ä»¶èª¬æ˜ï¼Œè¨­å®š subdomain çš„æ–¹å¼ç›¸å°ç°¡å–®æ˜ç™½\nGitHub Pages Repository \u0026gt; Settings \u0026gt; Pages (å·¦å´é¸å–®) \u0026gt; Custom Domain \u0026gt; è¼¸å…¥ subdomain \u0026gt; Save\né€™æ™‚æœƒçœ‹åˆ° Custom Domain ä¸‹æ–¹å‡ºç¾æ­£åœ¨é©—è­‰ domain çš„å­—æ¨£ï¼Œç­‰ DNS Record è¨­å®šå¥½ä¹‹å¾Œï¼Œå¹¾åˆ†é˜å…§å°±æœƒå‡ºç¾é©—è­‰é€šéçš„ç¶ è‰²å­—æ¨£ã€‚\nGoDaddy DNS Record è¨­å®š åœ¨ GoDaddy çš„ DNS ç´€éŒ„é é¢ï¼Œæ–°å¢ä¸€ç­† C Name Recordï¼Œçµ¦äºˆæƒ³è¦çš„ subdomain åç¨±ï¼Œå¦‚: www ã€ blog ï¼Œå…§å®¹å€¼å¡«å…¥ GitHub Pages URL ï¼Œå¦‚ : zhweiliu.github.io. ï¼ŒTTL æ™‚é–“å¯ä»¥ç•™é è¨­å€¼ï¼Œä¹‹å¾Œå„²å­˜ä»¥æ–°å¢ç´€éŒ„å³å¯\nEnable GitHub Pages Enforce Https åœ¨ terminal ä¸­ä½¿ç”¨æŒ‡ä»¤ç¢ºèª DNS Record çš„è¨­ç½®æ˜¯å¦è®“ GitHub Pages Custom Domain ç”Ÿæ•ˆ\n$ dig blog.zhengweiliu.com è‹¥è¨­ç½®å·²ç¶“ç”Ÿæ•ˆï¼Œä½ æœƒçœ‹åˆ°å¦‚ä¸‹åœ–æ‰€ç¤ºçš„ Answer Section å°‡ blog.zhengweiliu.com ç½®æ›ç‚ºä½ è¨­å®š subdomain\nå‡è¨­ä½ è¨­å®š CNAME å¾—åç¨±ç‚º www ï¼Œ ä½ è³¼è²·çš„ domain name æ˜¯ example.com ï¼Œé‚£ä½ éœ€è¦ dig www.example.com\nå›åˆ°å…ˆå‰ GitHub Pages Custom Domain è¨­å®šçš„é é¢ï¼Œåˆ·æ–°ç¶²é å¾Œå°‡ Enforce HTTPS æ‰“å‹¾ï¼Œä»¥ç¢ºä¿ http:// é–‹é ­çš„è«‹æ±‚éƒ½èƒ½å¤ è¢«å¼·åˆ¶è½‰ç‚º https://\n","permalink":"https://blog.zhengweiliu.com/posts/hugo/custom_domain/","summary":"é€™ç¯‡æ–‡ç« ä¸»è¦æä¾› GitHub Pages è¨­å®š custom domain çš„éç¨‹","title":"GitHub Pages è¨­å®š Custom Domain ( Go Daddy )"},{"content":"é€™ç¯‡æ–‡ç« ä¸»è¦æä¾›åœ¨ Mac M2 ä¸Šå®‰è£ Hugo ã€åŸ·è¡Œä¸€å€‹ quick start çš„ç¤ºç¯„ç«™é»ï¼Œä¸¦è‡ªå‹•éƒ¨ç½²åˆ° GitHub Pages çš„éç¨‹\nWhat is Hugo ? Hugo æ˜¯ä¸€å€‹é€šç”¨çš„ç¶²ç«™æ¡†æ¶ã€‚å¾æŠ€è¡“ä¸Šè¬›ï¼ŒHugo æ˜¯ä¸€å€‹éœæ…‹ç«™é»ç”Ÿæˆå™¨ã€‚èˆ‡æ ¹æ“šæ¯å€‹è¨ªå•è€…è«‹æ±‚å‹•æ…‹æ§‹å»ºé é¢çš„ç³»çµ±ä¸åŒï¼ŒHugo åœ¨æ‚¨å‰µå»ºæˆ–æ›´æ–°å…§å®¹æ™‚æ§‹å»ºé é¢ã€‚\néœæ…‹ç«™é»ç”Ÿæˆå™¨ ç¶²ç«™ç”Ÿæˆå™¨çš„ç›®çš„æ˜¯å°‡å…§å®¹å‘ˆç¾ç‚º HTML æ–‡ä»¶ã€‚å¤§å¤šæ•¸æ˜¯â€œå‹•æ…‹ç«™é»ç”Ÿæˆå™¨â€ã€‚é€™æ„å‘³è‘— HTTP æœå‹™å™¨â€”â€”å³ï¼Œå°‡æ–‡ä»¶ç™¼é€åˆ°ç€è¦½å™¨ä»¥ä¾›æŸ¥çœ‹çš„ç¨‹åºâ€”â€”é‹è¡Œç”Ÿæˆå™¨ä»¥åœ¨æ¯æ¬¡æœ€çµ‚ç”¨æˆ¶è«‹æ±‚é é¢æ™‚å‰µå»ºä¸€å€‹æ–°çš„ HTML æ–‡ä»¶ã€‚\néš¨è‘—æ™‚é–“çš„æ¨ç§»ï¼Œå‹•æ…‹ç«™é»ç”Ÿæˆå™¨è¢«ç·¨ç¨‹ç‚ºç·©å­˜å®ƒå€‘çš„ HTML æ–‡ä»¶ï¼Œä»¥é˜²æ­¢åœ¨å‘æœ€çµ‚ç”¨æˆ¶äº¤ä»˜é é¢æ™‚å‡ºç¾ä¸å¿…è¦çš„å»¶é²ã€‚ç·©å­˜é é¢æ˜¯ç¶²é çš„éœæ…‹ç‰ˆæœ¬ã€‚\nHugo ä½¿ç·©å­˜æ›´é€²ä¸€æ­¥ï¼Œæ‰€æœ‰ HTML æ–‡ä»¶éƒ½å‘ˆç¾åœ¨æ‚¨çš„è¨ˆç®—æ©Ÿä¸Šã€‚åœ¨å°‡æ–‡ä»¶è¤‡è£½åˆ°è¨—ç®¡ HTTP æœå‹™å™¨çš„è¨ˆç®—æ©Ÿä¹‹å‰ï¼Œæ‚¨å¯ä»¥åœ¨æœ¬åœ°æŸ¥çœ‹é€™äº›æ–‡ä»¶ã€‚ç”±æ–¼ HTML æ–‡ä»¶ä¸æ˜¯å‹•æ…‹ç”Ÿæˆçš„ï¼Œæˆ‘å€‘èªª Hugo æ˜¯ä¸€å€‹éœæ…‹ç«™é»ç”Ÿæˆå™¨ã€‚\nMac M2 å®‰è£ å®‰è£å‰éœ€æ±‚ Hugo ç¶“å¸¸æœƒä¼´éš¨è‘— Git å’Œ Go çš„åŠŸèƒ½ä¾†é€²è¡Œéƒ¨ç½²å’Œä½¿ç”¨å…¶ä»–çš„ modules featureï¼Œå› æ­¤éœ€è¦å…ˆæª¢æŸ¥ Git å’Œ Go æ˜¯å¦æœ‰å®‰è£\nGit installation Mac M2 é è¨­å·²å®‰è£ Git\né€éæŒ‡ä»¤ç¢ºèª git æ˜¯å¦å·²å®‰è£\ngit --version å¦‚éœ€è¦é‡æ–°å®‰è£ Git ï¼Œå¯åˆ©ç”¨ brew æŒ‡ä»¤é€²è¡Œå®‰è£\nbrew install git Go installation åŒæ¨£åˆ©ç”¨ brew install æŒ‡ä»¤å®‰è£ Go å³å¯\nbrew install go å®‰è£å®Œæˆå¾Œï¼Œåˆ©ç”¨æŒ‡ä»¤æª¢æŸ¥å®‰è£ç‰ˆæœ¬ï¼Œä»¥ç¢ºèªå®‰è£æˆåŠŸ\nbrew install Hugo åˆ©ç”¨ brew install æŒ‡ä»¤ï¼Œç›´æ¥å®‰è£ Hugo extended edition ç‰ˆæœ¬å³å¯\nbrew install hugo å®‰è£å®Œæˆå¾Œï¼Œä¸€æ¨£åˆ©ç”¨æŒ‡ä»¤æª¢æŸ¥å®‰è£ç‰ˆæœ¬ï¼Œä»¥ç¢ºèªå®‰è£æˆåŠŸ Quick Start ä»¥ Hogo å®˜æ–¹çš„ Quick Start æ–‡ä»¶ç‚ºä¾‹\nå»ºç«‹ Hugo ç«™é» # åˆ©ç”¨ hugo æŒ‡ä»¤å»ºç«‹æ–°çš„éœæ…‹ç«™é» # ä¸¦åœ¨ç•¶å‰ç›®éŒ„ä¸‹å»ºç«‹åç‚º \u0026#34;quickstart\u0026#34; çš„è³‡æ–™å¤¾ $ hugo new site quickstart # åˆ‡æ›åˆ° quickstart $ cd quickstart # åˆ©ç”¨ git æŒ‡ä»¤å°‡ quickstart è³‡æ–™å¤¾è®Šæˆä¸€å€‹ repository # ä¸¦å— git ç®¡ç† $ git init # ä»¥ submodule æ–¹å¼ç‚ºæ·»åŠ å¯ç”¨ hugo ä¸»é¡Œ # å®˜æ–¹æ¡ç”¨ Ananke ä¸»é¡Œä½œç‚ºç¤ºç¯„ $ git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke # å°‡ä¸»é¡Œè¨­ç½®çµ¦ hugo # hugo é€šå¸¸ä»¥ config.toml ä½œç‚ºä¸»è¦è¨­å®šæª”æ¡ˆ # é™¤äº† toml æ ¼å¼æ¨™æº–ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ json æˆ– yaml æ ¼å¼ $ echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; config.toml # åœ¨æœ¬æ©Ÿé›»è…¦ä¸ŠåŸ·è¡Œ hugo server æœå‹™ # -D è¡¨ç¤ºå¯ä»¥åœ¨æœ¬æ©Ÿé è¦½ draft: true çš„æ–‡ç«  $ hugo server -D åŸ·è¡Œ hugo server -D å¾Œï¼Œå¯ä»¥åœ¨ terminal çœ‹åˆ°æœ¬æ©Ÿé›»è…¦æä¾›çš„æ¸¬è©¦ URL : http://localhost:1313/ ï¼Œåœ¨ç€è¦½å™¨ä¸Šè¼¸å…¥é€™æ®µ URL ä¾¿èƒ½å¤ çœ‹åˆ°æœ¬æ©Ÿé»è…¦ä¸Šçš„ Hugo ç«™é»èˆ‡æ–‡ç«  æ–°å¢ä¸€ç¯‡æ–‡ç«  åœ¨ terminal ä¸­ï¼Œé€²å…¥äº† qucikstart çš„ Hugo ç«™é»è³‡æ–™å¤¾å¾Œï¼Œåˆ©ç”¨ Hugo æŒ‡ä»¤å»ºç«‹ä¸€ç¯‡æ–°çš„æ–‡ç« \n$ hugo new posts/hello_world.md hugo new æŒ‡ä»¤å¯ä»¥å¹«åŠ©æˆ‘å€‘å¿«é€Ÿçš„å»ºç«‹ Hugo ç«™é»å…§çš„æ‰€ä»¥æ–°è³‡æº å¦‚æœä¸ç†Ÿæ‚‰çš„è©±ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨åœ–åƒä»‹é¢ä¸­ï¼Œåœ¨ content è³‡æ–™å¤¾ä¸‹æ–°å¢ä¸€å€‹ posts è³‡æ–™å¤¾ï¼Œä¸¦ä¸”åœ¨ posts è³‡æ–™å¤¾åœ¨æ–°å¢ä¸€å€‹ hello_world.md æª”æ¡ˆï¼Œä¹Ÿèƒ½é”æˆç›¸åŒçš„æ•ˆæœ\næ–‡ç« å…§å®¹ æ‰“é–‹ hello_world.md æª”æ¡ˆï¼Œé è¨­æ‡‰è©²æœƒçœ‹åˆ° Hugo å¹«æˆ‘å€‘å»ºç«‹çš„ Front Matter è³‡è¨Š\ntitle: \u0026#34;My First Post\u0026#34; date: 2022-11-20T09:03:20-08:00 draft: true title : æ–‡ç« æ¨™é¡Œ\ndate : æ–‡ç« å»ºç«‹æ™‚é–“\ndraft : æ˜¯å¦ç‚ºè‰ç¨¿ã€‚ true è¡¨ç¤ºç‚ºè‰ç¨¿ï¼ŒHugo ä¸æœƒå°‡è‰ç¨¿ç™¼ä½ˆåˆ°æ­£å¼çš„ç«™é»ç’°å¢ƒï¼Œè‰ç¨¿æ–‡ç« åƒ…åœ¨ hugo server -D æ™‚å¯è¦‹ã€‚\n*.md æª”æ¡ˆä½¿ç”¨çš„æ˜¯ markdown èªæ³• ï¼Œ å¯ä»¥åœ¨ Front Matter ä¸‹ç›´æ¥ä½¿ç”¨ markdown èªæ³•é–‹å§‹ç·¨å¯«æ–‡ç« \n--- title: \u0026#34;My First Post\u0026#34; date: 2022-11-20T09:03:20-08:00 draft: true --- ## Introduction This is **bold** text, and this is *emphasized* text. Visit the [Hugo](https://gohugo.io) website! æ–‡ç« å…§å®¹æœ‰ç•°å‹•ä¸¦ä¸”å„²å­˜æª”æ¡ˆå¾Œï¼Œåœ¨ hugo server -D å•Ÿå‹•æœ¬æ©Ÿé›»è…¦ Hugo ç«™é»çš„æƒ…æ³ä¸‹ï¼Œå¯ä»¥ç›´æ¥åœ¨ http://localhost:1313/ ä¸­çœ‹åˆ°è®Šå‹•å¾Œçš„æ–‡ç« å…§å®¹ã€‚\néƒ¨ç½²åˆ° GitHub Pages ç›®å‰æœ‰æ»¿å¤š provider æ”¯æ´éƒ¨ç½² Hugo ç«™é»çš„æœå‹™ï¼Œå¦‚ AWS Amplify, CloudCannon, Cloudflare Pages, GitHub Pages, GitLab Pages, and Netlify.\nå› å€‹äººç¿’æ…£ï¼Œæ‰€ä»¥æœ¬æ–‡æ¡ç”¨éƒ¨ç½²åˆ° GitHub Pages\nå»ºç«‹ GitHub Pages çš„ Repository ç™»å…¥è‡ªå·±çš„ GitHub å¸³è™Ÿå¾Œï¼Œå»ºç«‹ä¸€å€‹ repository çµ¦ GitHub Pages ä½¿ç”¨\nRepository Name åš´æ ¼è¦å®šè¦ä½¿ç”¨ {github å¸³è™Ÿ}.github.io\nå…ˆæ‰¾åˆ°å‰›æ‰å»ºç«‹å¥½çš„ GitHub Pages Repository æä¾›çš„ HTTP URL\né–‹å•Ÿ Terminal ä¸¦åœ¨ Hugo ç«™é»ä¸‹åŸ·è¡Œ git æŒ‡ä»¤\n$ git remote add origin {GitHub Pages Repository URL} é€éæŒ‡ä»¤æª¢æŸ¥ git remote æ˜¯å¦è¨­å®šå®Œæˆ\n$ git remote -v GitHub Personal Access Token å¦‚æœç¬¬ä¸€æ¬¡åœ¨ Mac ä¸Šè¨­å®š Git é€£ç·šè³‡è¨Šï¼Œæœ‰å¯èƒ½æœƒæç¤ºä½ è¦è¼¸å…¥ GitHub çš„å¸³è™Ÿå¯†ç¢¼ã€‚ ä½† GitHub å·²ç¶“å–æ¶ˆä½¿ç”¨å¯†ç¢¼ç™»å…¥çš„æ–¹å¼ï¼Œç›®å‰åƒ…èƒ½é€é personal access token çš„æ–¹å¼ä¾†é€šéé©—è­‰ã€‚ (å³åœ¨è¼¸å…¥å¯†ç¢¼æ™‚ï¼Œæ”¹ä»¥æä¾› person access token è€Œéå¯†ç¢¼)\nHugo åœ¨éƒ¨ç½²ç«™é»æ™‚æœƒéœ€è¦ä½¿ç”¨ CI/CD çš„åŠŸèƒ½ï¼Œå› æ­¤ GitHub Access Token çš„ Scope ä¸­éœ€è¦æŠŠ workflow ä¸€ä½µå‹¾é¸ä»¥æˆæ¬Š\nè¨­å®š GitHub Action é€éè¨­å®š GitHub Action ï¼Œ åœ¨æ¯æ¬¡å°‡æ–‡ç« æ¨é€åˆ° GitHub Repository å¾Œï¼Œè‡ªå‹•åŸ·è¡Œéƒ¨ç½²ç«™é»çš„å‹•ä½œ\né¦–å…ˆï¼Œåœ¨ Terminal é€éæŒ‡ä»¤å»ºç«‹ .github/workflows/gh-pages.yml æª”æ¡ˆ\n# è¨˜å¾—å…ˆå°‡ Terminal åˆ‡æ›åˆ° Hugo ç«™é»çš„è³‡æ–™å¤¾ä¸‹ï¼Œæ¯”å¦‚ quickstart # å»ºç«‹è³‡æ–™å¤¾ .github/workflows/ # -p æŒ‡ä»¤å¯ä»¥ç›´æ¥å°‡è·¯å¾‘ä¸­ç¼ºå°‘çš„è³‡æ–™å¤¾ä¸€ä½µå»ºç«‹ $ mkdir -p .github/workflows/ # touch æŒ‡ä»¤å»ºç«‹ä¸€å€‹ç©ºæª”æ¡ˆï¼Œå‘½åç‚º gh-pages.yml ï¼Œ # å› ç‚ºè¼¸å…¥äº†ç›¸å°è·¯å¾‘ .github/workflows ï¼Œ # gh-pages.yml æª”æ¡ˆæœƒè¢«æ”¾åœ¨ .github/workflows è³‡æ–™å¤¾ä¸‹ $ touch .github/workflows/gh-pages.yml å°‡ä¸‹åˆ—çš„å…§å®¹è¤‡è£½è²¼ä¸Šåˆ° .github/workflows/gh-pages.yml æª”æ¡ˆä¸­\nname: GitHub Pages on: push: branches: - main # Set a branch name to trigger deployment pull_request: jobs: deploy: runs-on: ubuntu-22.04 permissions: contents: write concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 # If you\u0026#39;re changing the branch from main, # also change the `main` in `refs/heads/main` # below accordingly. if: ${{ github.ref == \u0026#39;refs/heads/main\u0026#39; }} with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public ä¿®æ”¹ Hugo è¨­å®šæª” baseURL è¨­å®š Hugo config.toml (æˆ– config.yml | config.json) ï¼Œ æ›´æ”¹ baseURL ç‚º https://{GitHubå¸³è™Ÿ}.github.io\nåŒæ­¥ Hugo ç«™é»åˆ° GitHub é€é Terminal ä½¿ç”¨ git æŒ‡ä»¤\n# å°‡ GitHub Pages Repository çš„è³‡è¨ŠåŒæ­¥åˆ°æœ¬æ©Ÿé›»è…¦ä¸Šçš„ Hugo ç«™é»è³‡æ–™å¤¾ä¸­ $ git fetch # å°‡ç›®å‰ Hugo ç«™é»çš„æ‰€æœ‰æª”æ¡ˆç´å…¥ git ç®¡ç† $ git add --all # å°‡æœ¬æ¬¡ç´å…¥ git ç®¡ç†çš„ç•°å‹•æª”æ¡ˆï¼Œæ‰“åŒ…æˆä¸€å€‹ç‰ˆæœ¬ $ git commit -m \u0026#39;first commit\u0026#39; # å°‡æ‰“åŒ…çš„ç‰ˆæœ¬åŒæ­¥åˆ° GitHub Pages Repository $ git push -u origin main æª¢æŸ¥ GitHub Pages éƒ¨ç½²ç‹€æ³ åœ¨ GitHub Pages ä¸­é»é¸ Actions é ç°½ï¼Œå¯ä»¥æŸ¥çœ‹æ‰€æœ‰ workflow çš„é‹å‹ç‹€æ³ã€‚ ç”±æ–¼å‰é¢è¨­å®šäº† .github/workflows/gh-pages.yml æª”æ¡ˆï¼Œæ¯æ¬¡å°‡ç•°å‹•çš„æª”æ¡ˆåŒæ­¥åˆ° GitHub Pages Repository å¾Œï¼Œ GitHub ä¾¿æœƒè‡ªå‹•åŸ·è¡Œ .github/workflows/gh-pages.yml æª”æ¡ˆè¨­å®šçš„å·¥ä½œæµå…§å®¹ï¼Œä¸¦å°‡ Hugo ç«™é»çš„æ–‡ç« éƒ¨ç½²åˆ° GitHub Pages ä¿®æ”¹ GitHub Pages Repository çš„åˆ†æ”¯ åœ¨ GitHub Pages Repository çš„ Settings é ç°½ä¸­ä¿®æ”¹ Branch ï¼Œé€™å€‹å‹•ä½œæ˜¯è®“ GitHub Pages å¯ä»¥çŸ¥é“æ‡‰è©²å¾å“ªä¸€å€‹ Branch æŠ“å–éœ€è¦éƒ¨ç½²çš„ Hugo ç«™é»è³‡æ–™\nGitHub Pages Repository \u0026gt; Settings \u0026gt; Pages (å·¦å´é¸å–®) \u0026gt; Build and deployment \u0026gt; Branch \u0026gt; é»æ“Šä¸‹æ‹‰é¸å–®å¾ main æ›´æ”¹ç‚º gh-pages.\n","permalink":"https://blog.zhengweiliu.com/posts/hugo/installation/","summary":"é€™ç¯‡æ–‡ç« ä¸»è¦æä¾›åœ¨ Mac M2 ä¸Šå®‰è£ Hugo ã€åŸ·è¡Œä¸€å€‹ quick start çš„ç¤ºç¯„ç«™é»ï¼Œä¸¦è‡ªå‹•éƒ¨ç½²åˆ° GitHub Pages çš„éç¨‹","title":"Hugo å®‰è£èˆ‡éƒ¨ç½²åˆ° GitHub Pages ( Mac M2 ) "},{"content":"Description Five silent philosophers sit at a round table with bowls of spaghetti. Forks are placed between each pair of adjacent philosophers.\nEach philosopher must alternately think and eat. However, a philosopher can only eat spaghetti when they have both left and right forks. Each fork can be held by only one philosopher and so a philosopher can use the fork only if it is not being used by another philosopher. After an individual philosopher finishes eating, they need to put down both forks so that the forks become available to others. A philosopher can take the fork on their right or the one on their left as they become available, but cannot start eating before getting both forks.\nEating is not limited by the remaining amounts of spaghetti or stomach space; an infinite supply and an infinite demand are assumed.\nDesign a discipline of behaviour (a concurrent algorithm) such that no philosopher will starve; i.e., each can forever continue to alternate between eating and thinking, assuming that no philosopher can know when others may want to eat or think.\nThe problem statement and the image above are taken from wikipedia.org\nThe philosophersâ€™ ids are numbered from 0 to 4 in a clockwise order. Implement the function void wantsToEat(philosopher, pickLeftFork, pickRightFork, eat, putLeftFork, putRightFork) where:\nphilosopher is the id of the philosopher who wants to eat. pickLeftFork and pickRightFork are functions you can call to pick the corresponding forks of that philosopher. eat is a function you can call to let the philosopher eat once he has picked both forks. putLeftFork and putRightFork are functions you can call to put down the corresponding forks of that philosopher. The philosophers are assumed to be thinking as long as they are not asking to eat (the function is not being called with their number). Five threads, each representing a philosopher, will simultaneously use one object of your class to simulate the process. The function may be called for the same philosopher more than once, even before the last call ends.\nIdea The Dining philosophers problem.\nIn computer science, the dining philosophers problem is an example problem often used in concurrent algorithm design to illustrate synchronization issues and techniques for resolving them.\nFocus on the forks instead of philosophers, because forks are necessary resources if philosopher would like to eat food.\nI used a list to put 5 lock, each lock indicates a fork, let philosopher id + 1 as their left-hand, philosopher id as their right-hand.\nTake the pickup left-handâ€™s fork first because itâ€™s have a higher numberÂ , and put down right fork first because it a higher number fork for right side philosopher.\nSolution from threading import Condition class DiningPhilosophers: def __init__(self) -\u0026gt; None: self._forks = [Condition()] * 5 # call the functions directly to execute, for example, eat() def wantsToEat(self, philosopher: int, pickLeftFork: \u0026#39;Callable[[], None]\u0026#39;, pickRightFork: \u0026#39;Callable[[], None]\u0026#39;, eat: \u0026#39;Callable[[], None]\u0026#39;, putLeftFork: \u0026#39;Callable[[], None]\u0026#39;, putRightFork: \u0026#39;Callable[[], None]\u0026#39;) -\u0026gt; None: with self._forks[(philosopher+1)%5], self._forks[philosopher]: pickLeftFork() pickRightFork() eat() putRightFork() putLeftFork() ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/concurrency/the-dining-philosophers/","summary":"Description Five silent philosophers sit at a round table with bowls of spaghetti. Forks are placed between each pair of adjacent philosophers.\nEach philosopher must alternately think and eat. However, a philosopher can only eat spaghetti when they have both left and right forks. Each fork can be held by only one philosopher and so a philosopher can use the fork only if it is not being used by another philosopher.","title":"[leetcode][Python][Concurrency][Medium] 1226. The Dining Philosophers"},{"content":"Description You have the four functions:\nprintFizz that prints the word \u0026quot;fizz\u0026quot; to the console, printBuzz that prints the word \u0026quot;buzz\u0026quot; to the console, printFizzBuzz that prints the word \u0026quot;fizzbuzz\u0026quot; to the console, and printNumber that prints a given integer to the console. You are given an instance of the class FizzBuzz that has four functions: fizz, buzz, fizzbuzz and number. The same instance of FizzBuzz will be passed to four different threads:\nThread A: calls fizz() that should output the word \u0026quot;fizz\u0026quot;. Thread B: calls buzz() that should output the word \u0026quot;buzz\u0026quot;. Thread C: calls fizzbuzz() that should output the word \u0026quot;fizzbuzz\u0026quot;. Thread D: calls number() that should only output the integers. Modify the given class to output the series [1, 2, \u0026quot;fizz\u0026quot;, 4, \u0026quot;buzz\u0026quot;,Â ...] where the ith token (1-indexed) of the series is:\n\u0026quot;fizzbuzz\u0026quot; if i is divisible by 3 and 5, \u0026quot;fizz\u0026quot; if i is divisible by 3 and not 5, \u0026quot;buzz\u0026quot; if i is divisible by 5 and not 3, or i if i is not divisible by 3 or 5. Implement the FizzBuzz class:\nFizzBuzz(int n) Initializes the object with the number n that represents the length of the sequence that should be printed. void fizz(printFizz) Calls printFizz to output \u0026quot;fizz\u0026quot;. void buzz(printBuzz) Calls printBuzz to output \u0026quot;buzz\u0026quot;. void fizzbuzz(printFizzBuzz) Calls printFizzBuzz to output \u0026quot;fizzbuzz\u0026quot;. void number(printNumber) Calls printnumber to output the numbers. Idea For example\nInput: n = 15 Output: [1,2,\u0026#34;fizz\u0026#34;,4,\u0026#34;buzz\u0026#34;,\u0026#34;fizz\u0026#34;,7,8,\u0026#34;fizz\u0026#34;,\u0026#34;buzz\u0026#34;,11,\u0026#34;fizz\u0026#34;,13,14,\u0026#34;fizzbuzz\u0026#34;] Basically, I guess it could be used Condition or Lock to solve this question, but its could be bring about not easily to read for the solution.\nAfter study the discussion with other contributors, I agree to use Python threading.Semaphore to solve this question.\nThe Semaphore introduce on official documentation asÂ :\nA semaphore manages an atomic counter representing the number of release() calls minus the number of acquire() calls, plus an initial value. The acquire() method blocks if necessary until it can return without making the counter negative. If not given, value defaults to 1. We can create Semaphore objects for fizz, buzz, fizzbuzz and numbers. And use the for-loops setup their runtimes with fit conditions to nÂ .\nThe semaphore initial values are 0 for fizz, buzz, fizzbuzz, but setup the semaphore initial value 1 for numbers, because we know the serial start with a number, 1 to nÂ , and all conditions of fizz, buzz, fizzbuzz requires divisible by numberÂ ,at least 3Â , it will help the function number to print numbers without blocking.\nSolution from threading import Semaphore class FizzBuzz: def __init__(self, n: int): self.n = n self._lock_fz = Semaphore(0) self._lock_bz = Semaphore(0) self._lock_fzbz = Semaphore(0) self._lock_num = Semaphore(1) # printFizz() outputs \u0026#34;fizz\u0026#34; def fizz(self, printFizz: \u0026#39;Callable[[], None]\u0026#39;) -\u0026gt; None: for i in range(self.n//3-self.n//15): self._lock_fz.acquire() printFizz() self._lock_num.release() # printBuzz() outputs \u0026#34;buzz\u0026#34; def buzz(self, printBuzz: \u0026#39;Callable[[], None]\u0026#39;) -\u0026gt; None: for i in range(self.n//5-self.n//15): self._lock_bz.acquire() printBuzz() self._lock_num.release() # printFizzBuzz() outputs \u0026#34;fizzbuzz\u0026#34; def fizzbuzz(self, printFizzBuzz: \u0026#39;Callable[[], None]\u0026#39;) -\u0026gt; None: for _ in range(self.n//15): self._lock_fzbz.acquire() printFizzBuzz() self._lock_num.release() # printNumber(x) outputs \u0026#34;x\u0026#34;, where x is an integer. def number(self, printNumber: \u0026#39;Callable[[int], None]\u0026#39;) -\u0026gt; None: for i in range(1, self.n+1): self._lock_num.acquire() if i%3==0 and i%5==0: self._lock_fzbz.release() elif i%3==0: self._lock_fz.release() elif i%5==0: self._lock_bz.release() else: printNumber(i) self._lock_num.release() ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/concurrency/fizz-buzz-multithreaded/","summary":"Description You have the four functions:\nprintFizz that prints the word \u0026quot;fizz\u0026quot; to the console, printBuzz that prints the word \u0026quot;buzz\u0026quot; to the console, printFizzBuzz that prints the word \u0026quot;fizzbuzz\u0026quot; to the console, and printNumber that prints a given integer to the console. You are given an instance of the class FizzBuzz that has four functions: fizz, buzz, fizzbuzz and number. The same instance of FizzBuzz will be passed to four different threads:","title":"[leetcode][Python][Concurrency][Medium] 1195. Fizz Buzz Multithreaded"},{"content":"Description Suppose you are given the following code:\nclass FooBar { public void foo() { for (int i = 0; i \u0026lt; n; i++) { print(\u0026#34;foo\u0026#34;); } } public void bar() { for (int i = 0; i \u0026lt; n; i++) { print(\u0026#34;bar\u0026#34;); } } } The same instance of FooBar will be passed to two different threads:\nthread A will call foo(), while thread B will call bar(). Modify the given program to output \u0026quot;foobar\u0026quot; n times.\nIdea An example for output\nInput: n = 2 Output: \u0026#34;foobarfoobar\u0026#34; Explanation: \u0026#34;foobar\u0026#34; is being output 2 times. Using a flag to switch printFoo() and printBar() when acquire the lock.\nSolution from threading import Condition class FooBar: def __init__(self, n): self.n = n self._lock = Condition() self._is_printed_foo = False def foo(self, printFoo: \u0026#39;Callable[[], None]\u0026#39;) -\u0026gt; None: for i in range(self.n): with self._lock: while self._is_printed_foo: self._lock.wait() # printFoo() outputs \u0026#34;foo\u0026#34;. Do not change or remove this line. printFoo() self._is_printed_foo = True self._lock.notify_all() def bar(self, printBar: \u0026#39;Callable[[], None]\u0026#39;) -\u0026gt; None: for i in range(self.n): with self._lock: while not self._is_printed_foo: self._lock.wait() # printBar() outputs \u0026#34;bar\u0026#34;. Do not change or remove this line. printBar() self._is_printed_foo = False self._lock.notify_all() ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/concurrency/print-foobar-alternately/","summary":"Description Suppose you are given the following code:\nclass FooBar { public void foo() { for (int i = 0; i \u0026lt; n; i++) { print(\u0026#34;foo\u0026#34;); } } public void bar() { for (int i = 0; i \u0026lt; n; i++) { print(\u0026#34;bar\u0026#34;); } } } The same instance of FooBar will be passed to two different threads:\nthread A will call foo(), while thread B will call bar(). Modify the given program to output \u0026quot;foobar\u0026quot; n times.","title":"[leetcode][Python][Concurrency][Medium] 1115. Print FooBar Alternately"},{"content":"asyncio is a library to write concurrent code using the async/await syntax. ---- from Python3.11.1 documentation This article is write down the note with my study of python asyncio package.\nHow does asyncio workÂ ? The main process, which is start run by IDE or command line, have a main thread to execute submit a coroutine to asyncio event loops by asyncio.create_task() or asyncio.run()Â , the keyword async will packet methods as coroutine. The event loops will monitoring all of the submit task, and choice a not finished, current can going on coroutine to execute its task until it finish, or change status to wait when meet awaitÂ . When event loops meet awaitÂ , you should be notify (or notify all) task(s) which status is waiting for blocking, and check the blocking condition is still exist or not. Repeating above step 2 and step 3 until no more coroutines in asyncio event loops (i.e. all of the coroutine will be finish or canceled). async \u0026amp;Â await Using async to create a coroutine method Using await to call another coroutine _B_ in coroutine _A_.\n_A_ will into wait status until _B_ execute finish and notify. Using asyncio.run() to submit a coroutine Create Task \u0026amp; Submit Coroutine The asyncio.create_task() will submit a coroutine into Task Queue When await _task_1_ be execute, main thread will keep waiting until _task_1_ finish/await, and so on _task_2_ It have concurrency effect like as multi threading( or multi processing ) Timeout \u0026amp;Â Cancel Using Task.done() to determine a task is finish or not yet. Using Task.cancel() to cancel a task which is executing. Using asyncio.wait_for(task, timeout=wait_duration) for automate cancel a task if execute timeout Sometimes, we want the task keep going on their work until finish, and I just would like to know the task will happened timeout or not. For example: Counting the times of timeout to calculate performance\nGather multiÂ task Using asyncio.gather(task1, task2,Â â€¦, taskN) Add parameter return_exceptions = True capture exception result ","permalink":"https://blog.zhengweiliu.com/posts/normal/python3-asyncio/","summary":"asyncio is a library to write concurrent code using the async/await syntax.\nHow does \u003cem\u003easyncio\u003c/em\u003e workÂ ?\nasync \u0026amp;Â await,\u003cbr\u003e\nCreate Task \u0026amp; Submit Coroutine,\nTimeout \u0026amp;Â Cancel,\nGather multiÂ task\u0026hellip;","title":"Python3 - asyncio"},{"content":"Description Implement a thread-safe bounded blocking queue that has the following methods:\nBoundedBlockingQueue(int capacity) The constructor initializes the queue with a maximum capacity. void enqueue(int element) Adds an element to the front of the queue. If the queue is full, the calling thread is blocked until the queue is no longer full. int dequeue() Returns the element at the rear of the queue and removes it. If the queue is empty, the calling thread is blocked until the queue is no longer empty. int size() Returns the number of elements currently in the queue. Please do not use built-in implementations of bounded blocking queue as this will not be accepted in an interview.\nIdea Your implementation will be tested using multiple threads at the same time. Each thread will either be a producer thread that only makes calls to the enqueue method or a consumer thread that only makes calls to the dequeue method. The size method will be called after every test case.\nInput: 3 4 [\u0026#34;BoundedBlockingQueue\u0026#34;,\u0026#34;enqueue\u0026#34;,\u0026#34;enqueue\u0026#34;,\u0026#34;enqueue\u0026#34;,\u0026#34;dequeue\u0026#34;,\u0026#34;dequeue\u0026#34;,\u0026#34;dequeue\u0026#34;,\u0026#34;enqueue\u0026#34;] [[3],[1],[0],[2],[],[],[],[3]] Output: [1,0,2,1] Explanation: Number of producer threads = 3 Number of consumer threads = 4 BoundedBlockingQueue queue = new BoundedBlockingQueue(3); // initialize the queue with capacity = 3. queue.enqueue(1); // Producer thread P1 enqueues 1 to the queue. queue.enqueue(0); // Producer thread P2 enqueues 0 to the queue. queue.enqueue(2); // Producer thread P3 enqueues 2 to the queue. queue.dequeue(); // Consumer thread C1 calls dequeue. queue.dequeue(); // Consumer thread C2 calls dequeue. queue.dequeue(); // Consumer thread C3 calls dequeue. queue.enqueue(3); // One of the producer threads enqueues 3 to the queue. queue.size(); // 1 element remaining in the queue. Since the number of threads for producer/consumer is greater than 1, we do not know how the threads will be scheduled in the operating system, even though the input seems to imply the ordering. Therefore, any of the output [1,0,2] or [1,2,0] or [0,1,2] or [0,2,1] or [2,0,1] or [2,1,0] will be accepted. I guess the blocking means a task cannot going on its work when some condition cannot fit.\nIn this question, I need to design a bounded blocking queue, the queue have a capacity that meansÂ :\nCannot enqueue if queue have no remain space for element Can not dequeue when no more element in the queue The block happened when meet above situation.\nWhile the thread acquire lock, thread must be detect currently status of queueÂ :\nWaiting for next time notify if queue have not remaining space for enqueue Waiting for next time notify if queue have not any element for dequeue Solution from threading import Condition class BoundedBlockingQueue(object): def __init__(self, capacity: int): self.__capacity = capacity self.__lock = Condition() self.__queue = list() def enqueue(self, element: int) -\u0026gt; None: with self.__lock: while self.size() == self.__capacity: self.__lock.wait() self.__queue.insert(0, element) self.__lock.notify_all() def dequeue(self) -\u0026gt; int: ret = None with self.__lock: while self.size() == 0: self.__lock.wait() ret = self.__queue.pop() self.__lock.notify_all() return ret def size(self) -\u0026gt; int: return len(self.__queue) ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/concurrency/design-bounded-blocking-queue/","summary":"Description Implement a thread-safe bounded blocking queue that has the following methods:\nBoundedBlockingQueue(int capacity) The constructor initializes the queue with a maximum capacity. void enqueue(int element) Adds an element to the front of the queue. If the queue is full, the calling thread is blocked until the queue is no longer full. int dequeue() Returns the element at the rear of the queue and removes it. If the queue is empty, the calling thread is blocked until the queue is no longer empty.","title":"[leetcode][Python][Concurrency][Medium] 1188. Design Bounded Blocking Queue"},{"content":"Description Given a URL startUrl and an interface HtmlParser, implement a Multi-threaded web crawler to crawl all links that are under the same hostname as startUrl.\nReturn all URLs obtained by your web crawler in any order.\nYour crawler should:\nStart from the page: startUrl Call HtmlParser.getUrls(url) to get all URLs from a webpage of a given URL. Do not crawl the same link twice. Explore only the links that are under the same hostname as startUrl. As shown in the example URL above, the hostname is example.org. For simplicity\u0026rsquo;s sake, you may assume all URLs use HTTP protocol without any port specified. For example, the URLs http://leetcode.com/problems and http://leetcode.com/contest are under the same hostname, while URLs http://example.org/test and http://example.com/abc are not under the same hostname.\nThe HtmlParser interface is defined as such:\ninterface HtmlParser { // Return a list of all urls from a webpage of given url. // This is a blocking call, that means it will do HTTP request and return when this request is finished. public List\u0026lt;String\u0026gt; getUrls(String url); } Note that getUrls(String url) simulates performing an HTTP request. You can treat it as a blocking function call that waits for an HTTP request to finish. It is guaranteed that getUrls(String url) will return the URLs within 15ms. Single-threaded solutions will exceed the time limit so, can your multi-threaded web crawler do better?\nIdea Below are two examples explaining the functionality of the problem. For custom testing purposes, youâ€™ll have three variables urls, edges and startUrl. Notice that you will only have access to startUrl in your code, while urls and edges are not directly accessible to you in code.\nInput: urls = [ \u0026#34;http://news.yahoo.com\u0026#34;, \u0026#34;http://news.yahoo.com/news\u0026#34;, \u0026#34;http://news.yahoo.com/news/topics/\u0026#34;, \u0026#34;http://news.google.com\u0026#34;, \u0026#34;http://news.yahoo.com/us\u0026#34; ] edges = [[2,0],[2,1],[3,2],[3,1],[0,4]] startUrl = \u0026#34;http://news.yahoo.com/news/topics/\u0026#34; Output: [ \u0026#34;http://news.yahoo.com\u0026#34;, \u0026#34;http://news.yahoo.com/news\u0026#34;, \u0026#34;http://news.yahoo.com/news/topics/\u0026#34;, \u0026#34;http://news.yahoo.com/us\u0026#34; ] Be multi threading(or multi processing), Python recommend use ThreadPoolExecutor (or ProcessPoolExecutor)to protect the threads (or processes) in a safe state when it executing. And this question maybe execute under a virtual environment on leetcode platform, so I guess take the ThreadPoolExecutor is a better choice.\nSo, I write 2 methods of the class SolutionÂ , one for extract hostname from url name get_hostname(), another one for filter url which is not visited name visit_url().\nThen, using the ThreadPoolExecutor to submit task visit_url for each url which is in the queue, and call future.result() to execute each visit_url with url.\nFinally, shutdown the ThreadPoolExecutor to release resources and return a list for visit url result.\nSolution # \u0026#34;\u0026#34;\u0026#34; # This is HtmlParser\u0026#39;s API interface. # You should not implement it, or speculate about its implementation # \u0026#34;\u0026#34;\u0026#34; #class HtmlParser(object): # def getUrls(self, url): # \u0026#34;\u0026#34;\u0026#34; # :type url: str # :rtype List[str] # \u0026#34;\u0026#34;\u0026#34; from concurrent.futures import ThreadPoolExecutor from threading import Condition class Solution: def __init__(self) -\u0026gt; None: self._queue = list() self._lock = Condition() self._visited = set() def get_hostname(self, url: str): hostname = \u0026#39;.\u0026#39;.join(url.split(\u0026#39;/\u0026#39;)[2].split(\u0026#39;.\u0026#39;)[1:]) return hostname def visit_url(self, url: str): next_urls: List[str] = self._parser.getUrls(url) with self._lock: for next_url in next_urls: if next_url not in self._visited and self.current_hostname == self.get_hostname(next_url) : self._visited.add(next_url) self._queue.insert(0,next_url) def crawl(self, startUrl: str, htmlParser: \u0026#39;HtmlParser\u0026#39;) -\u0026gt; List[str]: self._queue.insert(0,startUrl) self._visited.add(startUrl) self.current_hostname = self.get_hostname(startUrl) self._parser = htmlParser executor = ThreadPoolExecutor() while self._queue: urls = [self._queue.pop(), ] while self._queue: urls.append(self._queue.pop()) excecutor_list = [executor.submit(self.visit_url, (url)) for url in urls] for future in excecutor_list: future.result() executor.shutdown() return list(self._visited) ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/concurrency/web-crawler-multithreaded/","summary":"Description Given a URL startUrl and an interface HtmlParser, implement a Multi-threaded web crawler to crawl all links that are under the same hostname as startUrl.\nReturn all URLs obtained by your web crawler in any order.\nYour crawler should:\nStart from the page: startUrl Call HtmlParser.getUrls(url) to get all URLs from a webpage of a given URL. Do not crawl the same link twice. Explore only the links that are under the same hostname as startUrl.","title":"[leetcode][Python][Concurrency][Medium] 1242. Web Crawler Multithreaded"},{"content":"Description There is an intersection of two roads. First road is road A where cars travel from North to South in direction 1 and from South to North in direction 2. Second road is road B where cars travel from West to East in direction 3 and from East to West in direction 4.\nThere is a traffic light located on each road before the intersection. A traffic light can either be green or red.\nGreen means cars can cross the intersection in both directions of the road. Red means cars in both directions cannot cross the intersection and must wait until the light turns green. The traffic lights cannot be green on both roads at the same time. That means when the light is green on road A, it is red on road B and when the light is green on road B, it is red on road A.\nInitially, the traffic light is green on road A and red on road B. When the light is green on one road, all cars can cross the intersection in both directions until the light becomes green on the other road. No two cars traveling on different roads should cross at the same time.\nDesign a deadlock-free traffic light controlled system at this intersection.\nImplement the function void carArrived(carId, roadId, direction, turnGreen, crossCar) where:\ncarId is the id of the car that arrived. roadId is the id of the road that the car travels on. direction is the direction of the car. turnGreen is a function you can call to turn the traffic light to green on the current road. crossCar is a function you can call to let the current car cross the intersection. Idea Your answer is considered correct if it avoids cars deadlock in the intersection. Turning the light green on a road when it was already green is considered a wrong answer.\nInput: cars = [1,2,3,4,5], directions = [2,4,3,3,1], arrivalTimes = [10,20,30,40,40] Output: [ \u0026#34;Car 1 Has Passed Road A In Direction 2\u0026#34;, // Traffic light on road A is green, car 1 can cross the intersection. \u0026#34;Traffic Light On Road B Is Green\u0026#34;, // Car 2 requests green light for road B. \u0026#34;Car 2 Has Passed Road B In Direction 4\u0026#34;, // Car 2 crosses as the light is green on road B now. \u0026#34;Car 3 Has Passed Road B In Direction 3\u0026#34;, // Car 3 crosses as the light is green on road B now. \u0026#34;Traffic Light On Road A Is Green\u0026#34;, // Car 5 requests green light for road A. \u0026#34;Car 5 Has Passed Road A In Direction 1\u0026#34;, // Car 5 crosses as the light is green on road A now. \u0026#34;Traffic Light On Road B Is Green\u0026#34;, // Car 4 requests green light for road B. Car 4 blocked until car 5 crosses and then traffic light is green on road B. \u0026#34;Car 4 Has Passed Road B In Direction 3\u0026#34; // Car 4 crosses as the light is green on road B now. ] Explanation: This is a dead-lock free scenario. Note that the scenario when car 4 crosses before turning light into green on road A and allowing car 5 to pass is also correct and Accepted scenario. Fulfill requirementsÂ :\nHere an important thing that which road can change the traffic control light, but also cars can pass through fast if current light is GREEN with the road their own.\nSo, change traffic control light to Green if the lock status is release, or wait it until release by notify.\nSolution from threading import Condition class TrafficLight: def __init__(self): self.__lock = Condition() self.__light = 1 def carArrived( self, carId: int, # ID of the car roadId: int, # ID of the road the car travels on. Can be 1 (road A) or 2 (road B) direction: int, # Direction of the car turnGreen: \u0026#39;Callable[[], None]\u0026#39;, # Use turnGreen() to turn light to green on current road crossCar: \u0026#39;Callable[[], None]\u0026#39; # Use crossCar() to make car cross the intersection ) -\u0026gt; None: with self.__lock: if self.__light != roadId: turnGreen() self.__light = roadId crossCar() ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/concurrency/traffic-light-controlled-intersection/","summary":"Description There is an intersection of two roads. First road is road A where cars travel from North to South in direction 1 and from South to North in direction 2. Second road is road B where cars travel from West to East in direction 3 and from East to West in direction 4.\nThere is a traffic light located on each road before the intersection. A traffic light can either be green or red.","title":"[leetcode][Python][Concurrency][Easy] 1279. Traffic Light Controlled Intersection"},{"content":"Description Table: Matches\n+-------------+------+ | Column Name | Type | +-------------+------+ | player_id | int | | match_day | date | | result | enum | +-------------+------+ (player_id, match_day) is the primary key for this table. Each row of this table contains the ID of a player, the day of the match they played, and the result of that match. The result column is an ENUM type of (\u0026#39;Win\u0026#39;, \u0026#39;Draw\u0026#39;, \u0026#39;Lose\u0026#39;). The winning streak of a player is the number of consecutive wins uninterrupted by draws or losses.\nWrite an SQL query to count the longest winning streak for each player.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Matches (player_id int, match_day date, result ENUM(\u0026#39;Win\u0026#39;, \u0026#39;Draw\u0026#39;, \u0026#39;Lose\u0026#39;)) Truncate table Matches insert into Matches (player_id, match_day, result) values (\u0026#39;1\u0026#39;, \u0026#39;2022-01-17\u0026#39;, \u0026#39;Win\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;1\u0026#39;, \u0026#39;2022-01-18\u0026#39;, \u0026#39;Win\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;1\u0026#39;, \u0026#39;2022-01-25\u0026#39;, \u0026#39;Win\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;1\u0026#39;, \u0026#39;2022-01-31\u0026#39;, \u0026#39;Draw\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;1\u0026#39;, \u0026#39;2022-02-08\u0026#39;, \u0026#39;Win\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;2\u0026#39;, \u0026#39;2022-02-06\u0026#39;, \u0026#39;Lose\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;2\u0026#39;, \u0026#39;2022-02-08\u0026#39;, \u0026#39;Lose\u0026#39;) insert into Matches (player_id, match_day, result) values (\u0026#39;3\u0026#39;, \u0026#39;2022-03-30\u0026#39;, \u0026#39;Win\u0026#39;) Idea The query result format is in the following example.\n+-----------+----------------+ | player_id | longest_streak | +-----------+----------------+ | 1 | 3 | | 2 | 0 | | 3 | 1 | +-----------+----------------+ Fulfill requirementsÂ :\nI guess that I have to extract each game result which is not a winner, and convert _a split timeline_ for each player to help calculating _longest winning streak_.\nSo, I marked each game and sorted by match_day of each player, that will help to find losing matches, then I can use it as a split timeline to calculate with win of continuous games.\nSolution with game_result_rn as ( select row_number() over(partition by player_id order by match_day) as rn, player_id, result from Matches ), player_lose_game_rn as ( select player_id, rn, ifnull(lead(rn, 1) over(partition by player_id order by rn) ,rn) as next_rn from ( select player_id, 0 as rn from game_result_rn group by player_id union select player_id, rn from game_result_rn where result \u0026lt;\u0026gt; \u0026#39;Win\u0026#39; union select player_id, max(rn)+1 as rn from game_result_rn group by player_id ) a ), count_player_win as ( select distinct a.player_id, count(result) over(partition by a.player_id, b.next_rn) as longest_streak from game_result_rn a left join player_lose_game_rn b on b.player_id=a.player_id where a.rn between b.rn and b.next_rn and a.result = \u0026#39;Win\u0026#39; ) select a.player_id, ifnull(max(b.longest_streak), 0) as longest_streak from ( select distinct player_id from Matches ) a left join count_player_win b using(player_id) group by a.player_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/longest-winning-streak/","summary":"Description Table: Matches\n+-------------+------+ | Column Name | Type | +-------------+------+ | player_id | int | | match_day | date | | result | enum | +-------------+------+ (player_id, match_day) is the primary key for this table. Each row of this table contains the ID of a player, the day of the match they played, and the result of that match. The result column is an ENUM type of (\u0026#39;Win\u0026#39;, \u0026#39;Draw\u0026#39;, \u0026#39;Lose\u0026#39;).","title":"[leetcode][Database][Hard] 2173. Longest Winning Streak"},{"content":"Description Table: Orders\n+--------------+------+ | Column Name | Type | +--------------+------+ | order_id | int | | customer_id | int | | order_date | date | | price | int | +--------------+------+ order_id is the primary key for this table. Each row contains the id of an order, the id of customer that ordered it, the date of the order, and its price. Write an SQL query to report the IDs of the customers with the total purchases strictly increasing yearly.\nThe total purchases of a customer in one year is the sum of the prices of their orders in that year. If for some year the customer did not make any order, we consider the total purchases 0. The first year to consider for each customer is the year of their first order. The last year to consider for each customer is the year of their last order. Return the result table in any order.\nSQL Schema\nCreate table If Not Exists Orders (order_id int, customer_id int, order_date date, price int) Truncate table Orders insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2019-07-01\u0026#39;, \u0026#39;1100\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2019-11-01\u0026#39;, \u0026#39;1200\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2020-05-26\u0026#39;, \u0026#39;3000\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;4\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2021-08-31\u0026#39;, \u0026#39;3100\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;5\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2022-12-07\u0026#39;, \u0026#39;4700\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;6\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2015-01-01\u0026#39;, \u0026#39;700\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;7\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2017-11-07\u0026#39;, \u0026#39;1000\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;8\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2017-01-01\u0026#39;, \u0026#39;900\u0026#39;) insert into Orders (order_id, customer_id, order_date, price) values (\u0026#39;9\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2018-11-07\u0026#39;, \u0026#39;900\u0026#39;) Idea The query result format is in the following example.\n+-------------+ | customer_id | +-------------+ | 1 | +-------------+ Fulfill requirementsÂ :\nI need to find the range between the first order year to last order year of each customer, and set price as 0 if the year have not order record(s) of customer.\nThen, I can calculate strictly increasing purchases with each year of each customer via window function lead(column, offset) over().\nMarking the calculate result 1 if the total purchase price of next year larger than current year, otherwise, marking 0Â . Name marking result as mark_increase_purchasesÂ .\nFinally, to compare the counting result of records and total mark_increase_purchases of each customer, I can get the result for customers are strictly increasing purchases or not. Due to next order after last order of each customer is not exist, so the records counting need to minus 1Â .\nSolution with recursive cte_customer_order_year as ( select customer_id, year(min(order_date)) as first_order_year, year(max(order_date)) as last_order_year from Orders group by customer_id ), cte_customer_zero_order as ( select customer_id, first_order_year, last_order_year from cte_customer_order_year union select customer_id, first_order_year+1, last_order_year from cte_customer_zero_order where first_order_year \u0026lt; last_order_year ), cte_orders as ( select distinct customer_id, year(order_date) as order_year, sum(price) over(partition by customer_id, year(order_date) order by year(order_date)) as price from ( select customer_id, makedate(first_order_year, 1) as order_date, 0 as price from cte_customer_zero_order union select customer_id, order_date, price from Orders ) union_orders ) select a.customer_id from ( select customer_id, order_year, if( lead(price, 1) over(partition by customer_id order by order_year)-price \u0026gt; 0, 1, 0 ) as mark_increase_purchases from cte_orders ) a group by a.customer_id having sum(a.mark_increase_purchases) = (count(a.customer_id)-1) ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/customers-with-strictly-increasing-purchases/","summary":"Description Table: Orders\n+--------------+------+ | Column Name | Type | +--------------+------+ | order_id | int | | customer_id | int | | order_date | date | | price | int | +--------------+------+ order_id is the primary key for this table. Each row contains the id of an order, the id of customer that ordered it, the date of the order, and its price. Write an SQL query to report the IDs of the customers with the total purchases strictly increasing yearly.","title":"[leetcode][Database][Hard] 2474. Customers With Strictly Increasing Purchases"},{"content":"Description Table: Products\n+-------------+------+ | Column Name | Type | +-------------+------+ | product_id | int | | price | int | +-------------+------+ product_id is the primary key for this table. Each row in this table shows the ID of a product and the price of one unit. Table: Purchases\n+-------------+------+ | Column Name | Type | +-------------+------+ | invoice_id | int | | product_id | int | | quantity | int | +-------------+------+ (invoice_id, product_id) is the primary key for this table. Each row in this table shows the quantity ordered from one product in an invoice. Write an SQL query to show the details of the invoice with the highest price. If two or more invoices have the same price, return the details of the one with the smallest invoice_id.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Products (product_id int, price int) Create table If Not Exists Purchases (invoice_id int, product_id int, quantity int) Truncate table Products insert into Products (product_id, price) values (\u0026#39;1\u0026#39;, \u0026#39;100\u0026#39;) insert into Products (product_id, price) values (\u0026#39;2\u0026#39;, \u0026#39;200\u0026#39;) Truncate table Purchases insert into Purchases (invoice_id, product_id, quantity) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) insert into Purchases (invoice_id, product_id, quantity) values (\u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;) insert into Purchases (invoice_id, product_id, quantity) values (\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;) insert into Purchases (invoice_id, product_id, quantity) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;4\u0026#39;) insert into Purchases (invoice_id, product_id, quantity) values (\u0026#39;4\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;) Idea The query result format is shown in the following example.\n+------------+----------+-------+ | product_id | quantity | price | +------------+----------+-------+ | 2 | 3 | 600 | | 1 | 4 | 400 | +------------+----------+-------+ Fulfill requirementsÂ :\nI used the function sum() over() to calculate totally price of each invoice, and raking the above calaulate result by sorted with invoide_id ascending, and totally pricing descending, and name ranking result as rn.\nThen, finding the record which rn equals to 1 for query result.\nSolution with cte as ( select invoice_id, product_id, quantity, price, s_price, row_number() over(order by s_price desc, invoice_id) as rn from ( select a.invoice_id, a.product_id, a.quantity, ifnull(a.quantity * b.price, 0) as price, sum(ifnull(a.quantity * b.price, 0)) over(partition by a.invoice_id) as s_price from Purchases a left join Products b using(product_id) ) detail ) select product_id, quantity, price from cte where invoice_id = (select invoice_id from cte where rn = 1) ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/generate-the-invoice/","summary":"Description Table: Products\n+-------------+------+ | Column Name | Type | +-------------+------+ | product_id | int | | price | int | +-------------+------+ product_id is the primary key for this table. Each row in this table shows the ID of a product and the price of one unit. Table: Purchases\n+-------------+------+ | Column Name | Type | +-------------+------+ | invoice_id | int | | product_id | int | | quantity | int | +-------------+------+ (invoice_id, product_id) is the primary key for this table.","title":"[leetcode][Database][Hard] 2362. Generate the Invoice"},{"content":"Description Table: Keywords\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | topic_id | int | | word | varchar | +-------------+---------+ (topic_id, word) is the primary key for this table. Each row of this table contains the id of a topic and a word that is used to express this topic. There may be more than one word to express the same topic and one word may be used to express multiple topics. Table: Posts\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | post_id | int | | content | varchar | +-------------+---------+ post_id is the primary key for this table. Each row of this table contains the ID of a post and its content. Content will consist only of English letters and spaces. Leetcode has collected some posts from its social media website and is interested in finding the topics of each post. Each topic can be expressed by one or more keywords. If a keyword of a certain topic exists in the content of a post (case insensitive) then the post has this topic.\nWrite an SQL query to find the topics of each post according to the following rules:\nIf the post does not have keywords from any topic, its topic should be \u0026quot;Ambiguous!\u0026quot;. If the post has at least one keyword of any topic, its topic should be a string of the IDs of its topics sorted in ascending order and separated by commas ','. The string should not contain duplicate IDs. Return the result table in any order.\nSQL Schema\nCreate table If Not Exists Keywords (topic_id int, word varchar(25)) Create table If Not Exists Posts (post_id int, content varchar(100)) Truncate table Keywords insert into Keywords (topic_id, word) values (\u0026#39;1\u0026#39;, \u0026#39;handball\u0026#39;) insert into Keywords (topic_id, word) values (\u0026#39;1\u0026#39;, \u0026#39;football\u0026#39;) insert into Keywords (topic_id, word) values (\u0026#39;3\u0026#39;, \u0026#39;WAR\u0026#39;) insert into Keywords (topic_id, word) values (\u0026#39;2\u0026#39;, \u0026#39;Vaccine\u0026#39;) Truncate table Posts insert into Posts (post_id, content) values (\u0026#39;1\u0026#39;, \u0026#39;We call it soccer They call it football hahaha\u0026#39;) insert into Posts (post_id, content) values (\u0026#39;2\u0026#39;, \u0026#39;Americans prefer basketball while Europeans love handball and football\u0026#39;) insert into Posts (post_id, content) values (\u0026#39;3\u0026#39;, \u0026#39;stop the war and play handball\u0026#39;) insert into Posts (post_id, content) values (\u0026#39;4\u0026#39;, \u0026#39;warning I planted some flowers this morning and then got vaccinated\u0026#39;) Idea The query result format is in the following example.\n+---------+------------+ | post_id | topic | +---------+------------+ | 1 | 1 | | 2 | 1 | | 3 | 1,3 | | 4 | Ambiguous! | +---------+------------+ Fulfill requirementsÂ :\nI guess that will maybe use the functions SUBSTRING or SUBSTRING_INDE when most people, include me, seem this question at first. But I would like to solve this question via function INSTRÂ .\nAs we can find the definition for INSTR in MySQL official documentation.\nReturns the position of the first occurrence of substring substr in string str.\nThis is the same as the two-argument form of LOCATE(),\nexcept that the order of the arguments is reversed.\nmysql \u0026gt; SELECT INSTR(\u0026#39;foobarbar\u0026#39;, \u0026#39;bar\u0026#39;); -\u0026gt; 4 mysql \u0026gt; SELECT INSTR(\u0026#39;xbar\u0026#39;, \u0026#39;foobar\u0026#39;); -\u0026gt; 0 So, in the first step, an easy way for adding two space characters as prefix and suffix for a post content, itâ€™s help to find the first/last words are keyword or not in a post content via function INSTR to use {SPACE_SYMBOL}{keyword}{SPACE_SYMBOL} as a condition.\nINSTR will return a position(or an index) of the content if a keyword in this content, but also return 0 if a keyword not in this content.\nFinally, using the table Posts as a main table in query, and using left join to associate the result from INSTR to map if topic(s) is/are in a post content. Also, replacing the topic to Ambiguous! if here havenâ€™t a topic in.\nSolution with cte_post as ( select post_id, concat(\u0026#39; \u0026#39;, content, \u0026#39; \u0026#39;) as content from Posts -- The easy way for INSTR() to find keyword ), cte_match_topics as ( select a.post_id, group_concat(distinct b.topic_id separator \u0026#39;,\u0026#39;) as topic from cte_post a, Keywords b where INSTR(a.content, concat(\u0026#39; \u0026#39;, b.word, \u0026#39; \u0026#39;)) \u0026gt; 0 -- find keyword position group by a.post_id ) select distinct(a.post_id), ifnull(b.topic, \u0026#39;Ambiguous!\u0026#39;) as topic from Posts a left join cte_match_topics b using(post_id) order by 1 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/finding-the-topic-of-each-post/","summary":"Description Table: Keywords\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | topic_id | int | | word | varchar | +-------------+---------+ (topic_id, word) is the primary key for this table. Each row of this table contains the id of a topic and a word that is used to express this topic. There may be more than one word to express the same topic and one word may be used to express multiple topics.","title":"[leetcode][Database][Hard] 2199. Finding the Topic of Each Post"},{"content":"Description Table: Candidates\n+-------------+------+ | Column Name | Type | +-------------+------+ | employee_id | int | | experience | enum | | salary | int | +-------------+------+ employee_id is the primary key column for this table. experience is an enum with one of the values (\u0026#39;Senior\u0026#39;, \u0026#39;Junior\u0026#39;). Each row of this table indicates the id of a candidate, their monthly salary, and their experience. The salary of each candidate is guaranteed to be unique. A company wants to hire new employees. The budget of the company for the salaries is $70000. The company\u0026rsquo;s criteria for hiring are:\nKeep hiring the senior with the smallest salary until you cannot hire any more seniors. Use the remaining budget to hire the junior with the smallest salary. Keep hiring the junior with the smallest salary until you cannot hire any more juniors. Write an SQL query to find the ids of seniors and juniors hired under the mentioned criteria.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Candidates (employee_id int, experience ENUM(\u0026#39;Senior\u0026#39;, \u0026#39;Junior\u0026#39;), salary int) Truncate table Candidates insert into Candidates (employee_id, experience, salary) values (\u0026#39;1\u0026#39;, \u0026#39;Junior\u0026#39;, \u0026#39;10000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;9\u0026#39;, \u0026#39;Junior\u0026#39;, \u0026#39;15000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;2\u0026#39;, \u0026#39;Senior\u0026#39;, \u0026#39;20000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;11\u0026#39;, \u0026#39;Senior\u0026#39;, \u0026#39;16000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;13\u0026#39;, \u0026#39;Senior\u0026#39;, \u0026#39;50000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;4\u0026#39;, \u0026#39;Junior\u0026#39;, \u0026#39;40000\u0026#39;) Idea The query result format is in the following example.\n+-------------+ | employee_id | +-------------+ | 11 | | 2 | | 1 | | 9 | +-------------+ Fulfill requirementsÂ :\nThe thinking process like as [leetcode][Database][Hard] 2004. The Number of Seniors and Juniors to Join the Company.\nSo we can calculating the cumulative salary, sorted the salary of each employee and partition by different experience at first.\nNext, finding the max cumulative salary which less than budget $70,000 and take employee_id which are fitting the above condition. Also, finding the junior employees by remaining budget from hired senior employees.\nSolution with salary_cumulative as ( select employee_id, experience, salary, sum(salary) over(partition by experience order by salary) as cumulative_salary from Candidates ), senior_hiring as ( select -1 as employee_id, 0 as cumulative_salary union select employee_id, cumulative_salary from salary_cumulative where experience = \u0026#39;Senior\u0026#39; and 70000 - cumulative_salary \u0026gt;=0 ), junior_hiring as ( select employee_id from salary_cumulative join ( select 70000-max(cumulative_salary) as remaining from senior_hiring ) senior where experience = \u0026#39;Junior\u0026#39; and remaining-cumulative_salary\u0026gt;=0 ) select employee_id from senior_hiring where employee_id \u0026gt; 0 union select employee_id from junior_hiring ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/the-number-of-seniors-and-juniors-to-join-the-company-ii/","summary":"Description Table: Candidates\n+-------------+------+ | Column Name | Type | +-------------+------+ | employee_id | int | | experience | enum | | salary | int | +-------------+------+ employee_id is the primary key column for this table. experience is an enum with one of the values (\u0026#39;Senior\u0026#39;, \u0026#39;Junior\u0026#39;). Each row of this table indicates the id of a candidate, their monthly salary, and their experience. The salary of each candidate is guaranteed to be unique.","title":"[leetcode][Database][Hard] 2010. The Number of Seniors and Juniors to Join the Company II"},{"content":"Description Table: Terms\n+-------------+------+ | Column Name | Type | +-------------+------+ | power | int | | factor | int | +-------------+------+ power is the primary key column for this table. Each row of this table contains information about one term of the equation. power is an integer in the range [0, 100]. factor is an integer in the range [-100, 100] and cannot be zero. You have a very powerful program that can solve any equation of one variable in the world. The equation passed to the program must be formatted as follows:\nThe left-hand side (LHS) should contain all the terms. The right-hand side (RHS) should be zero. Each term of the LHS should follow the format \u0026quot;\u0026lt;sign\u0026gt;\u0026lt;fact\u0026gt;X^\u0026lt;pow\u0026gt;\u0026quot; where:\n\u0026lt;sign\u0026gt; is either \u0026quot;+\u0026quot; or \u0026quot;-\u0026quot;.\n\u0026lt;fact\u0026gt; is the absolute value of the factor.\n\u0026lt;pow\u0026gt; is the value of the power. If the power is 1, do not add \u0026quot;^\u0026lt;pow\u0026gt;\u0026quot;.\nFor example, if power = 1 and factor = 3, the term will be \u0026quot;+3X\u0026quot;. If the power is 0, add neither \u0026quot;X\u0026quot; nor \u0026quot;^\u0026lt;pow\u0026gt;\u0026quot;.\nFor example, if power = 0 and factor = -3, the term will be \u0026quot;-3\u0026quot;. The powers in the LHS should be sorted in descending order. Write an SQL query to build the equation.\nSQL Schema\nCreate table If Not Exists Terms (power int, factor int) Truncate table Terms insert into Terms (power, factor) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;) insert into Terms (power, factor) values (\u0026#39;1\u0026#39;, \u0026#39;-4\u0026#39;) insert into Terms (power, factor) values (\u0026#39;0\u0026#39;, \u0026#39;2\u0026#39;) Idea The query result format is in the following example.\n+-----------------+ | equation | +-----------------+ | -4X^4+1X^2-1X=0 | +-----------------+ Fulfill requirementsÂ :\nFor generating the equation by records of table TermsÂ , it can be reorganize to a few parts of a term {factor sign}{absolute factor value}{power of X sign}{power value}Â For exampleÂ :\nTerm will be present -4X when the record.factor=-4Â , record.power=1Â Term will be present +2x^4 when the record.factor=2Â , record.power=4Â Term will be present +1 when the record.factor=1Â , record.power=0 Finally, using the function group_concat() combainating all of the terms from reorganize.\nSolution with builder as ( select 0 as LHS, -1 as rk, \u0026#39;=0\u0026#39; as e union select 0 as LHS, row_number() over(order by power) rk, concat( if(factor \u0026gt;0, \u0026#39;+\u0026#39;, \u0026#39;-\u0026#39;), -- factor sign abs(factor), -- remove factor sign of the value if(power=0, \u0026#39;\u0026#39;, if(power=1, \u0026#39;X\u0026#39;, \u0026#39;X^\u0026#39;) ), -- power of X if(power\u0026lt;2, \u0026#39;\u0026#39;, power) -- show power text when power large than 2 ) e from Terms ) select group_concat( e order by rk desc separator \u0026#39;\u0026#39; ) as equation from builder group by LHS ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/build-the-equation/","summary":"Description Table: Terms\n+-------------+------+ | Column Name | Type | +-------------+------+ | power | int | | factor | int | +-------------+------+ power is the primary key column for this table. Each row of this table contains information about one term of the equation. power is an integer in the range [0, 100]. factor is an integer in the range [-100, 100] and cannot be zero. You have a very powerful program that can solve any equation of one variable in the world.","title":"[leetcode][Database][Hard] 2118. Build the Equation"},{"content":"Description Table: Products\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | product_id | int | | store_name1 | int | | store_name2 | int | | : | int | | : | int | | : | int | | store_namen | int | +-------------+---------+ product_id is the primary key for this table. Each row in this table indicates the product\u0026#39;s price in n different stores. If the product is not available in a store, the price will be null in that store\u0026#39;s column. The names of the stores may change from one testcase to another. There will be at least 1 store and at most 30 stores. Important note: This problem targets those who have a good experience with SQL. If you are a beginner, we recommend that you skip it for now.\nImplement the procedure UnpivotProducts to reorganize the Products table so that each row has the id of one product, the name of a store where it is sold, and its price in that store. If a product is not available in a store, do not include a row with that product_id and store combination in the result table. There should be three columns: product_id, store, and price.\nThe procedure should return the table after reorganizing it.\nReturn the result table in any order.\nSQL Schema\nTruncate table Products insert into Products (product_id, LC_Store, Nozama, Shop, Souq) values (\u0026#39;1\u0026#39;, \u0026#39;100\u0026#39;, \u0026#39;None\u0026#39;, \u0026#39;110\u0026#39;, \u0026#39;None\u0026#39;) insert into Products (product_id, LC_Store, Nozama, Shop, Souq) values (\u0026#39;2\u0026#39;, \u0026#39;None\u0026#39;, \u0026#39;200\u0026#39;, \u0026#39;None\u0026#39;, \u0026#39;190\u0026#39;) insert into Products (product_id, LC_Store, Nozama, Shop, Souq) values (\u0026#39;3\u0026#39;, \u0026#39;None\u0026#39;, \u0026#39;None\u0026#39;, \u0026#39;1000\u0026#39;, \u0026#39;1900\u0026#39;) Idea The query result format is in the following example.\n+------------+----------+-------+ | product_id | store | price | +------------+----------+-------+ | 1 | LC_Store | 100 | | 1 | Shop | 110 | | 2 | Nozama | 200 | | 2 | Souq | 190 | | 3 | Shop | 1000 | | 3 | Souq | 1900 | +------------+----------+-------+ Refer bofeng07\u0026rsquo;s MySQL solution, it a grate idea!\nGetting the column names of table Products from information_schema.columns, using group_concat to combian each column values of each row of table Products by unionÂ .\nSolution CREATE PROCEDURE UnpivotProducts() BEGIN set session group_concat_max_len = 1000000; set @macro = null; select group_concat( concat( \u0026#39;select product_id, \u0026#34;\u0026#39;, column_name, \u0026#39;\u0026#34; as store, \u0026#39;, column_name, \u0026#39; as price \u0026#39;, \u0026#39;from Products \u0026#39;, \u0026#39;where \u0026#39;, column_name, \u0026#39; is not null\u0026#39; ) separator \u0026#39; union \u0026#39; ) into @macro from information_schema.columns where table_schema=\u0026#39;test\u0026#39; and table_name=\u0026#39;Products\u0026#39; and column_name != \u0026#39;product_id\u0026#39;; prepare sql_query from @macro; execute sql_query; deallocate prepare sql_query; END ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/dynamic-unpivoting-of-a-table/","summary":"Description Table: Products\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | product_id | int | | store_name1 | int | | store_name2 | int | | : | int | | : | int | | : | int | | store_namen | int | +-------------+---------+ product_id is the primary key for this table. Each row in this table indicates the product\u0026#39;s price in n different stores. If the product is not available in a store, the price will be null in that store\u0026#39;s column.","title":"[leetcode][Database][Hard]2253. Dynamic Unpivoting of a Table"},{"content":"Description Table: Listens\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | song_id | int | | day | date | +-------------+---------+ There is no primary key for this table. It may contain duplicates. Each row of this table indicates that the user user_id listened to the song song_id on the day day. Table: Friendship\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user1_id | int | | user2_id | int | +---------------+---------+ (user1_id, user2_id) is the primary key for this table. Each row of this table indicates that the users user1_id and user2_id are friends. Note that user1_id \u0026lt; user2_id. Write an SQL query to report the similar friends of Leetcodify users. A user x and user y are similar friends if:\nUsers x and y are friends, and Users x and y listened to the same three or more different songs on the same day. Return the result table in any order. Note that you must return the similar pairs of friends the same way they were represented in the input (i.e., always user1_id \u0026lt; user2_id).\nSQL Schema\nCreate table If Not Exists Listens (user_id int, song_id int, day date) Create table If Not Exists Friendship (user1_id int, user2_id int) Truncate table Listens insert into Listens (user_id, song_id, day) values (\u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;1\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;1\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;2\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;2\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;2\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;3\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;3\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;3\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;4\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;4\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;4\u0026#39;, \u0026#39;13\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;5\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-16\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;5\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-16\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;5\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-16\u0026#39;) Truncate table Friendship insert into Friendship (user1_id, user2_id) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;2\u0026#39;, \u0026#39;5\u0026#39;) Idea The query result format is in the following example.\n+----------+----------+ | user1_id | user2_id | +----------+----------+ | 1 | 2 | +----------+----------+ Fulfill requirementsÂ :\nThe thinking process like as [leetcode][Database][Hard] 1917. Leetcodify Friends Recommendations, the different is this question asking to find similar friend (i.e. user x and user y have a pair record in Friendship).\nSo, we can do that with the same logic to find user x and user y are listened to the same three or more different songs on the same day or not.\nListing each user and their friends cte_user_friendsÂ . To avoid the records that user listen the same song in a day, using the distinct to remove duplicates records. Finally, counting the song_id via group by day, user_id, recommended_id, and filtering the counting song_id value large than or equals to 3 after group by statement.\nSolution with cte_user_friends as ( select user1_id as user1_id, user2_id as user2_id from Friendship union select user2_id as user1_id, user1_id as user2_id from Friendship ), cte_listen_distinct as ( select distinct user_id, song_id , day from Listens ), cte_similar_friend as ( select a.user_id as user1_id, b.user_id as user2_id from cte_listen_distinct a # user1 left join cte_listen_distinct b on b.song_id=a.song_id and a.day=b.day # user2 left join cte_user_friends c on c.user1_id = a.user_id and c.user2_id = b.user_id where a.user_id \u0026lt;\u0026gt; b.user_id and user1_id is not null group by a.day, a.user_id, b.user_id having count(a.song_id) \u0026gt;=3 ) select distinct b.user1_id, b.user2_id from Friendship a join cte_similar_friend b on b.user1_id = a.user1_id and b.user2_id = a.user2_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/leetcodify-similar-friends/","summary":"Description Table: Listens\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | song_id | int | | day | date | +-------------+---------+ There is no primary key for this table. It may contain duplicates. Each row of this table indicates that the user user_id listened to the song song_id on the day day. Table: Friendship\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user1_id | int | | user2_id | int | +---------------+---------+ (user1_id, user2_id) is the primary key for this table.","title":"[leetcode][Database][Hard] 1919. Leetcodify Similar Friends"},{"content":"Description Table: Listens\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | song_id | int | | day | date | +-------------+---------+ There is no primary key for this table. It may contain duplicates. Each row of this table indicates that the user user_id listened to the song song_id on the day day. Table: Friendship\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user1_id | int | | user2_id | int | +---------------+---------+ (user1_id, user2_id) is the primary key for this table. Each row of this table indicates that the users user1_id and user2_id are friends. Note that user1_id \u0026lt; user2_id. Write an SQL query to recommend friends to Leetcodify users. We recommend user x to user y if:\nUsers x and y are not friends, and Users x and y listened to the same three or more different songs on the same day. Note that friend recommendations are unidirectional, meaning if user x and user y should be recommended to each other, the result table should have both user x recommended to user y and user y recommended to user x. Also, note that the result table should not contain duplicates (i.e., user y should not be recommended to user x multiple times.).\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Listens (user_id int, song_id int, day date) Create table If Not Exists Friendship (user1_id int, user2_id int) Truncate table Listens insert into Listens (user_id, song_id, day) values (\u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;1\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;1\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;2\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;2\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;2\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;3\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;3\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;3\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;4\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;4\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;4\u0026#39;, \u0026#39;13\u0026#39;, \u0026#39;2021-03-15\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;5\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2021-03-16\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;5\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-03-16\u0026#39;) insert into Listens (user_id, song_id, day) values (\u0026#39;5\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;2021-03-16\u0026#39;) Truncate table Friendship insert into Friendship (user1_id, user2_id) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) Idea The query result format is in the following example.\n+---------+----------------+ | user_id | recommended_id | +---------+----------------+ | 1 | 3 | | 2 | 3 | | 3 | 1 | | 3 | 2 | +---------+----------------+ Fulfill requirementsÂ :\nThe thinking process like as [leetcode][Database][Hard] 1892. Page Recommendations II, so the first step is listing each user and their friends cte_user_friendsÂ .\nTo avoid the records that user listen the same song in a day, using the distinct to remove duplicates records.\nFinding the users listening a song in a day via self join cte_listen_distinctÂ , and then confirm the user friendship who in above self join set and remove them.\nFinally, counting the song_id via group by day, user_id, recommended_id, and filtering the counting song_id value large than or equals to 3 after group by statement.\nSolution with cte_user_friends as ( select user1_id as user_id, user2_id as friend_id from Friendship union select user2_id as user_id, user1_id as friend_id from Friendship ), cte_listen_distinct as ( select distinct user_id, song_id, day from Listens ) select distinct a.user_id, b.user_id as recommended_id from cte_listen_distinct a left join cte_listen_distinct b on b.song_id=a.song_id and a.day=b.day left join cte_user_friends c on c.user_id = a.user_id and c.friend_id = b.user_id where c.user_id is null and a.user_id \u0026lt;\u0026gt; b.user_id group by a.day, a.user_id, b.user_id having count(a.song_id) \u0026gt;=3 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/leetcodify-friends-recommendations/","summary":"Description Table: Listens\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | song_id | int | | day | date | +-------------+---------+ There is no primary key for this table. It may contain duplicates. Each row of this table indicates that the user user_id listened to the song song_id on the day day. Table: Friendship\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user1_id | int | | user2_id | int | +---------------+---------+ (user1_id, user2_id) is the primary key for this table.","title":"[leetcode][Database][Hard] 1917. Leetcodify Friends Recommendations"},{"content":"Description Table: Friendship\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user1_id | int | | user2_id | int | +---------------+---------+ (user1_id, user2_id) is the primary key for this table. Each row of this table indicates that the users user1_id and user2_id are friends. Table: Likes\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | page_id | int | +-------------+---------+ (user_id, page_id) is the primary key for this table. Each row of this table indicates that user_id likes page_id. You are implementing a page recommendation system for a social media website. Your system will recommended a page to user_id if the page is liked by at least one friend of user_id and is not liked by user_id.\nWrite an SQL query to find all the possible page recommendations for every user. Each recommendation should appear as a row in the result table with these columns:\nuser_id: The ID of the user that your system is making the recommendation to. page_id: The ID of the page that will be recommended to user_id. friends_likes: The number of the friends of user_id that like page_id. Return result table in any order.\nSQL Schema\nCreate table If Not Exists Friendship (user1_id int, user2_id int) Create table If Not Exists Likes (user_id int, page_id int) Truncate table Friendship insert into Friendship (user1_id, user2_id) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;1\u0026#39;, \u0026#39;4\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;2\u0026#39;, \u0026#39;5\u0026#39;) insert into Friendship (user1_id, user2_id) values (\u0026#39;6\u0026#39;, \u0026#39;1\u0026#39;) Truncate table Likes insert into Likes (user_id, page_id) values (\u0026#39;1\u0026#39;, \u0026#39;88\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;2\u0026#39;, \u0026#39;23\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;3\u0026#39;, \u0026#39;24\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;4\u0026#39;, \u0026#39;56\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;5\u0026#39;, \u0026#39;11\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;6\u0026#39;, \u0026#39;33\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;2\u0026#39;, \u0026#39;77\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;3\u0026#39;, \u0026#39;77\u0026#39;) insert into Likes (user_id, page_id) values (\u0026#39;6\u0026#39;, \u0026#39;88\u0026#39;) Idea The query result format is in the following example.\n+---------+---------+---------------+ | user_id | page_id | friends_likes | +---------+---------+---------------+ | 1 | 77 | 2 | | 1 | 23 | 1 | | 1 | 24 | 1 | | 1 | 56 | 1 | | 1 | 33 | 1 | | 2 | 24 | 1 | | 2 | 56 | 1 | | 2 | 11 | 1 | | 2 | 88 | 1 | | 3 | 88 | 1 | | 3 | 23 | 1 | | 4 | 88 | 1 | | 4 | 77 | 1 | | 4 | 23 | 1 | | 5 | 77 | 1 | | 5 | 23 | 1 | +---------+---------+---------------+ Fulfill requirementsÂ :\nThe thinking process like as [leetcode][Database][Hard]1972. First and Last Call On the Same Day, so the first step is listing each user and their friends cte_all_users.\nFinding the pages which are friends likes, then to find which pages both user and friends likes. Finally, filtering not match the conditionÂ : the page user not liked but friends did.\nThis solution have same concept with minus or except, finding the difference set between both user and friends likes pages and only friends like pages.\nSolution with cte_all_users as ( select user1_id as user_id, user2_id as friend from Friendship union select user2_id as user_id, user1_id as friend from Friendship ) select distinct a.user_id, b.page_id , count(a.friend) as friends_likes from cte_all_users a join Likes b on b.user_id = a.friend -- find the pages friend like left join Likes c on c.user_id = a.user_id and b.page_id = c.page_id -- find the pages both user and friend like where c.page_id is null -- filtering not match the condition : the page user not liked but friends did. group by a.user_id, b.page_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/page-recommendations-ii/","summary":"Description Table: Friendship\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user1_id | int | | user2_id | int | +---------------+---------+ (user1_id, user2_id) is the primary key for this table. Each row of this table indicates that the users user1_id and user2_id are friends. Table: Likes\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | page_id | int | +-------------+---------+ (user_id, page_id) is the primary key for this table.","title":"[leetcode][Database][Hard] 1892. Page Recommendations II"},{"content":"Description Table: Tasks\n+----------------+---------+ | Column Name | Type | +----------------+---------+ | task_id | int | | subtasks_count | int | +----------------+---------+ task_id is the primary key for this table. Each row in this table indicates that task_id was divided into subtasks_count subtasks labeled from 1 to subtasks_count. It is guaranteed that 2 \u0026lt;= subtasks_count \u0026lt;= 20. Table: Executed\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | task_id | int | | subtask_id | int | +---------------+---------+ (task_id, subtask_id) is the primary key for this table. Each row in this table indicates that for the task task_id, the subtask with ID subtask_id was executed successfully. It is guaranteed that subtask_id \u0026lt;= subtasks_count for each task_id. Write an SQL query to report the IDs of the missing subtasks for each task_id.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Tasks (task_id int, subtasks_count int) Create table If Not Exists Executed (task_id int, subtask_id int) Truncate table Tasks insert into Tasks (task_id, subtasks_count) values (\u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;) insert into Tasks (task_id, subtasks_count) values (\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;) insert into Tasks (task_id, subtasks_count) values (\u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;) Truncate table Executed insert into Executed (task_id, subtask_id) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) insert into Executed (task_id, subtask_id) values (\u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;) insert into Executed (task_id, subtask_id) values (\u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;) insert into Executed (task_id, subtask_id) values (\u0026#39;3\u0026#39;, \u0026#39;3\u0026#39;) insert into Executed (task_id, subtask_id) values (\u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;) Idea The query result format is in the following example.\n+---------+------------+ | task_id | subtask_id | +---------+------------+ | 1 | 1 | | 1 | 3 | | 2 | 1 | | 2 | 2 | +---------+------------+ Fulfill requirementsÂ :\nUsing the with recursive to generate a serial number for subtasks_id from 1 to 20, then finding not executed subtasks with condition ifnull(task_id) or ifnull(subtask_id) which subtask_id records not in table Executed.\nSolution with recursive cte_subtasks_sn as ( SELECT 1 AS subtask_id UNION ALL SELECT subtask_id + 1 FROM cte_subtasks_sn WHERE subtask_id \u0026lt; 20 ), cte_subtasks_count as ( select a.task_id as task_id, b.subtask_id as subtask_id from Tasks a, cte_subtasks_sn b where b.subtask_id \u0026lt;= a.subtasks_count ) select a.task_id, a.subtask_id from cte_subtasks_count a left join Executed b using(task_id, subtask_id) where ifnull(b.task_id, -1) = -1 or ifnull(b.subtask_id, -1) = -1 order by task_id, subtask_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/find-the-subtasks-that-did-not-execute/","summary":"Description Table: Tasks\n+----------------+---------+ | Column Name | Type | +----------------+---------+ | task_id | int | | subtasks_count | int | +----------------+---------+ task_id is the primary key for this table. Each row in this table indicates that task_id was divided into subtasks_count subtasks labeled from 1 to subtasks_count. It is guaranteed that 2 \u0026lt;= subtasks_count \u0026lt;= 20. Table: Executed\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | task_id | int | | subtask_id | int | +---------------+---------+ (task_id, subtask_id) is the primary key for this table.","title":"[leetcode][Database][Hard] 1767. Find the Subtasks That Did Not Execute"},{"content":"Description Table: Drivers\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | driver_id | int | | join_date | date | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver\u0026#39;s ID and the date they joined the Hopper company. Table: Rides\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | ride_id | int | | user_id | int | | requested_at | date | +--------------+---------+ ride_id is the primary key for this table. Each row of this table contains the ID of a ride, the user\u0026#39;s ID that requested it, and the day they requested it. There may be some ride requests in this table that were not accepted. Table: AcceptedRides\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | ride_id | int | | driver_id | int | | ride_distance | int | | ride_duration | int | +---------------+---------+ ride_id is the primary key for this table. Each row of this table contains some information about an accepted ride. It is guaranteed that each accepted ride exists in the Rides table. Write an SQL query to compute the average_ride_distance and average_ride_duration of every 3-month window starting from January - March 2020 to October - December 2020. Round average_ride_distance and average_ride_duration to the nearest two decimal places.\nThe average_ride_distance is calculated by summing up the total ride_distance values from the three months and dividing it by 3. The average_ride_duration is calculated in a similar way.\nReturn the result table ordered by month in ascending order, where month is the starting month\u0026rsquo;s number (January is 1, February is 2, etc.).\nSQL Schema\nCreate table If Not Exists Drivers (driver_id int, join_date date) Create table If Not Exists Rides (ride_id int, user_id int, requested_at date) Create table If Not Exists AcceptedRides (ride_id int, driver_id int, ride_distance int, ride_duration int) Truncate table Drivers insert into Drivers (driver_id, join_date) values (\u0026#39;10\u0026#39;, \u0026#39;2019-12-10\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;8\u0026#39;, \u0026#39;2020-1-13\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;5\u0026#39;, \u0026#39;2020-2-16\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;7\u0026#39;, \u0026#39;2020-3-8\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;4\u0026#39;, \u0026#39;2020-5-17\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;1\u0026#39;, \u0026#39;2020-10-24\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;6\u0026#39;, \u0026#39;2021-1-5\u0026#39;) Truncate table Rides insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;6\u0026#39;, \u0026#39;75\u0026#39;, \u0026#39;2019-12-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;1\u0026#39;, \u0026#39;54\u0026#39;, \u0026#39;2020-2-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;10\u0026#39;, \u0026#39;63\u0026#39;, \u0026#39;2020-3-4\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;19\u0026#39;, \u0026#39;39\u0026#39;, \u0026#39;2020-4-6\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;3\u0026#39;, \u0026#39;41\u0026#39;, \u0026#39;2020-6-3\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;13\u0026#39;, \u0026#39;52\u0026#39;, \u0026#39;2020-6-22\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;7\u0026#39;, \u0026#39;69\u0026#39;, \u0026#39;2020-7-16\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;17\u0026#39;, \u0026#39;70\u0026#39;, \u0026#39;2020-8-25\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;20\u0026#39;, \u0026#39;81\u0026#39;, \u0026#39;2020-11-2\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;5\u0026#39;, \u0026#39;57\u0026#39;, \u0026#39;2020-11-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;2\u0026#39;, \u0026#39;42\u0026#39;, \u0026#39;2020-12-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;11\u0026#39;, \u0026#39;68\u0026#39;, \u0026#39;2021-1-11\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;15\u0026#39;, \u0026#39;32\u0026#39;, \u0026#39;2021-1-17\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;12\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-1-19\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;14\u0026#39;, \u0026#39;18\u0026#39;, \u0026#39;2021-1-27\u0026#39;) Truncate table AcceptedRides insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;10\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;63\u0026#39;, \u0026#39;38\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;13\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;73\u0026#39;, \u0026#39;96\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;100\u0026#39;, \u0026#39;28\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;17\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;119\u0026#39;, \u0026#39;68\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;20\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;121\u0026#39;, \u0026#39;92\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;5\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;42\u0026#39;, \u0026#39;101\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;38\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;11\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;37\u0026#39;, \u0026#39;43\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;15\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;108\u0026#39;, \u0026#39;82\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;12\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;38\u0026#39;, \u0026#39;34\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;14\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;90\u0026#39;, \u0026#39;74\u0026#39;) Idea The query result format is in the following example.\n+-------+-----------------------+-----------------------+ | month | average_ride_distance | average_ride_duration | +-------+-----------------------+-----------------------+ | 1 | 21.00 | 12.67 | | 2 | 21.00 | 12.67 | | 3 | 21.00 | 12.67 | | 4 | 24.33 | 32.00 | | 5 | 57.67 | 41.33 | | 6 | 97.33 | 64.00 | | 7 | 73.00 | 32.00 | | 8 | 39.67 | 22.67 | | 9 | 54.33 | 64.33 | | 10 | 56.33 | 77.00 | +-------+-----------------------+-----------------------+ Fulfill requirementsÂ :\nBefore all, I would like to share a problem for timeout limit exceeded of this question when I submit my solution. Because of the pervious solution, I used subquery in select column statement to calculate average distance and average duration.\nSo, Iâ€™m learned when the query statement meet a large dataset, the subquery will spending more process resource to calculate its.\nFor the above reason, I modifying the output query used function lead() getting next two months distance and duration for each row instead of subquery. From the response of submissions, itâ€™s worked and improve the query performance.\nSolution with cte_month as ( select 1 as month union select 2 as month union select 3 as month union select 4 as month union select 5 as month union select 6 as month union select 7 as month union select 8 as month union select 9 as month union select 10 as month union select 11 as month union select 12 as month ), cte_accepted_rides as ( select c.month, sum(c.distance) as distance, sum(c.duration) as duration from ( select month(b.requested_at) as month, a.ride_distance as distance, a.ride_duration as duration from AcceptedRides a join Rides b using(ride_id) where year(b.requested_at) = 2020 ) c group by c.month ), cte_ride_info as ( select a.month, ifnull(b.distance, 0) as m0_distance, ifnull(b.duration, 0) as m0_duration, ifnull(lead(b.distance, 1) over(order by a.month), 0) as m1_distance, ifnull(lead(b.duration, 1) over(order by a.month), 0) as m1_duration, ifnull(lead(b.distance, 2) over(order by a.month), 0) as m2_distance, ifnull(lead(b.duration, 2) over(order by a.month), 0) as m2_duration from cte_month a left join cte_accepted_rides b on b.month = a.month ) select distinct(a.month), round((m0_distance + m1_distance + m2_distance ) / 3, 2) as average_ride_distance, round((m0_duration + m1_duration + m2_duration ) / 3, 2) as average_ride_duration from cte_ride_info a where a.month \u0026lt;= 10 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/hopper-company-queries-iii/","summary":"Description Table: Drivers\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | driver_id | int | | join_date | date | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver\u0026#39;s ID and the date they joined the Hopper company. Table: Rides\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | ride_id | int | | user_id | int | | requested_at | date | +--------------+---------+ ride_id is the primary key for this table.","title":"[leetcode][Database][Hard] 1651. Hopper Company Queries III"},{"content":"Description Table: Drivers\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | driver_id | int | | join_date | date | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver\u0026#39;s ID and the date they joined the Hopper company. Table: Rides\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | ride_id | int | | user_id | int | | requested_at | date | +--------------+---------+ ride_id is the primary key for this table. Each row of this table contains the ID of a ride, the user\u0026#39;s ID that requested it, and the day they requested it. There may be some ride requests in this table that were not accepted. Table: AcceptedRides\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | ride_id | int | | driver_id | int | | ride_distance | int | | ride_duration | int | +---------------+---------+ ride_id is the primary key for this table. Each row of this table contains some information about an accepted ride. It is guaranteed that each accepted ride exists in the Rides table. Write an SQL query to report the percentage of working drivers (working_percentage) for each month of 2020 where:\nNote that if the number of available drivers during a month is zero, we consider the working_percentage to be 0.\nReturn the result table ordered by month in ascending order, where month is the month\u0026rsquo;s number (January is 1, February is 2, etc.). Round working_percentage to the nearest 2 decimal places.\nSQL Schema\nCreate table If Not Exists Drivers (driver_id int, join_date date) Create table If Not Exists Rides (ride_id int, user_id int, requested_at date) Create table If Not Exists AcceptedRides (ride_id int, driver_id int, ride_distance int, ride_duration int) Truncate table Drivers insert into Drivers (driver_id, join_date) values (\u0026#39;10\u0026#39;, \u0026#39;2019-12-10\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;8\u0026#39;, \u0026#39;2020-1-13\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;5\u0026#39;, \u0026#39;2020-2-16\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;7\u0026#39;, \u0026#39;2020-3-8\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;4\u0026#39;, \u0026#39;2020-5-17\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;1\u0026#39;, \u0026#39;2020-10-24\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;6\u0026#39;, \u0026#39;2021-1-5\u0026#39;) Truncate table Rides insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;6\u0026#39;, \u0026#39;75\u0026#39;, \u0026#39;2019-12-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;1\u0026#39;, \u0026#39;54\u0026#39;, \u0026#39;2020-2-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;10\u0026#39;, \u0026#39;63\u0026#39;, \u0026#39;2020-3-4\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;19\u0026#39;, \u0026#39;39\u0026#39;, \u0026#39;2020-4-6\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;3\u0026#39;, \u0026#39;41\u0026#39;, \u0026#39;2020-6-3\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;13\u0026#39;, \u0026#39;52\u0026#39;, \u0026#39;2020-6-22\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;7\u0026#39;, \u0026#39;69\u0026#39;, \u0026#39;2020-7-16\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;17\u0026#39;, \u0026#39;70\u0026#39;, \u0026#39;2020-8-25\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;20\u0026#39;, \u0026#39;81\u0026#39;, \u0026#39;2020-11-2\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;5\u0026#39;, \u0026#39;57\u0026#39;, \u0026#39;2020-11-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;2\u0026#39;, \u0026#39;42\u0026#39;, \u0026#39;2020-12-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;11\u0026#39;, \u0026#39;68\u0026#39;, \u0026#39;2021-1-11\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;15\u0026#39;, \u0026#39;32\u0026#39;, \u0026#39;2021-1-17\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;12\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-1-19\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;14\u0026#39;, \u0026#39;18\u0026#39;, \u0026#39;2021-1-27\u0026#39;) Truncate table AcceptedRides insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;10\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;63\u0026#39;, \u0026#39;38\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;13\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;73\u0026#39;, \u0026#39;96\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;100\u0026#39;, \u0026#39;28\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;17\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;119\u0026#39;, \u0026#39;68\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;20\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;121\u0026#39;, \u0026#39;92\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;5\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;42\u0026#39;, \u0026#39;101\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;38\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;11\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;37\u0026#39;, \u0026#39;43\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;15\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;108\u0026#39;, \u0026#39;82\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;12\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;38\u0026#39;, \u0026#39;34\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;14\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;90\u0026#39;, \u0026#39;74\u0026#39;) Idea The query result format is in the following example.\n+-------+--------------------+ | month | working_percentage | +-------+--------------------+ | 1 | 0.00 | | 2 | 0.00 | | 3 | 25.00 | | 4 | 0.00 | | 5 | 0.00 | | 6 | 20.00 | | 7 | 20.00 | | 8 | 20.00 | | 9 | 0.00 | | 10 | 0.00 | | 11 | 33.33 | | 12 | 16.67 | +-------+--------------------+ Fulfill requirementsÂ :\nThe thinking process like as [leetcode][Database][Hard] 1635. Hopper Company Queries IÂ , cumulating available drivers by month who join date less than year 2021.\nItâ€™s only different to counting _drivers that accepted at least one of each month_ in table AcceptedRides and table Rides instead of ride records.\nSolution with cte_month as ( select 1 as month union select 2 as month union select 3 as month union select 4 as month union select 5 as month union select 6 as month union select 7 as month union select 8 as month union select 9 as month union select 10 as month union select 11 as month union select 12 as month ), cte_monthly_drivers as ( select driver_id, if(year(join_date) \u0026lt; 2020, 1, month(join_date)) as month from Drivers where year(join_date) \u0026lt;= 2020 ), cte_monthly_rides as ( select distinct(a.month), count(a.driver_id) over(partition by a.month) as accepted_ride_drivers from ( select distinct(driver_id) as driver_id, month(b.requested_at) as month from AcceptedRides a join Rides b using (ride_id) where year(b.requested_at) = 2020 ) a ) select opt.month, if( opt.available_drivers=0, 0, round((accepted_ride_drivers / opt.available_drivers)*100, 2) ) as working_percentage from ( select distinct(a.month), count(b.driver_id) over(order by a.month) as available_drivers, ifnull(c.accepted_ride_drivers, 0) as accepted_ride_drivers from cte_month a left join cte_monthly_drivers b on b.month = a.month left join cte_monthly_rides c on c.month = a.month ) opt ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/hopper-company-queries-ii/","summary":"Description Table: Drivers\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | driver_id | int | | join_date | date | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver\u0026#39;s ID and the date they joined the Hopper company. Table: Rides\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | ride_id | int | | user_id | int | | requested_at | date | +--------------+---------+ ride_id is the primary key for this table.","title":"[leetcode][Database][Hard] 1645. Hopper Company Queries II"},{"content":"Description Table: Drivers\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | driver_id | int | | join_date | date | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver\u0026#39;s ID and the date they joined the Hopper company. Table: Rides\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | ride_id | int | | user_id | int | | requested_at | date | +--------------+---------+ ride_id is the primary key for this table. Each row of this table contains the ID of a ride, the user\u0026#39;s ID that requested it, and the day they requested it. There may be some ride requests in this table that were not accepted. Table: AcceptedRides\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | ride_id | int | | driver_id | int | | ride_distance | int | | ride_duration | int | +---------------+---------+ ride_id is the primary key for this table. Each row of this table contains some information about an accepted ride. It is guaranteed that each accepted ride exists in the Rides table. Write an SQL query to report the following statistics for each month of 2020:\nThe number of drivers currently with the Hopper company by the end of the month (active_drivers). The number of accepted rides in that month (accepted_rides). Return the result table ordered by month in ascending order, where month is the month\u0026rsquo;s number (January is 1, February is 2, etc.).\nSQL Schema\nCreate table If Not Exists Drivers (driver_id int, join_date date) Create table If Not Exists Rides (ride_id int, user_id int, requested_at date) Create table If Not Exists AcceptedRides (ride_id int, driver_id int, ride_distance int, ride_duration int) Truncate table Drivers insert into Drivers (driver_id, join_date) values (\u0026#39;10\u0026#39;, \u0026#39;2019-12-10\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;8\u0026#39;, \u0026#39;2020-1-13\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;5\u0026#39;, \u0026#39;2020-2-16\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;7\u0026#39;, \u0026#39;2020-3-8\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;4\u0026#39;, \u0026#39;2020-5-17\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;1\u0026#39;, \u0026#39;2020-10-24\u0026#39;) insert into Drivers (driver_id, join_date) values (\u0026#39;6\u0026#39;, \u0026#39;2021-1-5\u0026#39;) Truncate table Rides insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;6\u0026#39;, \u0026#39;75\u0026#39;, \u0026#39;2019-12-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;1\u0026#39;, \u0026#39;54\u0026#39;, \u0026#39;2020-2-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;10\u0026#39;, \u0026#39;63\u0026#39;, \u0026#39;2020-3-4\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;19\u0026#39;, \u0026#39;39\u0026#39;, \u0026#39;2020-4-6\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;3\u0026#39;, \u0026#39;41\u0026#39;, \u0026#39;2020-6-3\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;13\u0026#39;, \u0026#39;52\u0026#39;, \u0026#39;2020-6-22\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;7\u0026#39;, \u0026#39;69\u0026#39;, \u0026#39;2020-7-16\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;17\u0026#39;, \u0026#39;70\u0026#39;, \u0026#39;2020-8-25\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;20\u0026#39;, \u0026#39;81\u0026#39;, \u0026#39;2020-11-2\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;5\u0026#39;, \u0026#39;57\u0026#39;, \u0026#39;2020-11-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;2\u0026#39;, \u0026#39;42\u0026#39;, \u0026#39;2020-12-9\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;11\u0026#39;, \u0026#39;68\u0026#39;, \u0026#39;2021-1-11\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;15\u0026#39;, \u0026#39;32\u0026#39;, \u0026#39;2021-1-17\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;12\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-1-19\u0026#39;) insert into Rides (ride_id, user_id, requested_at) values (\u0026#39;14\u0026#39;, \u0026#39;18\u0026#39;, \u0026#39;2021-1-27\u0026#39;) Truncate table AcceptedRides insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;10\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;63\u0026#39;, \u0026#39;38\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;13\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;73\u0026#39;, \u0026#39;96\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;100\u0026#39;, \u0026#39;28\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;17\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;119\u0026#39;, \u0026#39;68\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;20\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;121\u0026#39;, \u0026#39;92\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;5\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;42\u0026#39;, \u0026#39;101\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;38\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;11\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;37\u0026#39;, \u0026#39;43\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;15\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;108\u0026#39;, \u0026#39;82\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;12\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;38\u0026#39;, \u0026#39;34\u0026#39;) insert into AcceptedRides (ride_id, driver_id, ride_distance, ride_duration) values (\u0026#39;14\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;90\u0026#39;, \u0026#39;74\u0026#39;) Idea The query result format is in the following example.\n+-------+----------------+----------------+ | month | active_drivers | accepted_rides | +-------+----------------+----------------+ | 1 | 2 | 0 | | 2 | 3 | 0 | | 3 | 4 | 1 | | 4 | 4 | 0 | | 5 | 5 | 0 | | 6 | 5 | 1 | | 7 | 5 | 1 | | 8 | 5 | 1 | | 9 | 5 | 0 | | 10 | 6 | 0 | | 11 | 6 | 2 | | 12 | 6 | 1 | +-------+----------------+----------------+ Fulfill requirements:\nThe output, it apparently show the computed result of each month. So, we can generate a monthly table that month range between 1 (Jan) to 12 (Dec) as a main table in the query statement, then cumulating the active drivers and counting the accepted rides of each month by left join.\nSolution with cte_month as ( select 1 as month union select 2 as month union select 3 as month union select 4 as month union select 5 as month union select 6 as month union select 7 as month union select 8 as month union select 9 as month union select 10 as month union select 11 as month union select 12 as month ), cte_drivers as ( select driver_id, join_date, if(year(join_date)\u0026lt;2020, 2020, year(join_date)) as join_year, if(year(join_date)\u0026lt;2020, 1, month(join_date)) as join_month from Drivers where year(join_date) \u0026lt;= 2020 ), cte_accepted_rides as ( select distinct(month(b.requested_at)) as month, count(ride_id) over(partition by month(b.requested_at)) as accepted_rides from AcceptedRides a join Rides b using(ride_id) where year(b.requested_at)=2020 ) select distinct(a.month) as month, count(b.driver_id) over(order by a.month) as active_drivers, ifnull(c.accepted_rides, 0) as accepted_rides from cte_month a left join cte_drivers b on b.join_month = a.month left join cte_accepted_rides c on c.month = a.month ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/hopper-company-queries-i/","summary":"Description Table: Drivers\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | driver_id | int | | join_date | date | +-------------+---------+ driver_id is the primary key for this table. Each row of this table contains the driver\u0026#39;s ID and the date they joined the Hopper company. Table: Rides\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | ride_id | int | | user_id | int | | requested_at | date | +--------------+---------+ ride_id is the primary key for this table.","title":"[leetcode][Database][Hard] 1635. Hopper Company Queries I"},{"content":"Description Table: Student\n+---------------------+---------+ | Column Name | Type | +---------------------+---------+ | student_id | int | | student_name | varchar | +---------------------+---------+ student_id is the primary key for this table. student_name is the name of the student. Table: Exam\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | exam_id | int | | student_id | int | | score | int | +---------------+---------+ (exam_id, student_id) is the primary key for this table. Each row of this table indicates that the student with student_id had a score points in the exam with id exam_id. A quiet student is the one who took at least one exam and did not score the high or the low score.\nWrite an SQL query to report the students (student_id, student_name) being quiet in all exams. Do not return the student who has never taken any exam.\nReturn the result table ordered by student_id.\nSQL Schema\nCreate table If Not Exists Student (student_id int, student_name varchar(30)) Create table If Not Exists Exam (exam_id int, student_id int, score int) Truncate table Student insert into Student (student_id, student_name) values (\u0026#39;1\u0026#39;, \u0026#39;Daniel\u0026#39;) insert into Student (student_id, student_name) values (\u0026#39;2\u0026#39;, \u0026#39;Jade\u0026#39;) insert into Student (student_id, student_name) values (\u0026#39;3\u0026#39;, \u0026#39;Stella\u0026#39;) insert into Student (student_id, student_name) values (\u0026#39;4\u0026#39;, \u0026#39;Jonathan\u0026#39;) insert into Student (student_id, student_name) values (\u0026#39;5\u0026#39;, \u0026#39;Will\u0026#39;) Truncate table Exam insert into Exam (exam_id, student_id, score) values (\u0026#39;10\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;70\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;10\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;80\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;10\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;90\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;20\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;80\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;30\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;70\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;30\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;80\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;30\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;90\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;40\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;60\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;40\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;70\u0026#39;) insert into Exam (exam_id, student_id, score) values (\u0026#39;40\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;80\u0026#39;) Idea The query result format is in the following example.\n+-------------+---------------+ | student_id | student_name | +-------------+---------------+ | 2 | Jade | +-------------+---------------+ It has easy way to find quiet students by ranking score of each exam, getting best and worst rank of each exam, marking best and worst for each student of each exam if they are best score or worst score at the exam.\nFinally, listing the students who never got best mark and worst mark of all exam.\nSolution with rank_score_of_exam as ( select a.exam_id, a.student_id, b.student_name, dense_rank() over(partition by a.exam_id order by a.score) as score_rk from exam a left join student b using(student_id) ), rank_of_exam as ( select exam_id, max(score_rk) as high, min(score_rk) as low from rank_score_of_exam group by exam_id ), mark_best as ( select a.exam_id, a.student_id, a.student_name, if(a.score_rk=b.high, 1, 0) as mark from rank_score_of_exam a left join rank_of_exam b using(exam_id) ), mark_worst as ( select a.exam_id, a.student_id, a.student_name, if(a.score_rk=b.low, 1, 0) as mark from rank_score_of_exam a left join rank_of_exam b using(exam_id) ) select student_id, student_name from ( select exam_id, student_id, student_name, mark from mark_best union all select exam_id, student_id, student_name, mark from mark_worst ) opt group by student_id, student_name having sum(mark) = 0 order by student_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/find-the-quiet-students-in-all-exams/","summary":"Description Table: Student\n+---------------------+---------+ | Column Name | Type | +---------------------+---------+ | student_id | int | | student_name | varchar | +---------------------+---------+ student_id is the primary key for this table. student_name is the name of the student. Table: Exam\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | exam_id | int | | student_id | int | | score | int | +---------------+---------+ (exam_id, student_id) is the primary key for this table.","title":"[leetcode][Database][Hard] 1412. Find the Quiet Students in All Exams"},{"content":"Description Table: UserActivity\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | username | varchar | | activity | varchar | | startDate | Date | | endDate | Date | +---------------+---------+ There is no primary key for this table. It may contain duplicates. This table contains information about the activity performed by each user in a period of time. A person with username performed an activity from startDate to endDate. Write an SQL query to show the second most recent activity of each user.\nIf the user only has one activity, return that one. A user cannot perform more than one activity at the same time.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists UserActivity (username varchar(30), activity varchar(30), startDate date, endDate date) Truncate table UserActivity insert into UserActivity (username, activity, startDate, endDate) values (\u0026#39;Alice\u0026#39;, \u0026#39;Travel\u0026#39;, \u0026#39;2020-02-12\u0026#39;, \u0026#39;2020-02-20\u0026#39;) insert into UserActivity (username, activity, startDate, endDate) values (\u0026#39;Alice\u0026#39;, \u0026#39;Dancing\u0026#39;, \u0026#39;2020-02-21\u0026#39;, \u0026#39;2020-02-23\u0026#39;) insert into UserActivity (username, activity, startDate, endDate) values (\u0026#39;Alice\u0026#39;, \u0026#39;Travel\u0026#39;, \u0026#39;2020-02-24\u0026#39;, \u0026#39;2020-02-28\u0026#39;) insert into UserActivity (username, activity, startDate, endDate) values (\u0026#39;Bob\u0026#39;, \u0026#39;Travel\u0026#39;, \u0026#39;2020-02-11\u0026#39;, \u0026#39;2020-02-18\u0026#39;) Idea The query result format is in the following example.\n+------------+--------------+-------------+-------------+ | username | activity | startDate | endDate | +------------+--------------+-------------+-------------+ | Alice | Dancing | 2020-02-21 | 2020-02-23 | | Bob | Travel | 2020-02-11 | 2020-02-18 | +------------+--------------+-------------+-------------+ Fulfill requirementsÂ :\nTo generate a rank table order by endDate of each user via function rank()as rn. It will help to find user who has at least twice activity records in table UserActivity.\nName this with clause as rank_end_date. Find _second mostly recent activity_ record of each user from rand_end_date. User will be missing who has only one activity record.\nName this with clause as activity_twice. Find users who has only once activity record of table UserActivity. Using left join activity_twice to rule out users who has been listing in twice_record.\nName this with clause as activity_onceÂ . Finally, union the result of activity_twice and twice_record for output of the query. Solution with rank_end_date as ( select rank() over(partition by username order by endDate desc) as rn, username, activity, startDate, endDate from useractivity ), activity_twice as ( select rn, username, activity, startDate, endDate from rank_end_date where rn = 2 ), activity_once as ( select a.rn, a.username, a.activity, a.startDate, a.endDate from rank_end_date a left join activity_twice b using(username) where ifnull(b.rn, 0) = 0 ) select username, activity, startDate, endDate from activity_once union select username, activity, startDate, endDate from activity_twice ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/get-the-second-most-recent-activity/","summary":"Description Table: UserActivity\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | username | varchar | | activity | varchar | | startDate | Date | | endDate | Date | +---------------+---------+ There is no primary key for this table. It may contain duplicates. This table contains information about the activity performed by each user in a period of time. A person with username performed an activity from startDate to endDate.","title":"[leetcode][Database][Hard] 1369. Get the Second Most Recent Activity"},{"content":"Description Table: Visits\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user_id | int | | visit_date | date | +---------------+---------+ (user_id, visit_date) is the primary key for this table. Each row of this table indicates that user_id has visited the bank in visit_date. Table: Transactions\n+------------------+---------+ | Column Name | Type | +------------------+---------+ | user_id | int | | transaction_date | date | | amount | int | +------------------+---------+ There is no primary key for this table, it may contain duplicates. Each row of this table indicates that user_id has done a transaction of amount in transaction_date. It is guaranteed that the user has visited the bank in the transaction_date.(i.e The Visits table contains (user_id, transaction_date) in one row) A bank wants to draw a chart of the number of transactions bank visitors did in one visit to the bank and the corresponding number of visitors who have done this number of transaction in one visit.\nWrite an SQL query to find how many users visited the bank and didnâ€™t do any transactions, how many visited the bank and did one transaction and so on.\nThe result table will contain two columns:\ntransactions_count which is the number of transactions done in one visit. visits_count which is the corresponding number of users who did transactions_count in one visit to the bank. transactions_count should take all values from 0 to max(transactions_count) done by one or more users.\nReturn the result table ordered by transactions_count.\nSQL Schema\nCreate table If Not Exists Visits (user_id int, visit_date date) Create table If Not Exists Transactions (user_id int, transaction_date date, amount int) Truncate table Visits insert into Visits (user_id, visit_date) values (\u0026#39;1\u0026#39;, \u0026#39;2020-01-01\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;2\u0026#39;, \u0026#39;2020-01-02\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;12\u0026#39;, \u0026#39;2020-01-01\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;19\u0026#39;, \u0026#39;2020-01-03\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;1\u0026#39;, \u0026#39;2020-01-02\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;2\u0026#39;, \u0026#39;2020-01-03\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;1\u0026#39;, \u0026#39;2020-01-04\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;7\u0026#39;, \u0026#39;2020-01-11\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;9\u0026#39;, \u0026#39;2020-01-25\u0026#39;) insert into Visits (user_id, visit_date) values (\u0026#39;8\u0026#39;, \u0026#39;2020-01-28\u0026#39;) Truncate table Transactions insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;1\u0026#39;, \u0026#39;2020-01-02\u0026#39;, \u0026#39;120\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;2\u0026#39;, \u0026#39;2020-01-03\u0026#39;, \u0026#39;22\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;7\u0026#39;, \u0026#39;2020-01-11\u0026#39;, \u0026#39;232\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;1\u0026#39;, \u0026#39;2020-01-04\u0026#39;, \u0026#39;7\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;9\u0026#39;, \u0026#39;2020-01-25\u0026#39;, \u0026#39;33\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;9\u0026#39;, \u0026#39;2020-01-25\u0026#39;, \u0026#39;66\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;8\u0026#39;, \u0026#39;2020-01-28\u0026#39;, \u0026#39;1\u0026#39;) insert into Transactions (user_id, transaction_date, amount) values (\u0026#39;9\u0026#39;, \u0026#39;2020-01-25\u0026#39;, \u0026#39;99\u0026#39;) Idea The output requires result table contains 2 columnsÂ : transactions_count and visits_countÂ , but also the column transactions_count range between 0 to max(transactions_count). Finally, output the result table ordered by transactions_count.\nfor example:\n+--------------------+--------------+ | transactions_count | visits_count | +--------------------+--------------+ | 0 | 4 | | 1 | 5 | | 2 | 0 | | 3 | 1 | +--------------------+--------------+ Fultill requirements:\nGenerate a serial number table start with 0 by function row_number() of transactions table due to max(transactions_count) should be less tahn or equals to the number of records of transactions table.\nName this with clause as snÂ . Compute the transactions_count from records of transactions table, where the records matches the user_id from visits table, but also the transaction_date in visit_date.Â Name this with clause asÂ . Joint sn and cte_1, where row_number() of sn should be less than or equals tomax(cte_1.transactions_count)Â .Â It will help to confirm all of sn.rn rows where thesn.rn less than or equals tothan max(cte_1.transactions_count) should be in result table, because the cte_1 will not include row if the visits_count are zero times.\nName this with clause as cte_2. Finally, named column visits_count for counting how many users group by cte_2.transactions_countÂ , and output it. Solution with sn as ( select row_number() over() -1 rn from transactions ), cte_1 as ( select a.user_id, a.visit_date, count(b.transaction_date)as transactions_count from visits a left join transactions b on b.user_id = a.user_id and b.transaction_date = a.visit_date group by a.user_id, a.visit_date ), cte_2 as ( select user_id, visit_date, transactions_count from cte_1 union all select null, null, rn from sn where rn \u0026lt; (select max(transactions_count) from cte_1) ) select transactions_count, count(user_id) as visits_count from cte_2 group by transactions_count order by transactions_count ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/number-of-transactions-per-visit/","summary":"Description Table: Visits\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | user_id | int | | visit_date | date | +---------------+---------+ (user_id, visit_date) is the primary key for this table. Each row of this table indicates that user_id has visited the bank in visit_date. Table: Transactions\n+------------------+---------+ | Column Name | Type | +------------------+---------+ | user_id | int | | transaction_date | date | | amount | int | +------------------+---------+ There is no primary key for this table, it may contain duplicates.","title":"[leetcode][Database][Hard] 1336. Number of Transactions per Visit"},{"content":"è¨˜éŒ„åœ¨éå»é¢è©¦ä¸­å¸¸è¢«å•åˆ°çš„å•é¡Œï¼Œä»¥åŠä¾æ“šè‡ªå·±çš„ç†è§£èˆ‡æŸ¥æ‰¾åˆ°çš„è³‡æ–™ï¼Œæ•´ç†å°æ‡‰çš„å›è¦†\nQ1. K8s æœ‰å“ªäº› componentsÂ ?\nMaster Node â† ç®¡ç† clusterã€å„²å­˜ä¸åŒ node çš„è³‡è¨Šã€è¦åŠƒ containers çš„å»å‘ï¼Œä»¥åŠ monitor node ä¸Šçš„ containers\nkube-apiserver â† ç®¡ç†æ•´å€‹ K8s çš„ interfaceã€‚ä½¿ç”¨è€…å¯ä»¥é€éä¸‹é”æŒ‡ä»¤çµ¦ kube-apiserver ï¼Œä»¥é”åˆ°ç®¡ç† K8s resources çš„ç›®çš„ã€‚ etcd cluster â† å„²å­˜ K8s cluster å…§ï¼Œæ‰€æœ‰ node ã€ containers çš„è³‡è¨Š kube-scheduler â† ä¾æ“š containers çš„éœ€æ±‚ï¼ŒåŒ…å«ä½†ä¸é™æ–¼: cpuã€ menoryã€ affinity ã€ taints and tolerations ã€anti-* ç­‰ç­‰ï¼Œè¦åŠƒå°‡ containers æŒ‡æ´¾çµ¦ç¬¦åˆéœ€æ±‚çš„ nodeã€‚ controller manager â† ç®¡æ§ K8s cluster å…§çš„ resources ã€‚\nå¦‚ node controller ç®¡ç† nodesÂ : åŠ å…¥æ–° node åˆ° clusterã€è™•ç† node è®Šçš„ä¸å¯ç”¨çš„ç‹€æ³ Work Nodes â† è¨—ç®¡åŸ·è¡Œæ‡‰ç”¨çš„ containers\nkubelet â† K8s cluster åœ¨ work nodes ä¸Šçš„ä»£ç†ï¼Œåµè½ kube-apiserver çš„æŒ‡ä»¤ï¼Œä¸¦ä¾æ“šéœ€æ±‚éƒ¨ç½²æˆ–éŠ·æ¯€ containersã€‚ kube-apiserver é€±æœŸæ€§çš„å¾kubelet ç²å– work node å’Œ containers çš„ç‹€æ…‹ã€‚ kube-proxy â† è®“ work node ä¹‹é–“çš„ containers å¯ä»¥äº’ç›¸æºé€šã€‚ container runtime engine â† åŸ·è¡ŒåŒ…å«æ‡‰ç”¨çš„ containers Q2. éƒ¨ç½²ä¸€å€‹æ‡‰ç”¨åˆ° K8s æ™‚ï¼ŒK8s æœƒå¦‚ä½•é‹ä½œæ•´å€‹æµç¨‹Â ?\nUser ç™¼é€ deploy request çµ¦ kube-apiserverã€‚kube-apiserver é©—è­‰ User ä¸¦é©—è­‰æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ requestã€‚ å°‡æœ‰æ•ˆçš„ request æ›´æ–°åˆ° ETCDã€‚ ETCD å›è¦† kube-apiserver æ›´æ–°å·²å®Œæˆã€‚ kube-scheduler æœƒæŒçºŒç›£æ¸¬ kube-apiserverï¼Œæ­¤æ™‚ç™¼ç¾æœ‰ä¸€å€‹æ–°çš„ pod é‚„æ²’æœ‰è¢«æŒ‡æ´¾åˆ° work nodeï¼Œ kube-scheduler æœƒé¸æ“‡ç¬¦åˆæ¢ä»¶çš„ work nodeã€‚ kube-scheduler é€šçŸ¥ kube-apiserver ï¼Œè¦ç•«å°‡æ–°çš„ pod åˆ†é…åˆ°æŒ‡å®šçš„ work nodeã€‚ kube-apiserver é€šçŸ¥ work node ä¸Šçš„ kubeletï¼Œæœ‰æ–°çš„ pod éœ€è¦éƒ¨ç½²åˆ° work node ä¸Šã€‚ kubelet å˜—è©¦å°‡æ–°çš„ pod éƒ¨ç½²åˆ° work node ä¸Šï¼Œä¸¦æŒçºŒç›£æ¸¬ pod çš„ç‹€æ…‹ã€‚ æ–°çš„ pod é–‹å§‹éƒ¨ç½²åˆ° work node ã€‚ æ–°çš„ pod éƒ¨ç½²å®Œæˆã€‚ kubelet ç›£æ¸¬åˆ° pod å·²éƒ¨ç½² (ä½†ä¸ä¿è­‰ pod ä¸Šçš„æ‡‰ç”¨åŸ·è¡Œæ˜¯å¦æˆåŠŸ)ã€‚ kubelet é€šçŸ¥ kube-apiserver æ–°çš„ pod å·²éƒ¨ç½²åˆ° work nodeã€‚ kube-apiserver å°‡ pod éƒ¨ç½²è³‡è¨Šæ›´æ–°åˆ° ETCD ã€‚ ETCD å›è¦† kube-apiserver æ›´æ–°å·²å®Œæˆã€‚ kube-apiserver å›è¦† User æ–°çš„ pod å·²éƒ¨ç½²åˆ° work nodeã€‚ Q3. å°æ–¼åœ¨ K8s ä¸Šå»ºç½®æ­£å¼ç’°å¢ƒ (Product) å’Œæ¸¬è©¦ç’°å¢ƒ (Development)çš„è¦åŠƒ\nåœ¨ K8s åˆ†åˆ¥å»ºç«‹ Product å’Œ Development çš„ namespaceï¼Œä¸¦å¯é€éæŒ‡ä»¤ kubectl apply -f {YAML file} -n [ Product | Development ] ï¼Œå°‡éœ€è¦çš„ resources éƒ¨ç½²åˆ°å°æ‡‰çš„ namespace ã€‚ è‹¥éœ€è¦æ¬Šé™ç®¡ç†ï¼Œå‰‡é€é RBAC é€²è¡Œè¨­ç½®ã€‚æˆ‘å¸¸è¦‹çš„ä½œæ³•æ˜¯å…ˆå»ºç«‹ K8s çš„ service account ã€å»ºç«‹ Role æˆ– ClusterRole ä¸¦è¨­å®šå¯æ“ä½œçš„ resources èˆ‡å°æ‡‰çš„ verbsï¼Œæœ€å¾Œé€é RoleBinding æˆ– ClusterRoleBinding å°‡ service account å’Œ Role(æˆ–ClusterRole)é€²è¡Œç¶å®šã€‚ ","permalink":"https://blog.zhengweiliu.com/posts/normal/kubernetes/","summary":"è¨˜éŒ„åœ¨éå»é¢è©¦ä¸­å¸¸è¢«å•åˆ°çš„å•é¡Œï¼Œä»¥åŠä¾æ“šè‡ªå·±çš„ç†è§£èˆ‡æŸ¥æ‰¾åˆ°çš„è³‡æ–™ï¼Œæ•´ç†å°æ‡‰çš„å›è¦†\nQ1. K8s æœ‰å“ªäº› componentsÂ ?\nQ2. éƒ¨ç½²ä¸€å€‹æ‡‰ç”¨åˆ° K8s æ™‚ï¼ŒK8s æœƒå¦‚ä½•é‹ä½œæ•´å€‹æµç¨‹Â ?\nQ3. å°æ–¼åœ¨ K8s ä¸Šå»ºç½®æ­£å¼ç’°å¢ƒ (Product) å’Œæ¸¬è©¦ç’°å¢ƒ (Development)çš„è¦åŠƒ","title":"æ•´ç†é¢è©¦å¸¸è¦‹å•é¡Œâ€Šâ€”â€ŠKubernetes"},{"content":"é¡Œç›® Table: Failed\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | fail_date | date | +--------------+---------+ fail_date is the primary key for this table. This table contains the days of failed tasks. Table: Succeeded\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | success_date | date | +--------------+---------+ success_date is the primary key for this table. This table contains the days of succeeded tasks. A system is running one task every day. Every task is independent of the previous tasks. The tasks can fail or succeed.\nWrite an SQL query to generate a report of period_state for each continuous interval of days in the period from 2019-01-01 to 2019-12-31.\nperiod_state is \u0026rsquo;failed' if tasks in this interval failed or 'succeeded' if tasks in this interval succeeded. Interval of days are retrieved as start_date and end_date.\nReturn the result table ordered by start_date.\nSQL Schema\nCreate table If Not Exists Failed (fail_date date) Create table If Not Exists Succeeded (success_date date) Truncate table Failed insert into Failed (fail_date) values (\u0026#39;2018-12-28\u0026#39;) insert into Failed (fail_date) values (\u0026#39;2018-12-29\u0026#39;) insert into Failed (fail_date) values (\u0026#39;2019-01-04\u0026#39;) insert into Failed (fail_date) values (\u0026#39;2019-01-05\u0026#39;) Truncate table Succeeded insert into Succeeded (success_date) values (\u0026#39;2018-12-30\u0026#39;) insert into Succeeded (success_date) values (\u0026#39;2018-12-31\u0026#39;) insert into Succeeded (success_date) values (\u0026#39;2019-01-01\u0026#39;) insert into Succeeded (success_date) values (\u0026#39;2019-01-02\u0026#39;) insert into Succeeded (success_date) values (\u0026#39;2019-01-03\u0026#39;) insert into Succeeded (success_date) values (\u0026#39;2019-01-06\u0026#39;) è§£é¡Œæ€è€ƒ (Variable ç‰ˆæœ¬) é¡Œç›®è¦æ±‚è¼¸å‡º period_state ã€ start_date å’Œ end_date æ¬„ä½çš„è¡¨æ ¼ã€‚\nå…¶ä¸­å°‡é€£çºŒæ—¥æœŸéƒ½ç‚ºç›¸åŒ state çš„å®šç¾©ç‚ºä¸€å€‹ periodï¼Œä¸” start_date å’Œ end_date å°‡è¡¨ç¤ºè©² period çš„èµ·å§‹æ—¥æœŸå’ŒçµæŸæ—¥æœŸã€‚\n+--------------+--------------+--------------+ | period_state | start_date | end_date | +--------------+--------------+--------------+ | succeeded | 2019-01-01 | 2019-01-03 | | failed | 2019-01-04 | 2019-01-05 | | succeeded | 2019-01-06 | 2019-01-06 | +--------------+--------------+--------------+ æœ€é–‹å§‹ï¼Œæˆ‘çš„æƒ³æ³•æ˜¯åˆ©ç”¨ variableï¼Œåœ¨æ¯æ¬¡ period_state è®Šæ›æ™‚ï¼Œé€éè®Šæ•¸å°‡è©² period_stateç¬¬ä¸€å€‹æ—¥æœŸä½œç‚ºéŒ¨é» anchor ï¼Œå†ä½¿ç”¨ rank() å° start_date åšå‡åºæ’åº rnã€‚ é€é with clause å»ºç«‹ status è¡¨æ ¼ï¼Œè¯åˆ Failed è¡¨æ ¼å’Œ Successed è¡¨æ ¼ï¼Œç¯©é¸å‡º fail_date ã€ success_date ä»‹æ–¼ 2019â€“01â€“01 è‡³ 2019-12-31 çš„è³‡æ–™é›†ã€‚ é€é with clause å»ºç«‹ date_anchor è¡¨æ ¼ï¼Œæ“´å¢ anchor_dateæ¬„ä½ä»¥ä¾¿å¾ŒçºŒæ‰¾å‡º end_date ã€‚\nvariable current_state â† å„²å­˜ç•¶å‰ record çš„ period_state\nvariable date_anchor â† å„²å­˜ç•¶å‰ period çš„ç¬¬ä¸€å€‹æ—¥æœŸ\né€éå­æŸ¥è©¢åˆå§‹åŒ– variable current_state å’Œ variable date_anchor æŸ¥è©¢ date_anchor ä»¥å»ºç«‹å­æŸ¥è©¢è¡¨æ ¼ a ã€‚\nå­æŸ¥è©¢è¡¨æ ¼ä¸­ï¼Œåˆ©ç”¨ rank() å° start_date åšå‡åºï¼Œä»¥æ¨™è¨˜æ’åºçµæœ rn ã€‚ä¸¦åˆ©ç”¨ max(start_date) over(partition by anchor_date) å–å¾—æ¯å€‹ period ä¸­æœ€å¤§çš„ start_date ï¼Œå³è©² period çš„ end_date ã€‚ æŸ¥è©¢ a ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œåˆ©ç”¨ group by end_date å’Œ having min(rn) ä»¥ç¯©é¸å‡ºç¬¦åˆè¼¸å‡ºæ¢ä»¶çš„è³‡æ–™ã€‚ è§£æ±ºæ–¹æ¡ˆ (Variable ç‰ˆæœ¬) with status as ( select period_state, start_date from ( select fail_date as start_date, \u0026#39;failed\u0026#39; as period_state from Failed union all select success_date as start_date, \u0026#39;succeeded\u0026#39; as period_state from Succeeded ) tmp where start_date between \u0026#39;2019-01-01\u0026#39; and \u0026#39;2019-12-31\u0026#39; order by start_date ), date_anchor as ( select period_state, start_date, anchor_date from( select a.period_state, a.start_date, if(@current_state=a.period_state, @date_anchor, a.start_date) as anchor_date, if(@current_state=a.period_state, @date_anchor, @date_anchor:=a.start_date), @current_state:=a.period_state from status a, (select @current_state:=\u0026#34;initial\u0026#34;, @date_anchor:=\u0026#34;2018-12-31\u0026#34;) init ) anchor ) select a.period_state, a.start_date, a.end_date from ( select period_state, start_date, max(start_date) over(partition by anchor_date) as end_date, rank() over(order by start_date) rn from date_anchor ) a group by end_date having min(rn) order by start_date è§£é¡Œæ€è€ƒ (Rankç‰ˆæœ¬) åœ¨æäº¤äº† variable ç‰ˆæœ¬å¾Œï¼Œç™¼ç¾é€£çºŒæ—¥æœŸåœ¨æ’åºå¾Œï¼Œå…¶ rn ç­‰å·®ç‚º 1 ï¼Œé€™è¡¨ç¤ºæ¯æ¬¡ period_state è®Šæ›æ™‚ï¼Œå–ç¬¬ä¸€å€‹æ—¥æœŸä½œç‚ºè©² period çš„æœ€å°å€¼ï¼Œå‰‡è©² period ä¸­æ‰€æœ‰è³‡æ–™éƒ½æ‡‰ç¬¦åˆ start_date-rn=min(start_date) çš„æ¢ä»¶ï¼Œå› æ­¤åˆå¯«äº†ä¸€å€‹ Rank ç‰ˆæœ¬ã€‚ é€é with clause åˆ†åˆ¥å»ºç«‹ failed_state ã€ successeded_stateè¡¨æ ¼ã€‚\nç¯©é¸è³‡æ–™æ™‚é–“ä»‹æ–¼ 2019â€“01â€“01 è‡³ 2019-12-31 çš„è³‡æ–™é›†ï¼Œ\næ“´å¢ period_state æ¬„ä½ï¼Œ\nåˆ©ç”¨ rank() over(order by ) æ¨™è¨»æ’åºçµæœ rn ã€‚ åšå­æŸ¥è©¢è¡¨æ ¼ optï¼Œè¯åˆ failed_state å’Œ successeded_state ã€‚\nåœ¨ failed_state è¡¨æ ¼ï¼Œä»¥ group by period_state, date_add(fail_date, interval -rn day) ï¼Œåˆ†åˆ¥æ‰¾å‡ºfailed_state å’Œ successeded_stateï¼Œæ¯å€‹ period çš„ min(date) å’Œ max(date) ï¼Œä½œç‚ºè¼¸å‡ºçµæœçš„ start_date å’Œ end_date æ¬„ä½ã€‚ è§£æ±ºæ–¹æ¡ˆ (Rankç‰ˆæœ¬) with failed_state as ( select \u0026#39;failed\u0026#39; as period_state, fail_date, rank() over(order by fail_date) -1 as rn from Failed where fail_date between \u0026#39;2019-01-01\u0026#39; and \u0026#39;2019-12-31\u0026#39; ), succeeded_state as ( select \u0026#39;succeeded\u0026#39; as period_state, success_date, rank() over(order by success_date) -1 as rn from Succeeded where success_date between \u0026#39;2019-01-01\u0026#39; and \u0026#39;2019-12-31\u0026#39; ) select period_state, start_date, end_date from ( select period_state, min(fail_date) as start_date, max(fail_date) as end_date from failed_state group by period_state, date_add(fail_date, interval -rn day) union select period_state, min(success_date) as start_date, max(success_date) as end_date from succeeded_state group by period_state, date_add(success_date, interval -rn day) ) opt ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/report-contiguous-dates/","summary":"é¡Œç›® Table: Failed +--------------+---------+ | Column Name | Type | +--------------+---------+ | fail_date | date | +--------------+---------+ fail_date is the primary key for this table. This table contains the days of failed tasks. Table: Succeeded +--------------+---------+ | Column Name | Type | +--------------+---------+ | success_date | date | +--------------+---------+ success_date is the primary key for this table. This table contains the days of succeeded tasks. A system is running","title":"[leetcode][Database][Hard] 1225. Report Contiguous Dates"},{"content":"é¡Œç›®\nTable: Employee\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | id | int | | name | varchar | | salary | int | | departmentId | int | +--------------+---------+ id is the primary key column for this table. departmentId is a foreign key of the ID from the Department table. Each row of this table indicates the ID, name, and salary of an employee. It also contains the ID of their department. Table: Department\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | id | int | | name | varchar | +-------------+---------+ id is the primary key column for this table. Each row of this table indicates the ID of a department and its name. A companyâ€™s executives are interested in seeing who earns the most money in each of the companyâ€™s departments. A high earner in a department is an employee who has a salary in the top three unique salaries for that department.\nWrite an SQL query to find the employees who are high earners in each of the departments.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Employee (id int, name varchar(255), salary int, departmentId int) Create table If Not Exists Department (id int, name varchar(255)) Truncate table Employee insert into Employee (id, name, salary, departmentId) values (\u0026#39;1\u0026#39;, \u0026#39;Joe\u0026#39;, \u0026#39;85000\u0026#39;, \u0026#39;1\u0026#39;) insert into Employee (id, name, salary, departmentId) values (\u0026#39;2\u0026#39;, \u0026#39;Henry\u0026#39;, \u0026#39;80000\u0026#39;, \u0026#39;2\u0026#39;) insert into Employee (id, name, salary, departmentId) values (\u0026#39;3\u0026#39;, \u0026#39;Sam\u0026#39;, \u0026#39;60000\u0026#39;, \u0026#39;2\u0026#39;) insert into Employee (id, name, salary, departmentId) values (\u0026#39;4\u0026#39;, \u0026#39;Max\u0026#39;, \u0026#39;90000\u0026#39;, \u0026#39;1\u0026#39;) insert into Employee (id, name, salary, departmentId) values (\u0026#39;5\u0026#39;, \u0026#39;Janet\u0026#39;, \u0026#39;69000\u0026#39;, \u0026#39;1\u0026#39;) insert into Employee (id, name, salary, departmentId) values (\u0026#39;6\u0026#39;, \u0026#39;Randy\u0026#39;, \u0026#39;85000\u0026#39;, \u0026#39;1\u0026#39;) insert into Employee (id, name, salary, departmentId) values (\u0026#39;7\u0026#39;, \u0026#39;Will\u0026#39;, \u0026#39;70000\u0026#39;, \u0026#39;1\u0026#39;) Truncate table Department insert into Department (id, name) values (\u0026#39;1\u0026#39;, \u0026#39;IT\u0026#39;) insert into Department (id, name) values (\u0026#39;2\u0026#39;, \u0026#39;Sales\u0026#39;) è§£é¡Œæ€è€ƒ\né¡Œç›®è¦æ±‚è¼¸å‡ºæ¯å€‹éƒ¨é–€ä¸­ï¼Œæ”¶å…¥æ’åå‰ä¸‰é«˜çš„å“¡å·¥ã€‚\nè‹¥æœ‰æ”¶å…¥ç›¸åŒä¸”ä½æ–¼æ”¶å…¥æ’åå‰ä¸‰é«˜çš„å“¡å·¥ï¼Œä¹Ÿä½µå…¥è¼¸å‡ºçµæœã€‚ +------------+----------+--------+ | Department | Employee | Salary | +------------+----------+--------+ | IT | Max | 90000 | | IT | Joe | 85000 | | IT | Randy | 85000 | | IT | Will | 70000 | | Sales | Henry | 80000 | | Sales | Sam | 60000 | +------------+----------+--------+ é€é with clause å»ºç«‹ employee_info è¡¨æ ¼ï¼Œä»¥æä¾›æ¯å€‹éƒ¨é–€å…§ï¼Œæ¯ä½å“¡å·¥çš„è–ªæ°´æ’åºçµæœã€‚\nä½¿ç”¨ dense_rank() å‡½å¼é€²è¡Œæ’åºï¼Œdense_rank() æœƒä»¥é€£çºŒæ•¸å­—çš„æ–¹å¼çµ¦äºˆæ’åºçµæœ rnã€‚å¦‚ä¸‹æƒ…æ³ +------------+----------+--------+--------------+ | Department | Employee | Salary | dense_rank() | +------------+----------+--------+--------------+ | IT | Max | 90000 | 1 | | IT | Joe | 85000 | 2 | | IT | Randy | 85000 | 2 | | IT | Will | 70000 | 3 | | Sales | Henry | 80000 | 1 | | Sales | Sam | 60000 | 2 | +------------+----------+--------+--------------+ æŸ¥è©¢ employee_info ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œéæ¿¾æ¢ä»¶ä»¥æ‰¾å‡º employee_info.rn \u0026lt; 4 çš„ record setï¼Œå³æ‰¾å‡ºæ¯å€‹éƒ¨é–€ï¼Œæ”¶å…¥æ’åå‰ä¸‰é«˜çš„å“¡å·¥ã€‚ è§£æ±ºæ–¹æ¡ˆ\nwith employee_info as ( select Department.id as departmentId , Department.name as Department , Employee.name as Employee, Employee.Salary as Salary, dense_rank() over(partition by Department.id order by Employee.Salary desc ) rn from Employee join Department on Department.id = Employee.departmentId ) select employee_info.Department, employee_info.Employee, employee_info.Salary from employee_info where employee_info.rn \u0026lt; 4 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/department-top-three-salaries/","summary":"é¡Œç›® Table: Employee +--------------+---------+ | Column Name | Type | +--------------+---------+ | id | int | | name | varchar | | salary | int | | departmentId | int | +--------------+---------+ id is the primary key column for this table. departmentId is a foreign key of the ID from the Department table. Each row of this table indicates the ID, name, and salary of an employee. It also","title":"[leetcode][Database][Hard] 185. Department Top Three Salaries"},{"content":"é¡Œç›® Table: Trips\n+-------------+----------+ | Column Name | Type | +-------------+----------+ | id | int | | client_id | int | | driver_id | int | | city_id | int | | status | enum | | request_at | date | +-------------+----------+ id is the primary key for this table. The table holds all taxi trips. Each trip has a unique id, while client_id and driver_id are foreign keys to the users_id at the Users table. Status is an ENUM type of (\u0026#39;completed\u0026#39;, \u0026#39;cancelled_by_driver\u0026#39;, \u0026#39;cancelled_by_client\u0026#39;). Table: Users\n+-------------+----------+ | Column Name | Type | +-------------+----------+ | users_id | int | | banned | enum | | role | enum | +-------------+----------+ users_id is the primary key for this table. The table holds all users. Each user has a unique users_id, and role is an ENUM type of (\u0026#39;client\u0026#39;, \u0026#39;driver\u0026#39;, \u0026#39;partner\u0026#39;). banned is an ENUM type of (\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;). The cancellation rate is computed by dividing the number of canceled (by client or driver) requests with unbanned users by the total number of requests with unbanned users on that day.\nWrite a SQL query to find the cancellation rate of requests with unbanned users (both client and driver must not be banned) each day between \u0026quot;2013-10-01\u0026quot; and \u0026quot;2013-10-03\u0026quot;. Round Cancellation Rate to two decimal points.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Trips (id int, client_id int, driver_id int, city_id int, status ENUM(\u0026#39;completed\u0026#39;, \u0026#39;cancelled_by_driver\u0026#39;, \u0026#39;cancelled_by_client\u0026#39;), request_at varchar(50)) Create table If Not Exists Users (users_id int, banned varchar(50), role ENUM(\u0026#39;client\u0026#39;, \u0026#39;driver\u0026#39;, \u0026#39;partner\u0026#39;)) Truncate table Trips insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-01\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;cancelled_by_driver\u0026#39;, \u0026#39;2013-10-01\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;3\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-01\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;4\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;13\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;cancelled_by_client\u0026#39;, \u0026#39;2013-10-01\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;5\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-02\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;6\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-02\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;7\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-02\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;8\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-03\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;9\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;completed\u0026#39;, \u0026#39;2013-10-03\u0026#39;) insert into Trips (id, client_id, driver_id, city_id, status, request_at) values (\u0026#39;10\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;13\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;cancelled_by_driver\u0026#39;, \u0026#39;2013-10-03\u0026#39;) Truncate table Users insert into Users (users_id, banned, role) values (\u0026#39;1\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;client\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;2\u0026#39;, \u0026#39;Yes\u0026#39;, \u0026#39;client\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;3\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;client\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;4\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;client\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;10\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;driver\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;11\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;driver\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;12\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;driver\u0026#39;) insert into Users (users_id, banned, role) values (\u0026#39;13\u0026#39;, \u0026#39;No\u0026#39;, \u0026#39;driver\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚è¼¸å‡º 2013-10-01 è‡³ 2013-10-03 ï¼Œæ¯æ—¥çš„æ­ä¹˜è«‹æ±‚å–æ¶ˆç‡ï¼Œä¸”è¢«ç´å…¥è¨ˆç®—çš„æœ‰æ•ˆæ­ä¹˜è«‹æ±‚å¿…é ˆæ˜¯æœªåœæ¬Šä¹˜å®¢ å’Œ æœªåœæ¬Šé§•é§›ï¼Œè‹¥æœ‰ä¸€æ–¹è¢«åœæ¬Šï¼Œå‰‡è©²ç­†æ­ä¹˜è«‹æ±‚è¦–ç‚ºç„¡æ•ˆè³‡æ–™ã€‚\næ­ä¹˜è«‹æ±‚å–æ¶ˆç‡ â† è©²æ—¥æœ‰æ•ˆæ­ä¹˜è«‹æ±‚ä¸”è©²è«‹æ±‚è¢«æ‹’çµ•çš„è³‡æ–™æ•¸ / è©²æ—¥ç¸½æœ‰æ•ˆæ­ä¹˜è«‹æ±‚ +------------+-------------------+ | Day | Cancellation Rate | +------------+-------------------+ | 2013-10-01 | 0.33 | | 2013-10-02 | 0.00 | | 2013-10-03 | 0.50 | +------------+-------------------+ é€é with clause åˆ†åˆ¥å»ºç«‹æœªåœæ¬Šä¹˜å®¢ legal_clientã€æœªåœæ¬Šé§•é§› legal_driverï¼Œä»¥åŠ2013-10-01 è‡³ 2013-10-03 çš„æ­ä¹˜è³‡æ–™ legal_tripsã€‚ æŸ¥è©¢ legal_trips ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œé—œè¯legal_client å’Œ legal_driver ï¼Œä»¥è¨ˆç®—æ¯æ—¥çš„ æ­ä¹˜è«‹æ±‚å–æ¶ˆç‡ ã€‚ è§£æ±ºæ–¹æ¡ˆ with legal_client as ( select * from Users where role = \u0026#39;client\u0026#39; and banned = \u0026#39;No\u0026#39;), legal_driver as ( select * from Users where role = \u0026#39;driver\u0026#39; and banned = \u0026#39;No\u0026#39;), legal_trips as (select * from Trips where request_at between \u0026#39;2013-10-01\u0026#39; and \u0026#39;2013-10-03\u0026#39; ) select legal_trips.request_at as Day, round( count(if(legal_trips.status=\u0026#39;completed\u0026#39;, NULL, legal_trips.id)) / count(legal_trips.id), 2 ) as \u0026#39;Cancellation Rate\u0026#39; from legal_trips join legal_client on legal_client.users_id = legal_trips.client_id join legal_driver on legal_driver.users_id = legal_trips.driver_id group by legal_trips.request_at ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/trips-and-users/","summary":"é¡Œç›® Table: Trips +-------------+----------+ | Column Name | Type | +-------------+----------+ | id | int | | client_id | int | | driver_id | int | | city_id | int | | status | enum | | request_at | date | +-------------+----------+ id is the primary key for this table. The table holds all taxi trips. Each trip has a unique id, while client_id and driver_id are foreign keys","title":"[leetcode][Database][Hard] 262. Trips and Users"},{"content":"é¡Œç›®\nTable: Employee\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | id | int | | company | varchar | | salary | int | +--------------+---------+ id is the primary key column for this table. Each row of this table indicates the company and the salary of one employee. Write an SQL query to find the rows that contain the median salary of each company. While calculating the median, when you sort the salaries of the company, break the ties by id.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Employee (id int, company varchar(255), salary int) Truncate table Employee insert into Employee (id, company, salary) values (\u0026#39;1\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;2341\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;2\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;341\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;3\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;15\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;4\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;15314\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;5\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;451\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;6\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;513\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;7\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;15\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;8\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;13\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;9\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;1154\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;10\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;1345\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;11\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;1221\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;12\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;234\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;13\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;2345\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;14\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;2645\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;15\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;2645\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;16\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;2652\u0026#39;) insert into Employee (id, company, salary) values (\u0026#39;17\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;65\u0026#39;) è§£é¡Œæ€è€ƒ\né¡Œç›®è¦æ±‚è¨ˆç®—ä¸¦ä¸”è¼¸å‡ºæ¯é–“å…¬å¸çš„è–ªè³‡ä¸­ä½æ•¸ã€‚ +----+---------+--------+ | id | company | salary | +----+---------+--------+ | 5 | A | 451 | | 6 | A | 513 | | 12 | B | 234 | | 9 | B | 1154 | | 14 | C | 2645 | +----+---------+--------+ åšå­è¡¨ aæŸ¥è©¢ï¼Œæ¯é–“å…¬å¸çš„å“¡å·¥ç¸½æ•¸ cnt ï¼Œä¸¦åˆ©ç”¨ row_numbner()ä¾æ“šæ¯é–“å…¬å¸å“¡å·¥è–ªæ°´ salary å‡åºï¼Œæ¨™è¨»æ’åºçµæœ row_numã€‚ åˆ©ç”¨å­è¡¨ a ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œéæ¿¾row_numä»¥æ‰¾å‡ºä»‹æ–¼ cnt div 2å’Œ (cnt div 2)+1 çš„ record setï¼Œå³æ¯é–“å…¬å¸çš„æ–°å¢ä¸­ä½æ•¸ã€‚ è§£æ±ºæ–¹æ¡ˆ\nselect a.id, a.company, a.salary from ( select *, count(id) over(PARTITION by company) as cnt, row_number() over(PARTITION by company order by salary) as row_num from employee ) a where a.row_num between a.cnt div 2 and (a.cnt div 2)+1 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/median-employee-salary/","summary":"é¡Œç›® Table: Employee +--------------+---------+ | Column Name | Type | +--------------+---------+ | id | int | | company | varchar | | salary | int | +--------------+---------+ id is the primary key column for this table. Each row of this table indicates the company and the salary of one employee. Write an SQL query to find the rows that contain the median salary of each company. While calculating the","title":"[leetcode][Database][Hard] 569. Median Employee Salary"},{"content":"é¡Œç›® Table: Numbers\n+-------------+------+ | Column Name | Type | +-------------+------+ | num | int | | frequency | int | +-------------+------+ num is the primary key for this table. Each row of this table shows the frequency of a number in the database. The median is the value separating the higher half from the lower half of a data sample.\nWrite an SQL query to report the median of all the numbers in the database after decompressing the Numbers table. Round the median to one decimal point.\nSQL Schema\nCreate table If Not Exists Numbers (num int, frequency int) Truncate table Numbers insert into Numbers (num, frequency) values (\u0026#39;0\u0026#39;, \u0026#39;7\u0026#39;) insert into Numbers (num, frequency) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;) insert into Numbers (num, frequency) values (\u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;) insert into Numbers (num, frequency) values (\u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚è¼¸å‡º Numbers è¡¨æ ¼çš„ä¸­ä½æ•¸ medianã€‚\næœ¬é¡Œè¦æ±‚çš„é‚è¼¯ç‚ºÂ :Â 1. å…ˆå°‡ Numbers å…§çš„æ•¸å­— num ä»¥é »æ¬¡ frequency å±•é–‹ç‚ºç­‰é•·çš„æ•¸åˆ—\n2. L â† å°‡æ‰€æœ‰ num å±•é–‹çš„æ•¸åˆ—ä¾ num å¤§å°æœ‰åºä¸²æ¥Â 3. æ±‚å‡º L çš„ä¸­ä½æ•¸ medianï¼Œä¸¦å°‡ä¸­ä½æ•¸ä½œç‚ºè¼¸å‡ºçµæœ Input: Numbers table: +-----+-----------+ | num | frequency | +-----+-----------+ | 0 | 7 | | 1 | 1 | | 2 | 3 | | 3 | 1 | +-----+-----------+ Output: +--------+ | median | +--------+ | 0.0 | +--------+ Explanation: If we decompress the Numbers table, we will get [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3], so the median is (0 + 0) / 2 = 0. ä¸­ä½æ•¸çš„å®šç¾© â†’ åœ¨ä¸€çµ„æ•¸åˆ— _S_ ä¸­ï¼Œæœ‰ä¸€åŠæ•¸å­—å€‹æ•¸æœƒå°æ–¼ä¸­ä½æ•¸ï¼Œå¦å¤–ä¸€åŠæ•¸å­—å€‹æ•¸æœƒå¤§æ–¼ä¸­ä½æ•¸ã€‚å‡è¨­\n_L_ â† æ•¸åˆ— _S_ ä¸­ï¼Œå°æ–¼ç­‰æ–¼ Numbers.num çš„æ•¸å­—å€‹æ•¸\n_R_ â† æ•¸åˆ— _S_ ä¸­ï¼Œå¤§æ–¼ç­‰æ–¼ Numbers.num çš„æ•¸å­—å€‹æ•¸\n_N_ â† æ•¸åˆ— _S_ ä¸­ï¼ŒNumbers.num çš„æ•¸å­—å€‹æ•¸\nå‰‡æ•¸åˆ— _S_ çš„æ•¸å­—å€‹æ•¸æ‡‰ç­‰åŒæ–¼ _L + N + R_ ï¼Œ å° Numbers ä¸­çš„æ‰€æœ‰ num ï¼Œè©²æ¢ä»¶éƒ½æˆç«‹ è€ƒæ…®ç•¶ _L_ â‰  _R_ çš„æƒ…æ³ï¼Œè‹¥Numbers.numæ˜¯ä¸­ä½æ•¸ï¼Œç•¶ _N_ åŠ å…¥è‡³å€‹æ•¸è¼ƒå°‘çš„çŸ­é‚Šæ™‚ ( _L_ æˆ– _R_ ) ï¼Œè¢« _N_ åŠ å…¥çš„çŸ­é‚Šæœƒæˆç‚ºé•·é‚Š:\nç•¶ _L \u0026lt; R_ï¼Œ_L + N \u0026gt; R _ç•¶ _R \u0026lt; L_ï¼Œ_R + N \u0026gt; L _è‹¥Numbers.numä¸æ˜¯ä¸­ä½æ•¸ï¼Œç•¶ _L \u0026lt; R_ æ™‚ï¼Œå³ä½¿æŠŠ _N_ æ”¾åˆ°çŸ­é‚Šï¼Œä»æœƒå¾—åˆ° _L + N \u0026lt; R_ çš„çµæœï¼Œé€™è¡¨ç¤º _N_ ä¸åœ¨æ•¸åˆ—ä¸­é–“ è€ƒæ…®ç•¶ _L = R_ çš„æƒ…æ³ï¼Œæ ¹æ“šå®šç¾©å·²çŸ¥ Numbers.numæ˜¯ä¸­ä½æ•¸ è§£æ±ºæ–¹æ¡ˆ select round(avg(n.num),1) median from Numbers n where n.Frequency \u0026gt;= abs( (select sum(Frequency) from Numbers where num\u0026lt;=n.num) - (select sum(Frequency) from Numbers where num\u0026gt;=n.num) ) ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/find-median-given-frequency-of-numbers/","summary":"é¡Œç›® Table: Numbers +-------------+------+ | Column Name | Type | +-------------+------+ | num | int | | frequency | int | +-------------+------+ num is the primary key for this table. Each row of this table shows the frequency of a number in the database. The median is the value separating the higher half from the lower half of a data sample. Write an SQL query to report the median","title":"[leetcode][Database][Hard] 571. Find Median Given Frequency of Numbers"},{"content":"é¡Œç›® Table: Employee\n+-------------+------+ | Column Name | Type | +-------------+------+ | id | int | | month | int | | salary | int | +-------------+------+ (id, month) is the primary key for this table. Each row in the table indicates the salary of an employee in one month during the year 2020. Write an SQL query to calculate the cumulative salary summary for every employee in a single unified table.\nThe cumulative salary summary for an employee can be calculated as follows:\nFor each month that the employee worked, sum up the salaries in that month and the previous two months. This is their 3-month sum for that month. If an employee did not work for the company in previous months, their effective salary for those months is 0. Do not include the 3-month sum for the most recent month that the employee worked for in the summary. Do not include the 3-month sum for any month the employee did not work. Return the result table ordered by id in ascending order. In case of a tie, order it by month in descending order.\nSQL Schema\nCreate table If Not Exists Employee (id int, month int, salary int) Truncate table Employee insert into Employee (id, month, salary) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;20\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;20\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;30\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;30\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;40\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;40\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;3\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;60\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;1\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;60\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;70\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;1\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;90\u0026#39;) insert into Employee (id, month, salary) values (\u0026#39;1\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;90\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚è¼¸å‡ºæ¯ä½å“¡å·¥åœ¨æ¯å€‹æœˆåˆ†çš„ç´¯è¨ˆè–ªè³‡ï¼Œä¸¦ä¸”éæ¿¾æ¯å€‹å“¡å·¥æœ€å¾Œä¸€æ¬¡è–ªè³‡ç´€éŒ„çš„æœˆä»½ã€‚\nå®šç¾© ç´¯è¨ˆè–ªè³‡ â†’ è©²æœˆä»½è–ªè³‡èˆ‡å‰å…©å€‹æœˆçš„åŠ ç¸½ +----+-------+--------+ | id | month | Salary | +----+-------+--------+ | 1 | 7 | 90 | | 1 | 4 | 130 | | 1 | 3 | 90 | | 1 | 2 | 50 | | 1 | 1 | 20 | | 2 | 1 | 20 | | 3 | 3 | 100 | | 3 | 2 | 40 | +----+-------+--------+ é€é with clause å»ºç«‹ month_dense_rank è¡¨æ ¼ï¼Œä»¥ä¾¿æ‰¾å‡ºæ¯ä½å“¡å·¥éœ€è¦éæ¿¾æœ‰è–ªè³‡ç´€éŒ„çš„æœ€å¾Œä¸€å€‹æœˆä»½ã€‚\nåˆ©ç”¨ dense_rank() å‡½å¼ï¼Œä¾æ“šå“¡å·¥ç·¨è™Ÿ id èˆ‡ç´€éŒ„æœˆä»½ month é™åºï¼Œæ¨™è¨»æ¯ä½å“¡å·¥ï¼Œæ¯å€‹æœˆåˆ†è–ªè³‡ç´€éŒ„çš„æ’åºçµæœã€‚ é€é with clause å»ºç«‹ cumulate_month_salary è¡¨æ ¼ï¼Œçµ±è¨ˆæ¯ä½å“¡å·¥ï¼Œæ¯å€‹æœˆä»½çš„ç´¯ç©è–ªè³‡ã€‚\nåˆ©ç”¨å­æŸ¥è©¢é—œè¯å¤–éƒ¨ä¸»è¡¨ Employeeï¼Œä¸¦éæ¿¾å‡ºç¬¦åˆå­æŸ¥è©¢ id=Employee.id ä»¥åŠå­æŸ¥è©¢è–ªè³‡ç´€éŒ„æœˆä»½ month è½åœ¨ä¸»è¡¨ Employee.month-2 å’Œ Employee.month ä¹‹é–“çš„ record setï¼Œä¾æ“šè©² record set çš„å“¡å·¥ç·¨è™Ÿ id å°è©² record setçš„è–ªè³‡ salary é€²è¡ŒåŠ ç¸½ã€‚ åˆ©ç”¨å­è¡¨æŸ¥è©¢ month_dense_rank éæ¿¾ month_dense_rank.r_month \u0026gt; 1 çš„ record set ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œä¸¦é—œè¯ cumulate_month_salary è¡¨æ ¼ï¼Œæœ€å¾Œå¸¶å‡ºç¬¦åˆé¡Œç›®è¦æ±‚çš„è¼¸å‡ºçµæœ å“¡å·¥ç·¨è™Ÿid ã€ è–ªè³‡æœˆä»½month ã€ ç´¯ç©è–ªè³‡salary ã€‚ è§£æ±ºæ–¹æ¡ˆ with month_dense_rnak as ( select id, month, dense_rank() over(partition by id order by month desc) as r_month from Employee ), cumulate_month_salary as ( select id, month, ( select sum(salary) from Employee where id=e.id and month between e.month-2 and e.month group by id ) as salary from Employee e ) select a.id, a.month, b.salary from ( select id, month from month_dense_rnak where r_month \u0026gt; 1 ) a join cumulate_month_salary b on b.id = a.id and b.month = a.month ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/find-cumulative-salary-of-an-employee/","summary":"é¡Œç›® Table: Employee +-------------+------+ | Column Name | Type | +-------------+------+ | id | int | | month | int | | salary | int | +-------------+------+ (id, month) is the primary key for this table. Each row in the table indicates the salary of an employee in one month during the year 2020. Write an SQL query to calculate the cumulative salary summary for every employee in a","title":"[leetcode][Database][Hard] 579. Find Cumulative Salary of an Employee"},{"content":"é¡Œç›® Table: Stadium\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | id | int | | visit_date | date | | people | int | +---------------+---------+ visit_date is the primary key for this table. Each row of this table contains the visit date and visit id to the stadium with the number of people during the visit. No two rows will have the same visit_date, and as the id increases, the dates increase as well. Write an SQL query to display the records with three or more rows with consecutive id\u0026rsquo;s, and the number of people is greater than or equal to 100 for each.\nReturn the result table ordered by visit_date in ascending order.\nSQL Schema\nCreate table If Not Exists Stadium (id int, visit_date DATE NULL, people int) Truncate table Stadium insert into Stadium (id, visit_date, people) values (\u0026#39;1\u0026#39;, \u0026#39;2017-01-01\u0026#39;, \u0026#39;10\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;2\u0026#39;, \u0026#39;2017-01-02\u0026#39;, \u0026#39;109\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;3\u0026#39;, \u0026#39;2017-01-03\u0026#39;, \u0026#39;150\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;4\u0026#39;, \u0026#39;2017-01-04\u0026#39;, \u0026#39;99\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;5\u0026#39;, \u0026#39;2017-01-05\u0026#39;, \u0026#39;145\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;6\u0026#39;, \u0026#39;2017-01-06\u0026#39;, \u0026#39;1455\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;7\u0026#39;, \u0026#39;2017-01-07\u0026#39;, \u0026#39;199\u0026#39;) insert into Stadium (id, visit_date, people) values (\u0026#39;8\u0026#39;, \u0026#39;2017-01-09\u0026#39;, \u0026#39;188\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚è¼¸å‡ºé€£çºŒä¸‰æ—¥ä»¥ä¸Šï¼Œæ‹œè¨ªäººæ•¸é”åˆ° 100 ä»¥ä¸Š çš„æ—¥æœŸèˆ‡äººæ•¸ã€‚ +------+------------+-----------+ | id | visit_date | people | +------+------------+-----------+ | 5 | 2017-01-05 | 145 | | 6 | 2017-01-06 | 1455 | | 7 | 2017-01-07 | 199 | | 8 | 2017-01-09 | 188 | +------+------------+-----------+ é€é with clause å»ºç«‹ visit_thresgold è¡¨æ ¼ï¼Œåˆ©ç”¨ lead()å‡½ç¤ºæ“´å¢å¾Œå…©æ—¥ç€è¦½äººæ•¸æ¬„ä½ next_1ã€next_2ï¼Œåˆ©ç”¨lag() å‡½ç¤ºæ“´å¢å‰å…©æ—¥ç€è¦½äººæ•¸æ¬„ä½ prev_1ã€prev_2ï¼Œä»¥ over_threshold ä½œç‚ºç•¶æ—¥ç€è¦½äººæ•¸æ¬„ä½ã€‚\nåˆ¤æ–·æ¯å€‹æ¬„ä½ç€è¦½äººæ•¸æ˜¯å¦é”åˆ° 100 ä»¥ä¸Šï¼Œ\nè‹¥äººæ•¸é”åˆ° 100 ä»¥ä¸Šï¼Œæ¨™è¨˜ç‚º 1ï¼›\nè‹¥äººæ•¸ä¸æ»¿ 100ï¼Œå‰‡æ¨™è¨˜ç‚º 0 æŸ¥è©¢ stadium ä½œç‚ºä¸»è¦è¡¨æ ¼ä¸¦é—œè¯ visit_thresholdï¼Œè‹¥ä»¥ä¸‹ä¸‰æ¢åˆ¤æ–·å¼æœ‰å…¶ä¸­ä¸€æ¢æˆç«‹ï¼Œå‰‡è©²æ—¥æ—¥æœŸèˆ‡ç€è¦½äººæ•¸éœ€è¦åŒ…å«æ–¼è¼¸å‡ºçµæœå…§\nprev_2 + prev_1 + over_threshold \u0026gt; 2\nprev_1 + over_threshold + next_1 \u0026gt; 2\nover_threshold + next_1 + next_2 \u0026gt; 2 ç•¶çœ‹åˆ°é€£çºŒé€™å€‹é—œéµå­—æ™‚ï¼Œæˆ‘æœƒæƒ³åˆ°æ‡‰è©²ä½¿ç”¨ lead() å‡½å¼æˆ– lag() å‡½å¼ã€‚lead() å’Œ lag() å°æ‡‰çš„æ˜¯ç•¶å‰æŸ¥è©¢çš„ record set ï¼›è‹¥åœ¨å­æŸ¥è©¢æˆ–å­è¡¨å…§ä½¿ç”¨ï¼Œå‰‡å°æ‡‰å­æŸ¥è©¢æˆ–å­è¡¨çš„è³‡æ–™ç¯„åœã€‚\nlead( column, offset ) over( [partition by column1, column2,Â â€¦] [order by column1, column2,Â â€¦])\nlag( column, offset) over( [partition by column1, column2,Â â€¦] [order by column1, column2,Â â€¦]) Leetcode å®˜æ–¹å°æ–¼é€™é¡Œæ‰€æä¾›çš„è§£æ±ºæ–¹æ¡ˆæ˜¯é€é self join T å…©æ¬¡ä¸”ä¸çµ¦äºˆé—œè¯æ¢ä»¶ï¼Œä¸¦åˆ¤æ–· T1.people ã€ T2.people å’Œ T3.people æ˜¯å¦éƒ½æœ‰é”åˆ° 100 ä»¥ä¸Šã€‚ è§£æ±ºæ–¹æ¡ˆ with visit_threshold as ( select id, if(people \u0026gt;= 100, 1, 0) as over_threshold, if(lead(people, 1) over() \u0026gt;=100, 1,0) as next_1, if(lead(people, 2) over() \u0026gt;=100, 1,0) as next_2, if(lag(people, 1) over() \u0026gt;=100, 1,0) as prev_1, if(lag(people, 2) over() \u0026gt;=100, 1,0) as prev_2 from stadium ) select A.id, A.visit_date , A.people from stadium A join visit_threshold B using(id) where B.over_threshold+B.next_1+B.next_2 \u0026gt; 2 or B.prev_1+B.prev_2+B.over_threshold \u0026gt; 2 or B.prev_1+B.over_threshold+B.next_1 \u0026gt; 2 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/human-traffic-of-stadium/","summary":"é¡Œç›® Table: Stadium +---------------+---------+ | Column Name | Type | +---------------+---------+ | id | int | | visit_date | date | | people | int | +---------------+---------+ visit_date is the primary key for this table. Each row of this table contains the visit date and visit id to the stadium with the number of people during the visit. No two rows will have the same visit_date, and as the","title":"[leetcode][Database][Hard] 601. Human Traffic of Stadium"},{"content":"é¡Œç›® Table: Salary\n+-------------+------+ | Column Name | Type | +-------------+------+ | id | int | | employee_id | int | | amount | int | | pay_date | date | +-------------+------+ id is the primary key column for this table. Each row of this table indicates the salary of an employee in one month. employee_id is a foreign key from the Employee table. Table: Employee\n+---------------+------+ | Column Name | Type | +---------------+------+ | employee_id | int | | department_id | int | +---------------+------+ employee_id is the primary key column for this table. Each row of this table indicates the department of an employee. Write an SQL query to report the comparison result (higher/lower/same) of the average salary of employees in a department to the companyâ€™s average salary.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Salary (id int, employee_id int, amount int, pay_date date) Create table If Not Exists Employee (employee_id int, department_id int) Truncate table Salary insert into Salary (id, employee_id, amount, pay_date) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;9000\u0026#39;, \u0026#39;2017/03/31\u0026#39;) insert into Salary (id, employee_id, amount, pay_date) values (\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;6000\u0026#39;, \u0026#39;2017/03/31\u0026#39;) insert into Salary (id, employee_id, amount, pay_date) values (\u0026#39;3\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;10000\u0026#39;, \u0026#39;2017/03/31\u0026#39;) insert into Salary (id, employee_id, amount, pay_date) values (\u0026#39;4\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;7000\u0026#39;, \u0026#39;2017/02/28\u0026#39;) insert into Salary (id, employee_id, amount, pay_date) values (\u0026#39;5\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;6000\u0026#39;, \u0026#39;2017/02/28\u0026#39;) insert into Salary (id, employee_id, amount, pay_date) values (\u0026#39;6\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;8000\u0026#39;, \u0026#39;2017/02/28\u0026#39;) Truncate table Employee insert into Employee (employee_id, department_id) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;) insert into Employee (employee_id, department_id) values (\u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;) insert into Employee (employee_id, department_id) values (\u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚åˆ—å‡ºæ¯å€‹æœˆä»½ï¼Œæ¯å€‹éƒ¨é–€å¹³å‡è–ªè³‡ï¼Œå’Œæ•´å€‹å…¬å¸å¹³å‡è–ªè³‡çš„æ¯”è¼ƒçµæœï¼Œä¸¦é¡¯ç¤ºé«˜ higher/ ç›¸ç­‰ same/ ä½ lowerçš„çµæœã€‚ +-----------+---------------+------------+ | pay_month | department_id | comparison | +-----------+---------------+------------+ | 2017-02 | 1 | same | | 2017-03 | 1 | higher | | 2017-02 | 2 | same | | 2017-03 | 2 | lower | +-----------+---------------+------------+ é€é with clause å»ºç«‹ company_salary è¡¨æ ¼ï¼Œå¸¶å‡ºæ¯å€‹æœˆä»½å…¬å¸çš„å¹³å‡è–ªè³‡ã€‚\né¸æ“‡ salary ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œå› ç‚º company_salary è¡¨æ ¼ä¸éœ€è¦å€åˆ†å€‹åˆ¥éƒ¨é–€çš„å“¡å·¥è–ªè³‡ã€‚ é€é with clause å»ºç«‹ department_salary è¡¨æ ¼ï¼Œå¸¶å‡ºæ¯å€‹æœˆä»½ï¼Œæ¯å€‹éƒ¨é–€çš„å¹³å‡è–ªè³‡ã€‚\næŸ¥è©¢ employee ä½œç‚ºä¸»è¦è¡¨æ ¼ä¸¦é—œè¯ salary è¡¨æ ¼ï¼Œemployee.department_id å¯ä»¥ä½œç‚ºå€åˆ†å“¡å·¥éƒ¨é–€çš„ä¾æ“šï¼Œä¾¿èƒ½è¨ˆç®—å‡ºæ¯å€‹éƒ¨é–€çš„å¹³å‡è–ªè³‡ã€‚ æŸ¥è©¢ company_salary ä½œç‚ºä¸»è¦è¡¨æ ¼ä¸¦é—œè¯ department_salary è¡¨æ ¼ï¼Œæœ€å¾Œä»¥ pay_month å‡åºã€ department_id å‡åºè¼¸å‡ºæœ€å¾ŒæŸ¥è©¢çµæœã€‚\nåˆ©ç”¨ if( condition, statement for condition true, statement for condition false ) å‡½ç¤ºï¼Œä¸¦ä½¿ç”¨é€£çºŒçš„ if() åˆ¤æ–·å¼ä¾†é”æˆé¡¯ç¤ºé«˜ higher/ ç›¸ç­‰ same/ ä½ lowerçš„çµæœã€‚ è§£æ±ºæ–¹æ¡ˆ with company_salary as ( select date_format(pay_date, \u0026#34;%Y-%m\u0026#34;) as pay_month, avg(amount) as avg_salary from salary group by month(pay_date) ), department_salary as ( select a.department_id, date_format(b.pay_date, \u0026#34;%Y-%m\u0026#34;) as pay_month, avg(b.amount) as avg_salary from employee a join salary b using (employee_id) group by a.department_id, month(b.pay_date) ) select a.pay_month as pay_month, b.department_id as department_id, if(b.avg_salary\u0026gt;a.avg_salary, \u0026#34;higher\u0026#34;, if(b.avg_salary \u0026lt; a.avg_salary, \u0026#34;lower\u0026#34;, \u0026#34;same\u0026#34;)) as comparison from company_salary a join department_salary b using(pay_month) order by a.pay_month, b.department_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/average-salary-departments-vs-company/","summary":"é¡Œç›® Table: Salary +-------------+------+ | Column Name | Type | +-------------+------+ | id | int | | employee_id | int | | amount | int | | pay_date | date | +-------------+------+ id is the primary key column for this table. Each row of this table indicates the salary of an employee in one month. employee_id is a foreign key from the Employee table. Table: Employee +---------------+------+ | Column","title":"[leetcode][Database][Hard] 615. Average Salary: Departments VS Company"},{"content":"é¡Œç›® Table: Student\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | name | varchar | | continent | varchar | +-------------+---------+ There is no primary key for this table. It may contain duplicate rows. Each row of this table indicates the name of a student and the continent they came from. A school has students from Asia, Europe, and America.\nWrite an SQL query to pivot the continent column in the Student table so that each name is sorted alphabetically and displayed underneath its corresponding continent. The output headers should be America, Asia, and Europe, respectively.\nThe test cases are generated so that the student number from America is not less than either Asia or Europe.\nSQL Schema\nCreate table If Not Exists Student (name varchar(50), continent varchar(7)) Truncate table Student insert into Student (name, continent) values (\u0026#39;Jane\u0026#39;, \u0026#39;America\u0026#39;) insert into Student (name, continent) values (\u0026#39;Pascal\u0026#39;, \u0026#39;Europe\u0026#39;) insert into Student (name, continent) values (\u0026#39;Xi\u0026#39;, \u0026#39;Asia\u0026#39;) insert into Student (name, continent) values (\u0026#39;Jack\u0026#39;, \u0026#39;America\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚è¼¸å‡ºæ¨ç´è¡¨æ ¼ï¼Œè©²æ¨ç´è¡¨æ ¼éœ€è¦ä½¿ç”¨ America ã€ Asia å’Œ Europe ï¼Œä¸¦ç¬¦åˆè©²å¤§æ´²çš„å­¸ç”Ÿåå­— name åˆ—è¡¨ã€‚ +---------+------+--------+ | America | Asia | Europe | +---------+------+--------+ | Jack | Xi | Pascal | | Jane | null | null | +---------+------+--------+ ä½¿ç”¨ left join ä¾¿èƒ½ç°¡å–®çš„é”æˆé¡Œç›®è¦æ±‚ã€‚\néœ€è¦è‘—æ‰‹è™•ç†çš„å•é¡Œé»Â : å¦‚ä½•è®“å­¸ç”Ÿåå­—ä¸¦å­˜åœ¨åŒä¸€å€‹ row ã€‚\nåˆ©ç”¨ row_number() å‡½å¼ï¼Œå…ˆå°‡å­¸ç”Ÿä¾æ“šå¤§æ´²åˆ†é¡ï¼Œä¸¦çµ¦äºˆæ¯å€‹å¤§æ´²å…§çš„å­¸ç”Ÿåˆ—è¡¨æ¨™è¨˜æ’åºæ•¸å­—ï¼Œæœ€å¾Œé€éé¸æ“‡å­¸ç”Ÿäººæ•¸æœ€å¤šçš„å¤§æ´²ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œä¾æ¬¡ left join å…¶ä»–å¤§æ´²çš„å­¸ç”Ÿåˆ—è¡¨ï¼Œä¸¦ä»¥ row_number() çš„æ¨™è¨˜æ•¸å­—åšç‚ºè¡¨æ ¼é—œè¯çš„æ¢ä»¶ã€‚ è§£æ±ºæ–¹æ¡ˆ with from_america as (select name, row_number() over() as rn from student where continent = \u0026#39;America\u0026#39; order by name asc), from_asia as (select name, row_number() over() as rn from student where continent = \u0026#39;Asia\u0026#39; order by name asc), from_europe as (select name, row_number() over() as rn from student where continent = \u0026#39;Europe\u0026#39; order by name asc) select a.name as America, b.name as Asia, c.name as Europe from from_america a left join from_asia b using(rn) left join from_europe c using(rn) ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/students-report-by-geography/","summary":"é¡Œç›® Table: Student +-------------+---------+ | Column Name | Type | +-------------+---------+ | name | varchar | | continent | varchar | +-------------+---------+ There is no primary key for this table. It may contain duplicate rows. Each row of this table indicates the name of a student and the continent they came from. A school has students from Asia, Europe, and America. Write an SQL query to pivot the continent","title":"[leetcode][Database][Hard] 618. Students Report By Geography"},{"content":"é¡Œç›® Table: Activity\n+--------------+---------+ | Column Name | Type | +--------------+---------+ | player_id | int | | device_id | int | | event_date | date | | games_played | int | +--------------+---------+ (player_id, event_date) is the primary key of this table. This table shows the activity of players of some games. Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on someday using some device. The install date of a player is the first login day of that player.\nWe define day one retention of some date x to be the number of players whose install date is x and they logged back in on the day right after x, divided by the number of players whose install date is x, rounded to 2 decimal places.\nWrite an SQL query to report for each install date, the number of players that installed the game on that day, and the day one retention.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Activity (player_id int, device_id int, event_date date, games_played int) Truncate table Activity insert into Activity (player_id, device_id, event_date, games_played) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2016-03-01\u0026#39;, \u0026#39;5\u0026#39;) insert into Activity (player_id, device_id, event_date, games_played) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2016-03-02\u0026#39;, \u0026#39;6\u0026#39;) insert into Activity (player_id, device_id, event_date, games_played) values (\u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2017-06-25\u0026#39;, \u0026#39;1\u0026#39;) insert into Activity (player_id, device_id, event_date, games_played) values (\u0026#39;3\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2016-03-01\u0026#39;, \u0026#39;0\u0026#39;) insert into Activity (player_id, device_id, event_date, games_played) values (\u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2018-07-03\u0026#39;, \u0026#39;5\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚åˆ©ç”¨ Activity è¡¨æ ¼çµ±è¨ˆå®‰è£ç”¨æˆ¶æ•¸é‡ï¼Œä»¥åŠç”¨æˆ¶é¦–æ—¥ç•™å­˜ç‡ã€‚\nå®šç¾©ç”¨æˆ¶å®‰è£æ—¥ â†’ ç”¨æˆ¶åœ¨ Activity ç¬¬ä¸€æ¬¡å‡ºç¾ç´€éŒ„çš„ event_date ã€‚\nå®šç¾©ç”¨æˆ¶é¦–æ—¥ç•™å­˜ â†’ ç”¨æˆ¶åœ¨å®‰è£æ—¥éš”å¤© event_date+1 æœ‰ Activity recordã€‚\nå®šç¾©é¦–æ—¥ç•™å­˜ç‡è¨ˆç®—æ–¹å¼ â†’ ç”¨æˆ¶é¦–æ—¥ç•™å­˜æ•¸ / å®‰è£æ—¥ç¸½ç”¨æˆ¶äººæ•¸ é€é with clause å»ºç«‹ player_install_date è¡¨æ ¼ï¼Œæ‰¾å‡ºæ¯ä½ç”¨æˆ¶çš„å®‰è£æ—¥ install_dt é€é with clause å»ºç«‹ player_day1_back è¡¨æ ¼ï¼Œçµ±è¨ˆç”¨æˆ¶é¦–æ—¥ç•™å­˜äººæ•¸ cnt_login_back_player ã€‚\né¸æ“‡ Activity ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œä½¿ç”¨ left join player_install_date å¸¶å‡ºæ‰€æœ‰çš„å®‰è£æ—¥ install_dt ï¼Œä¸¦éæ¿¾ Activity è¡¨æ ¼ä¸­ç¬¦åˆæ¢ä»¶ Activity.event_date = player_install_date+1 çš„ record setã€‚ å¾ player_install_date å¸¶å‡º ç”¨æˆ¶å®‰è£æ—¥ çµ±è¨ˆäººæ•¸ï¼Œä½¿ç”¨ left join player_day1_back å¸¶å‡ºç”¨æˆ¶é¦–æ—¥ç•™å­˜ çµ±è¨ˆäººæ•¸ï¼Œä¾¿èƒ½è¨ˆç®—å‡º é¦–æ—¥ç•™å­˜ç‡ ã€‚ è§£æ±ºæ–¹æ¡ˆ with player_install_date as ( select player_id, min(event_date) as install_dt from activity group by player_id ), player_day1_back as ( select distinct b.install_dt, count(a.player_id) over(partition by a.event_date) as cnt_login_back_player from activity a left join player_install_date b using(player_id) where a.event_date = date_add(b.install_dt, INTERVAL 1 DAY) ) select a.install_dt, a.installs, round(ifnull(b.cnt_login_back_player,0) / a.installs,2) as Day1_retention from ( select distinct install_dt, count(player_id) over(partition by install_dt) as installs from player_install_date ) a left join player_day1_back b on b.install_dt = a.install_dt ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/game-play-analysis-v/","summary":"é¡Œç›® Table: Activity +--------------+---------+ | Column Name | Type | +--------------+---------+ | player_id | int | | device_id | int | | event_date | date | | games_played | int | +--------------+---------+ (player_id, event_date) is the primary key of this table. This table shows the activity of players of some games. Each row is a record of a player who logged in and played a number of games (possibly","title":"[leetcode][Database][Hard] 1097. Game Play Analysis V"},{"content":"é¡Œç›® Table: Spending\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | spend_date | date | | platform | enum | | amount | int | +-------------+---------+ The table logs the history of the spending of users that make purchases from an online shopping website that has a desktop and a mobile application. (user_id, spend_date, platform) is the primary key of this table. The platform column is an ENUM type of (\u0026#39;desktop\u0026#39;, \u0026#39;mobile\u0026#39;). Write an SQL query to find the total number of users and the total amount spent using the mobile only, the desktop only, and both mobile and desktop together for each date.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Spending (user_id int, spend_date date, platform ENUM(\u0026#39;desktop\u0026#39;, \u0026#39;mobile\u0026#39;), amount int) Truncate table Spending insert into Spending (user_id, spend_date, platform, amount) values (\u0026#39;1\u0026#39;, \u0026#39;2019-07-01\u0026#39;, \u0026#39;mobile\u0026#39;, \u0026#39;100\u0026#39;) insert into Spending (user_id, spend_date, platform, amount) values (\u0026#39;1\u0026#39;, \u0026#39;2019-07-01\u0026#39;, \u0026#39;desktop\u0026#39;, \u0026#39;100\u0026#39;) insert into Spending (user_id, spend_date, platform, amount) values (\u0026#39;2\u0026#39;, \u0026#39;2019-07-01\u0026#39;, \u0026#39;mobile\u0026#39;, \u0026#39;100\u0026#39;) insert into Spending (user_id, spend_date, platform, amount) values (\u0026#39;2\u0026#39;, \u0026#39;2019-07-02\u0026#39;, \u0026#39;mobile\u0026#39;, \u0026#39;100\u0026#39;) insert into Spending (user_id, spend_date, platform, amount) values (\u0026#39;3\u0026#39;, \u0026#39;2019-07-01\u0026#39;, \u0026#39;desktop\u0026#39;, \u0026#39;100\u0026#39;) insert into Spending (user_id, spend_date, platform, amount) values (\u0026#39;3\u0026#39;, \u0026#39;2019-07-02\u0026#39;, \u0026#39;desktop\u0026#39;, \u0026#39;100\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚çµ±è¨ˆé€éç”¨æˆ¶ useråœ¨ä½¿ç”¨PC desktopã€æ‰‹æ©ŸAPP mobile ä»¥åŠå…©è€…çš†æœ‰ both çš„æ¡è³¼é‡‘é¡ amount ã€‚\nåˆ†é–‹è¨ˆç®—PC desktop å’Œæ‰‹æ©ŸAPPmobile ä¸¦ä¸å›°é›£ï¼Œå› æ­¤éœ€è¦è‘—æ‰‹è™•ç†çš„æ˜¯å…©è€…çš†æœ‰ both æ¡è³¼ç´€éŒ„çš„ç”¨æˆ¶ï¼Œä¸¦å°‡é€™äº›ç”¨æˆ¶å¾PC desktopå’Œæ‰‹æ©ŸAPPmobile çš„çµ±è¨ˆä¸­åˆ†é›¢å‡ºä¾†ã€‚ é€é with clause å»ºç«‹ p_user_platform è¡¨æ ¼ï¼Œå¾ spending è¡¨æ ¼å¸¶å‡º user_idã€ spend_dateï¼Œä¸¦é€é group by user_id, spend_date å°‡è³‡æ–™åˆ†çµ„ç‚ºæ¯å€‹ç”¨æˆ¶ user_id åœ¨æ¯å€‹ spend_date çš„æ¡è³¼è³‡æ–™ï¼Œä¸¦åˆ†é–‹åŠ ç¸½ platform=\u0026quot;mobile\u0026quot; ã€platform=\u0026quot;desktop\u0026quot; çš„æ¡è³¼æ•¸é‡ amountä»¥è³¦äºˆ mobild_amount å’Œ desktop_amount æ¬„ä½ã€‚ é€é with clause å»ºç«‹ p_user_summary è¡¨æ ¼ï¼Œåˆ¤æ–· mobild_amount å’Œ desktop_amount çš„å€¼ï¼Œå°‡æ¯ä½ç”¨æˆ¶åœ¨æ¯å€‹ spend_date çš„æ¡è³¼æƒ…å½¢åˆ†é¡æˆ desktopã€mobileå’ŒbothÂ é€™å€‹æ­¥é©Ÿä¹Ÿå¯ä»¥åœ¨å»ºç«‹ p_user_platform çš„éç¨‹ä¸­é€²è¡Œåˆ†é¡ï¼Œä½†æˆ‘å‚¾å‘æ˜ç¢ºæ¯å¼µè¡¨æ ¼çš„ç”¨é€”ï¼Œä»¥ä¾¿ç†è§£æ¯ä¸€å€‹ query statement ä¸­å¼•ç”¨çš„è³‡æ–™è¡¨æ ¼èˆ‡æ¬„ä½ã€‚ é€é with clause å»ºç«‹ p_spend_date è¡¨æ ¼ï¼Œä¸¦åœ¨ spending è¡¨æ ¼æ“·å–æ‰€æœ‰ä¸é‡è¤‡çš„ spend_date ï¼Œä¸¦å°‡æ¯å€‹ä¸é‡è¤‡çš„ spend_date æ“´å±•æˆå¸¶æœ‰ desktopã€mobileå’Œboth çš„ record ã€‚\né€™å€‹å‹•ä½œæœƒå°‡æ¯å€‹ä¸é‡è¤‡çš„ spend_date ï¼Œå¾åŸå…ˆçš„ 1 row æ“´å±•æˆ 3 rowsã€‚ é€éæŸ¥è©¢ p_spend_date ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œä½¿ç”¨ left join p_user_summary å¸¶å‡ºç›¸å°æ‡‰ spend_date ã€platform çš„ record setï¼Œä¸¦åˆ©ç”¨ spend_date ã€platform çµ±è¨ˆå‡ºè©² spend_date åœ¨ desktopã€mobileå’Œboth çš„ç¸½æ¡è³¼é‡ total_amount å’Œç¸½è¨ˆäººæ•¸ total_user ã€‚ è§£æ±ºæ–¹æ¡ˆ with p_user_platform as ( select user_id, spend_date, sum(case when platform = \u0026#39;mobile\u0026#39; then amount else 0 end) as mobile_amount, sum(case when platform = \u0026#39;desktop\u0026#39; then amount else 0 end) as desktop_amount from spending group by user_id, spend_date ), p_user_summary as ( select user_id, spend_date, if(mobile_amount \u0026gt; 0, if(desktop_amount \u0026gt; 0, \u0026#39;both\u0026#39;, \u0026#39;mobile\u0026#39;), \u0026#39;desktop\u0026#39;) as platform, mobile_amount + desktop_amount as amount from p_user_platform ), p_spend_date as ( select distinct(spend_date), \u0026#39;desktop\u0026#39; as platform from spending union select distinct(spend_date), \u0026#39;mobile\u0026#39; as platform from spending union select distinct(spend_date), \u0026#39;both\u0026#39; as platform from spending ) select a.spend_date, a.platform, sum(ifnull(b.amount,0)) as total_amount, count(b.user_id) as total_users from p_spend_date a left join p_user_summary b using(spend_date, platform) group by a.spend_date, a.platform ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/user-purchase-platform/","summary":"é¡Œç›® Table: Spending +-------------+---------+ | Column Name | Type | +-------------+---------+ | user_id | int | | spend_date | date | | platform | enum | | amount | int | +-------------+---------+ The table logs the history of the spending of users that make purchases from an online shopping website that has a desktop and a mobile application. (user_id, spend_date, platform) is the primary key of this table. The","title":"[leetcode][Database][Hard] 1127. User Purchase Platform"},{"content":"é¡Œç›® Table: Users\n+----------------+---------+ | Column Name | Type | +----------------+---------+ | user_id | int | | join_date | date | | favorite_brand | varchar | +----------------+---------+ user_id is the primary key of this table. This table has the info of the users of an online shopping website where users can sell and buy items. Table: Orders\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | order_id | int | | order_date | date | | item_id | int | | buyer_id | int | | seller_id | int | +---------------+---------+ order_id is the primary key of this table. item_id is a foreign key to the Items table. buyer_id and seller_id are foreign keys to the Users table. Table: Items\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | item_id | int | | item_brand | varchar | +---------------+---------+ item_id is the primary key of this table. Write an SQL query to find for each user whether the brand of the second item (by date) they sold is their favorite brand. If a user sold less than two items, report the answer for that user as no. It is guaranteed that no seller sold more than one item on a day.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Users (user_id int, join_date date, favorite_brand varchar(10)) Create table If Not Exists Orders (order_id int, order_date date, item_id int, buyer_id int, seller_id int) Create table If Not Exists Items (item_id int, item_brand varchar(10)) Truncate table Users insert into Users (user_id, join_date, favorite_brand) values (\u0026#39;1\u0026#39;, \u0026#39;2019-01-01\u0026#39;, \u0026#39;Lenovo\u0026#39;) insert into Users (user_id, join_date, favorite_brand) values (\u0026#39;2\u0026#39;, \u0026#39;2019-02-09\u0026#39;, \u0026#39;Samsung\u0026#39;) insert into Users (user_id, join_date, favorite_brand) values (\u0026#39;3\u0026#39;, \u0026#39;2019-01-19\u0026#39;, \u0026#39;LG\u0026#39;) insert into Users (user_id, join_date, favorite_brand) values (\u0026#39;4\u0026#39;, \u0026#39;2019-05-21\u0026#39;, \u0026#39;HP\u0026#39;) Truncate table Orders insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (\u0026#39;1\u0026#39;, \u0026#39;2019-08-01\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (\u0026#39;2\u0026#39;, \u0026#39;2019-08-02\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;) insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (\u0026#39;3\u0026#39;, \u0026#39;2019-08-03\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;) insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (\u0026#39;4\u0026#39;, \u0026#39;2019-08-04\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2\u0026#39;) insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (\u0026#39;5\u0026#39;, \u0026#39;2019-08-04\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;) insert into Orders (order_id, order_date, item_id, buyer_id, seller_id) values (\u0026#39;6\u0026#39;, \u0026#39;2019-08-05\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;) Truncate table Items insert into Items (item_id, item_brand) values (\u0026#39;1\u0026#39;, \u0026#39;Samsung\u0026#39;) insert into Items (item_id, item_brand) values (\u0026#39;2\u0026#39;, \u0026#39;Lenovo\u0026#39;) insert into Items (item_id, item_brand) values (\u0026#39;3\u0026#39;, \u0026#39;LG\u0026#39;) insert into Items (item_id, item_brand) values (\u0026#39;4\u0026#39;, \u0026#39;HP\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚åˆ¤æ–·æ¯ä½ seller è³£å‡ºçš„ç¬¬äºŒé … item æ˜¯å¦ç‚ºè©² seller çš„å–œæ„›å“ç‰Œï¼Œä¸¦è¼¸å‡º No å’Œ Yes ä½œç‚ºæ¯ä½ seller çš„åˆ†é¡çµæœã€‚è‹¥æŸä½ seller åªè³£å‡ºä¸€é … itemï¼Œå‰‡çµæœæ‡‰ç‚º Noã€‚ é€é with clause å»ºç«‹ order_info è¡¨æ ¼ï¼Œåˆ©ç”¨ rank()å‡½å¼ä¸¦ä¾æ“šè³£å‡ºæ—¥æœŸ orders.order_date ç‚ºæ¯ä¸€ç­†éŠ·å”®è³‡æ–™é€²è¡Œæ’åº rank_sell_itemã€‚\nåŒæ™‚ï¼Œç‚º order_info è¡¨æ ¼é—œè¯ usersè¡¨æ ¼ä»¥å¸¶å‡ºæ¯ä½ userçš„å–œæ„›å“ç‰Œ users.favorite_brandã€‚ é€é with clause å»ºç«‹ second_sell_brand è¡¨æ ¼ï¼Œä¸¦åˆ¤æ–· second_sell_brand.sell_brand = second_sell_brand.seller_fav_brand ä»¥è¼¸å‡º Yes å’Œ No ã€‚ é€éæŸ¥è©¢ users ä½œç‚ºä¸»è¦è¡¨æ ¼ï¼Œä½¿ç”¨ left join second_sell_brand å¸¶å‡ºæ¯ä½ seller è³£å‡ºç¬¬äºŒé … item æ˜¯å¦ç‚ºè‡ªå·±çš„å–œæ„›å“ç‰Œçµæœã€‚\nåœ¨å»ºç«‹ second_sell_brand è¡¨æ ¼æ™‚ï¼Œç”±æ–¼ç¯©é¸æ¢ä»¶ rank_sell_item=2 æœƒéæ¿¾æ‰åªè³£å‡ºéä¸€æ¬¡çš„ user è³‡è¨Šï¼›è€Œåœ¨ orders è¡¨æ ¼ä¸­ä¹Ÿå­˜åœ¨æŸäº› user æ²’æœ‰è³£å‡ºçš„ç´€éŒ„ã€‚\nå› æ­¤éœ€è¦é€é left join second_sell_brand ä¿è­‰æ¯ä½ user éƒ½åŒ…å«æ–¼æœ€çµ‚çš„è¼¸å‡ºçµæœä¸­ã€‚ è§£æ±ºæ–¹æ¡ˆ with order_info as ( select a.order_id, a.order_date, c.item_brand as sell_brand, a.seller_id, b.favorite_brand as seller_fav_brand, rank() over(partition by a.seller_id order by a.order_date) as rank_sell_item from orders a join users b on b.user_id = a.seller_id join items c on c.item_id = a.item_id order by a.order_id, a.order_date ), second_sell_brand as ( select seller_id, if(sell_brand=seller_fav_brand, \u0026#34;yes\u0026#34;, \u0026#34;no\u0026#34;) as 2nd_item_fav_brand from order_info where rank_sell_item = 2 ) select a.user_id as seller_id, ifnull(b.2nd_item_fav_brand,\u0026#34;no\u0026#34;) as 2nd_item_fav_brand from users a left join second_sell_brand b on b.seller_id = a.user_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/market-analysis-ii/","summary":"é¡Œç›® Table: Users +----------------+---------+ | Column Name | Type | +----------------+---------+ | user_id | int | | join_date | date | | favorite_brand | varchar | +----------------+---------+ user_id is the primary key of this table. This table has the info of the users of an online shopping website where users can sell and buy items. Table: Orders +---------------+---------+ | Column Name | Type | +---------------+---------+ | order_id | int","title":"[leetcode][Database][Hard] 1159. Market Analysis II"},{"content":"é¡Œç›® Table: Players\n+-------------+-------+ | Column Name | Type | +-------------+-------+ | player_id | int | | group_id | int | +-------------+-------+ player_id is the primary key of this table. Each row of this table indicates the group of each player. Table: Matches\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | match_id | int | | first_player | int | | second_player | int | | first_score | int | | second_score | int | +---------------+---------+ match_id is the primary key of this table. Each row is a record of a match, first_player and second_player contain the player_id of each match. first_score and second_score contain the number of points of the first_player and second_player respectively. You may assume that, in each match, players belong to the same group. The winner in each group is the player who scored the maximum total points within the group. In the case of a tie, the lowest player_id wins.\nWrite an SQL query to find the winner in each group.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Players (player_id int, group_id int) Create table If Not Exists Matches (match_id int, first_player int, second_player int, first_score int, second_score int) Truncate table Players insert into Players (player_id, group_id) values (\u0026#39;10\u0026#39;, \u0026#39;2\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;15\u0026#39;, \u0026#39;1\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;20\u0026#39;, \u0026#39;3\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;25\u0026#39;, \u0026#39;1\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;30\u0026#39;, \u0026#39;1\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;35\u0026#39;, \u0026#39;2\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;40\u0026#39;, \u0026#39;3\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;45\u0026#39;, \u0026#39;1\u0026#39;) insert into Players (player_id, group_id) values (\u0026#39;50\u0026#39;, \u0026#39;2\u0026#39;) Truncate table Matches insert into Matches (match_id, first_player, second_player, first_score, second_score) values (\u0026#39;1\u0026#39;, \u0026#39;15\u0026#39;, \u0026#39;45\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;0\u0026#39;) insert into Matches (match_id, first_player, second_player, first_score, second_score) values (\u0026#39;2\u0026#39;, \u0026#39;30\u0026#39;, \u0026#39;25\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;) insert into Matches (match_id, first_player, second_player, first_score, second_score) values (\u0026#39;3\u0026#39;, \u0026#39;30\u0026#39;, \u0026#39;15\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;0\u0026#39;) insert into Matches (match_id, first_player, second_player, first_score, second_score) values (\u0026#39;4\u0026#39;, \u0026#39;40\u0026#39;, \u0026#39;20\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;2\u0026#39;) insert into Matches (match_id, first_player, second_player, first_score, second_score) values (\u0026#39;5\u0026#39;, \u0026#39;35\u0026#39;, \u0026#39;50\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;) è§£é¡Œæ€è€ƒ æ¨ç´è¡¨è¦æ±‚è¼¸å‡ºæ¯å€‹ group å…§ç¸½è¨ˆå¾—åˆ†æœ€é«˜çš„ç©å®¶ï¼Œè‹¥é‡åˆ°å¹³åˆ†æƒ…æ³å‰‡ä»¥ player_id è¼ƒå°çš„ä¸€æ–¹ç²å‹ã€‚\né€™é¡Œçš„æ€è€ƒæ–¹å¼å’Œ [leetcode][Database][Hard]1972. First and Last Call On the Same Day é›·åŒã€‚ é€é with clause å»ºç«‹ max_score_of_player è¡¨æ ¼ï¼Œä¸¦åˆ†åˆ¥åŠ ç¸½æ¯ä½ player çš„ score ã€‚\nå°‡ score è¡¨æ ¼ä¸­çš„ first_player å’Œ second_player æ‹†åˆ†æˆå…©å¼µå­è¡¨ï¼Œä¸¦æ“·å– first_score å’Œ second_score ä»¥ä¾¿é€²è¡Œæ¯ä½ player çš„ score åŠ ç¸½ã€‚ é€é with clause å»ºç«‹ group_player_rank è¡¨æ ¼ï¼Œé¸æ“‡ players è¡¨æ ¼ä½œç‚ºæŸ¥è©¢ä¸»è¡¨ä¸¦é—œè¯ max_score_of_player ï¼Œä¸¦ä¾æ“š max_score_of_player.score é™åºå’Œ players.player_id å‡åºçš„æ–¹å¼ï¼Œåˆ©ç”¨ rank()å‡½æ•¸å°players.group é€²è¡Œæ’å rnã€‚ æœ€å¾Œï¼ŒæŸ¥è©¢ group_player_rank.rn ç‚º 1 çš„è³‡æ–™ï¼Œä¾¿èƒ½æ‰¾å‡ºæ¯å€‹ group ç¸½è¨ˆå¾—åˆ†æœ€é«˜çš„ player ã€‚ è§£æ±ºæ–¹æ¡ˆ with max_score_of_player as ( select player_id, sum(score) as score from ( select first_player as player_id, first_score as score from matches union all select second_player as player_id, second_score as score from matches ) a group by player_id ), group_player_rank as ( select a.group_id, a.player_id, rank() over(partition by a.group_id order by b.score desc, a.player_id asc) as rn from players a join max_score_of_player b using(player_id) ) select group_id, player_id from group_player_rank where rn = 1 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/tournament-winners/","summary":"é¡Œç›® Table: Players +-------------+-------+ | Column Name | Type | +-------------+-------+ | player_id | int | | group_id | int | +-------------+-------+ player_id is the primary key of this table. Each row of this table indicates the group of each player. Table: Matches +---------------+---------+ | Column Name | Type | +---------------+---------+ | match_id | int | | first_player | int | | second_player | int | | first_score |","title":"[leetcode][Database][Hard] 1194. Tournament Winners"},{"content":"é¡Œç›® Table: Product\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | product_id | int | | product_name | varchar | +---------------+---------+ product_id is the primary key for this table. product_name is the name of the product. Table: Sales\n+---------------------+---------+ | Column Name | Type | +---------------------+---------+ | product_id | int | | period_start | date | | period_end | date | | average_daily_sales | int | +---------------------+---------+ product_id is the primary key for this table. period_start and period_end indicate the start and end date for the sales period, and both dates are inclusive. The average_daily_sales column holds the average daily sales amount of the items for the period. The dates of the sales years are between 2018 to 2020. Write an SQL query to report the total sales amount of each item for each year, with corresponding product_name, product_id, product_name, and report_year.\nReturn the result table ordered by product_id and report_year.\nSQL Schema\nCreate table If Not Exists Product (product_id int, product_name varchar(30)) Create table If Not Exists Sales (product_id int, period_start date, period_end date, average_daily_sales int) Truncate table Product insert into Product (product_id, product_name) values (\u0026#39;1\u0026#39;, \u0026#39;LC Phone \u0026#39;) insert into Product (product_id, product_name) values (\u0026#39;2\u0026#39;, \u0026#39;LC T-Shirt\u0026#39;) insert into Product (product_id, product_name) values (\u0026#39;3\u0026#39;, \u0026#39;LC Keychain\u0026#39;) Truncate table Sales insert into Sales (product_id, period_start, period_end, average_daily_sales) values (\u0026#39;1\u0026#39;, \u0026#39;2019-01-25\u0026#39;, \u0026#39;2019-02-28\u0026#39;, \u0026#39;100\u0026#39;) insert into Sales (product_id, period_start, period_end, average_daily_sales) values (\u0026#39;2\u0026#39;, \u0026#39;2018-12-01\u0026#39;, \u0026#39;2020-01-01\u0026#39;, \u0026#39;10\u0026#39;) insert into Sales (product_id, period_start, period_end, average_daily_sales) values (\u0026#39;3\u0026#39;, \u0026#39;2019-12-01\u0026#39;, \u0026#39;2020-01-31\u0026#39;, \u0026#39;1\u0026#39;) è§£é¡Œæ€è€ƒ é€é with clause åˆ†åˆ¥å»ºç«‹ report_year 2018ã€2019 ä»¥åŠ 2020 çš„ç”¢å“éŠ·å”®è¡¨æ ¼ sell_2018ã€ sell_2019 ã€ sell_2020\nç”±æ–¼ sales è¡¨æ ¼çš„ period_start å’Œ period_end æœ‰è·¨è¶Šå¹´åº¦çš„å¯èƒ½æ€§ï¼Œè€Œåœ¨å…¶ä»–çš„æ¸¬è©¦è³‡æ–™é›†ä¸­ï¼Œä¹Ÿå¯èƒ½å«æœ‰æ—©æ–¼ 2018 å¹´çš„éŠ·å”®è³‡æ–™ï¼Œæˆ–è€…æ™šæ–¼ 2020 å¹´å¾Œçš„éŠ·å”®è³‡æ–™ï¼Œå› æ­¤éœ€è¦ç‰¹åˆ¥æ³¨æ„æ™‚é–“ç¯„åœçš„åˆ‡å‰²ã€‚ Union sell_2018 ã€ sell_2019 å’Œ sell_2020 ï¼Œä¸¦å¾ union è¡¨æ ¼ä¸­å–å‡ºæ¯æ—¥å¹³å‡éŠ·å”®é‡‘é¡ average_daily_sales ä¹˜ä»¥ç•¶å¹´åº¦æ•´é«”éŠ·å”®å¤©æ•¸ datediff(period_end, period_start)+1 ï¼Œä¾¿å¯å¾—åˆ°ç•¶å¹´åº¦çš„å¹³å‡éŠ·å”®ç¸½é¡ã€‚ è§£æ±ºæ–¹æ¡ˆ with sell_2018 as ( select product_id, if( year(period_start) \u0026lt; \u0026#39;2018\u0026#39;, \u0026#39;2018-01-01\u0026#39;, period_start) as period_start, if( year(period_end) \u0026gt; \u0026#39;2018\u0026#39;, DATE_FORMAT(period_end,\u0026#39;2018-12-31\u0026#39;), period_end ) as period_end, average_daily_sales from sales where year(period_start) \u0026lt;= \u0026#39;2018\u0026#39; ), sell_2019 as ( select product_id, if( year(period_start) \u0026lt; \u0026#39;2019\u0026#39;, \u0026#39;2019-01-01\u0026#39;, period_start) as period_start, if( year(period_end) \u0026gt; \u0026#39;2019\u0026#39;, DATE_FORMAT(period_end,\u0026#39;2019-12-31\u0026#39;), period_end ) as period_end, average_daily_sales from sales where year(period_start) \u0026lt;= \u0026#39;2019\u0026#39; and year(period_end) \u0026gt;= \u0026#39;2019\u0026#39; ), sell_2020 as ( select product_id, if( year(period_start) \u0026lt; \u0026#39;2020\u0026#39;, \u0026#39;2020-01-01\u0026#39;, period_start) as period_start, if( year(period_end) \u0026gt; \u0026#39;2020\u0026#39;, DATE_FORMAT(period_end,\u0026#39;2020-12-31\u0026#39;), period_end ) as period_end, average_daily_sales from sales where year(period_start) \u0026lt;= \u0026#39;2020\u0026#39; and year(period_end) \u0026gt;= \u0026#39;2020\u0026#39; ), product_sell_info as ( select a.product_id, b.product_name, date_format(a.period_start, \u0026#34;%Y\u0026#34;) as report_year, average_daily_sales * (datediff(a.period_end, a.period_start)+1) as total_amount from ( select * from sell_2018 union select * from sell_2019 union select * from sell_2020 ) a left join product b using(product_id) ) select product_id, product_name, report_year, total_amount from product_sell_info order by product_id, report_year ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/total-sales-amount-by-year/","summary":"é¡Œç›® Table: Product +---------------+---------+ | Column Name | Type | +---------------+---------+ | product_id | int | | product_name | varchar | +---------------+---------+ product_id is the primary key for this table. product_name is the name of the product. Table: Sales +---------------------+---------+ | Column Name | Type | +---------------------+---------+ | product_id | int | | period_start | date | | period_end | date | | average_daily_sales | int | +---------------------+---------+ product_id","title":"[leetcode][Database][Hard] 1384. Total Sales Amount by Year"},{"content":"é¡Œç›® Table: Orders\n+---------------+---------+ | Column Name | Type | +---------------+---------+ | order_id | int | | customer_id | int | | order_date | date | | item_id | varchar | | quantity | int | +---------------+---------+ (ordered_id, item_id) is the primary key for this table. This table contains information on the orders placed. order_date is the date item_id was ordered by the customer with id customer_id. Table: Items\n+---------------------+---------+ | Column Name | Type | +---------------------+---------+ | item_id | varchar | | item_name | varchar | | item_category | varchar | +---------------------+---------+ item_id is the primary key for this table. item_name is the name of the item. item_category is the category of the item. You are the business owner and would like to obtain a sales report for category items and the day of the week.\nWrite an SQL query to report how many units in each category have been ordered on each day of the week.\nReturn the result table ordered by category.\nSQL Schema\nCreate table If Not Exists Orders (order_id int, customer_id int, order_date date, item_id varchar(30), quantity int) Create table If Not Exists Items (item_id varchar(30), item_name varchar(30), item_category varchar(30)) Truncate table Orders insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2020-06-01\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2020-06-08\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;10\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;3\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2020-06-02\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;5\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;4\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2020-06-03\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;5\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;5\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2020-06-04\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;1\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;6\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2020-06-05\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;5\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;7\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;2020-06-05\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;10\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;8\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;2020-06-14\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;) insert into Orders (order_id, customer_id, order_date, item_id, quantity) values (\u0026#39;9\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;2020-06-21\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;5\u0026#39;) Truncate table Items insert into Items (item_id, item_name, item_category) values (\u0026#39;1\u0026#39;, \u0026#39;LC Alg. Book\u0026#39;, \u0026#39;Book\u0026#39;) insert into Items (item_id, item_name, item_category) values (\u0026#39;2\u0026#39;, \u0026#39;LC DB. Book\u0026#39;, \u0026#39;Book\u0026#39;) insert into Items (item_id, item_name, item_category) values (\u0026#39;3\u0026#39;, \u0026#39;LC SmarthPhone\u0026#39;, \u0026#39;Phone\u0026#39;) insert into Items (item_id, item_name, item_category) values (\u0026#39;4\u0026#39;, \u0026#39;LC Phone 2020\u0026#39;, \u0026#39;Phone\u0026#39;) insert into Items (item_id, item_name, item_category) values (\u0026#39;5\u0026#39;, \u0026#39;LC SmartGlass\u0026#39;, \u0026#39;Glasses\u0026#39;) insert into Items (item_id, item_name, item_category) values (\u0026#39;6\u0026#39;, \u0026#39;LC T-Shirt XL\u0026#39;, \u0026#39;T-shirt\u0026#39;) è§£é¡Œæ€è€ƒ æ¨ç´è¡¨è¦æ±‚ä¾æ“šåˆ†é¡ categoryåˆ—å‡ºå‘¨ä¸€è‡³å‘¨æ—¥çš„æ•¸é‡ quantityçµ±è¨ˆï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ left join é€ä¸€åˆ—å‡ºæ¨ç´è¡¨å‘¨ä¸€è‡³å‘¨æ—¥çš„æ¬„ä½ã€‚ +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ | Category | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | Sunday | +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ | Book | 20 | 5 | 0 | 0 | 10 | 0 | 0 | | Glasses | 0 | 0 | 0 | 0 | 5 | 0 | 0 | | Phone | 0 | 0 | 5 | 1 | 0 | 0 | 10 | | T-Shirt | 0 | 0 | 0 | 0 | 0 | 0 | 0 | +------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+ åˆ©ç”¨ dayOfWeek() å°‡ orders.order_date è½‰æ›æˆå‘¨ä¸€è‡³å‘¨æ—¥ dayï¼Œä¸¦é€é with clause å»ºç«‹æ–°è¡¨æ ¼ orders_with_groupï¼Œæ“·å– orders.order_id ã€orders.quantity dayOfWeek() è½‰æ›å¾Œçš„ day ä»¥åŠå’Œ items è¡¨æ ¼é—œè¯å¾Œå–å¾—çš„ items.item_category æ¬„ä½ ä¾æ“š orders_with_groupåŠ ç¸½æ¯å€‹ day çš„ quantity ï¼Œä¸¦é€é with clause å»ºç«‹æ–°è¡¨ sum_quantity_by_category ã€‚\næœ€å¾Œï¼Œå¾ items è¡¨æ ¼åˆ—å‡ºä¸é‡è¤‡çš„ item_category ï¼Œä¸¦åˆ©ç”¨ left join åˆ†åˆ¥é—œè¯å‘¨ä¸€è‡³å‘¨æ—¥ day çš„ quantity åŠ ç¸½ã€‚ è§£æ±ºæ–¹æ¡ˆ with orders_with_group as ( select a.order_id, dayofweek(a.order_date) as day, b.item_category, a.quantity from orders a join items b using(item_id) ), sum_quantity_by_category as ( select item_category, day, sum(quantity) as sum_quantity from orders_with_group group by item_category, day ) select distinct(a.item_category) as Category, ifnull(Mon.sum_quantity, 0) as Monday, ifnull(Tue.sum_quantity, 0) as Tuesday, ifnull(Wen.sum_quantity, 0) as Wednesday, ifnull(Thu.sum_quantity, 0) as Thursday, ifnull(Fri.sum_quantity, 0) as Friday, ifnull(Sat.sum_quantity, 0) as Saturday, ifnull(Sun.sum_quantity, 0) as Sunday from items a left join ( select item_category, sum_quantity from sum_quantity_by_category where day=2) Mon using(item_category) left join ( select item_category, sum_quantity from sum_quantity_by_category where day=3) Tue using(item_category) left join ( select item_category, sum_quantity from sum_quantity_by_category where day=4) Wen using(item_category) left join ( select item_category, sum_quantity from sum_quantity_by_category where day=5) Thu using(item_category) left join ( select item_category, sum_quantity from sum_quantity_by_category where day=6) Fri using(item_category) left join ( select item_category, sum_quantity from sum_quantity_by_category where day=7) Sat using(item_category) left join ( select item_category, sum_quantity from sum_quantity_by_category where day=1) Sun using(item_category) order by a.item_category /* Map the return value of function dayOfWeek and text 1 = Sunday 2 = Monday 3 = Tuesday 4 = Wednesday 5 = Thursday 6 = Friday 7 = Saturday */ ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/sales-by-day-of-the-week/","summary":"é¡Œç›® Table: Orders +---------------+---------+ | Column Name | Type | +---------------+---------+ | order_id | int | | customer_id | int | | order_date | date | | item_id | varchar | | quantity | int | +---------------+---------+ (ordered_id, item_id) is the primary key for this table. This table contains information on the orders placed. order_date is the date item_id was ordered by the customer with id customer_id. Table: Items","title":"[leetcode][Database][Hard] 1479. Sales by Day of the Week"},{"content":"é¡Œç›® Table: Calls\n+--------------+----------+ | Column Name | Type | +--------------+----------+ | caller_id | int | | recipient_id | int | | call_time | datetime | +--------------+----------+ (caller_id, recipient_id, call_time) is the primary key for this table. Each row contains information about the time of a phone call between caller_id and recipient_id. Write an SQL query to report the IDs of the users whose first and last calls on any day were with the same person. Calls are counted regardless of being the caller or the recipient.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Calls (caller_id int, recipient_id int, call_time datetime) Truncate table Calls insert into Calls (caller_id, recipient_id, call_time) values (\u0026#39;8\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2021-08-24 17:46:07\u0026#39;) insert into Calls (caller_id, recipient_id, call_time) values (\u0026#39;4\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;2021-08-24 19:57:13\u0026#39;) insert into Calls (caller_id, recipient_id, call_time) values (\u0026#39;5\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2021-08-11 05:28:44\u0026#39;) insert into Calls (caller_id, recipient_id, call_time) values (\u0026#39;8\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2021-08-17 04:04:15\u0026#39;) insert into Calls (caller_id, recipient_id, call_time) values (\u0026#39;11\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2021-08-17 13:07:00\u0026#39;) insert into Calls (caller_id, recipient_id, call_time) values (\u0026#39;8\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;2021-08-17 22:22:22\u0026#39;) è§£é¡Œæ€è€ƒ å»ºç«‹ user_callsçš„ with clauseï¼Œä»¥æä¾›æœ€å¾Œè¼¸å‡ºçš„è¡¨æ ¼ä½¿ç”¨ã€‚\nuser_callså°‡æ¯ç­† calls ä¸­çš„é€šè©±ç´€éŒ„æ‹†åˆ†æˆå…©ç­† record ï¼Œå³è©²ç­†é€šè©±ç´€éŒ„çš„å…©ä½ user åˆ†åˆ¥ä»¥è‡ªå·±çš„è§’åº¦ï¼Œç´€éŒ„è©²ç­†é€šè©±çš„æ™‚é–“ä»¥åŠé€šè©±çš„å°è±¡\nA â† communicate â†’ BÂ : A â†’ B and B â†’ A å»ºç«‹ rank_calls çš„ with clause ï¼Œå° user_calls ä¸­çš„é€šè©±ç´€éŒ„é€²è¡Œæ’åºã€‚\nå°æ¯å€‹ user_id çš„æ‰€æœ‰ call_time é€šè©±æ™‚é–“åš å‡åº å’Œ é™åºï¼Œä»¥ä¾¿æ‰¾å‡ºç¬¬ä¸€ç­†é€šè©± first call å’Œæœ€å¾Œä¸€ç­†é€šè©± last call ã€‚ å° rank_calls æ¯å€‹ user_id çš„ first call å’Œ last call é€²è¡Œçµ±è¨ˆï¼Œè‹¥ä¸é‡è¤‡çš„é€šè©±å°è±¡åªæœ‰ä¸€ä½ï¼Œå‰‡å¯ä»¥æ‰¾å‡º first call å’Œ last call éƒ½æ˜¯åŒä¸€äººçš„ user_id è§£æ±ºæ–¹æ¡ˆ with user_calls as ( select caller_id as user_id, call_time, recipient_id from calls union select recipient_id as user_id, call_time, caller_id as recipient_id from calls ), rank_calls as ( select user_id, recipient_id, date(call_time) as day, dense_rank() over(partition by user_id, date(call_time) order by call_time asc) as rn, dense_rank() over(partition by user_id, date(call_time) order by call_time desc) as rk from user_calls ) select distinct user_id from rank_calls where rn=1 or rk=1 group by user_id, day having count(distinct recipient_id) = 1 ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/first-and-last-call-on-the-same-day/","summary":"é¡Œç›® Table: Calls +--------------+----------+ | Column Name | Type | +--------------+----------+ | caller_id | int | | recipient_id | int | | call_time | datetime | +--------------+----------+ (caller_id, recipient_id, call_time) is the primary key for this table. Each row contains information about the time of a phone call between caller_id and recipient_id. Write an SQL query to report the IDs of the users whose first and last calls on","title":"[leetcode][Database][Hard]1972. First and Last Call On the Same Day"},{"content":"é¡Œç›® Table: Candidates\n+-------------+------+ | Column Name | Type | +-------------+------+ | employee_id | int | | experience | enum | | salary | int | +-------------+------+ employee_id is the primary key column for this table. experience is an enum with one of the values (\u0026#39;Senior\u0026#39;, \u0026#39;Junior\u0026#39;). Each row of this table indicates the id of a candidate, their monthly salary, and their experience. A company wants to hire new employees. The budget of the company for the salaries is $70000. The company\u0026rsquo;s criteria for hiring are:\nHiring the largest number of seniors. After hiring the maximum number of seniors, use the remaining budget to hire the largest number of juniors. Write an SQL query to find the number of seniors and juniors hired under the mentioned criteria.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Candidates (employee_id int, experience ENUM(\u0026#39;Senior\u0026#39;, \u0026#39;Junior\u0026#39;), salary int) Truncate table Candidates insert into Candidates (employee_id, experience, salary) values (\u0026#39;1\u0026#39;, \u0026#39;Junior\u0026#39;, \u0026#39;10000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;9\u0026#39;, \u0026#39;Junior\u0026#39;, \u0026#39;10000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;2\u0026#39;, \u0026#39;Senior\u0026#39;, \u0026#39;20000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;11\u0026#39;, \u0026#39;Senior\u0026#39;, \u0026#39;20000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;13\u0026#39;, \u0026#39;Senior\u0026#39;, \u0026#39;50000\u0026#39;) insert into Candidates (employee_id, experience, salary) values (\u0026#39;4\u0026#39;, \u0026#39;Junior\u0026#39;, \u0026#39;40000\u0026#39;) è§£é¡Œæ€è€ƒ æ¨ç´è¡¨è¦æ±‚è¼¸å‡º Senioré›‡å“¡å’Œ Junioré›‡å“¡çš„å¯æ‹›è˜äººæ•¸ã€‚\nåˆ©ç”¨å­æŸ¥è©¢åŠŸèƒ½ï¼Œåˆ†åˆ¥å¸¶å‡º Seniorå’Œ Juniorçš„æ‹›è˜çµæœï¼Œä»¥ä½œç‚ºæ¨ç´è¡¨çš„æ¬„ä½å€¼ã€‚ åˆ©ç”¨ with clause å»ºç«‹ Senioré›‡å“¡ã€ Junioré›‡å“¡çš„è–ªæ°´æ’åºè¡¨ã€‚\nå› é¡Œç›®è¦æ±‚å¿…é ˆå…ˆæ‹›è˜ç›¡å¯èƒ½å¤šçš„ Senior é›‡å“¡ï¼Œå†åˆ©ç”¨å‰©é¤˜é ç®—æœè˜ç›¡å¯èƒ½å¤šçš„ Junior é›‡å“¡ è–ªæ°´æ’åºè¡¨ä¸­ï¼Œç”¨ row_number() æ¨™è¨»æ’åºçµæœï¼Œæ’åºä¸»è¦æ¢ä»¶ç‚ºè–ªè³‡ salary å‡åºï¼›åŒæ™‚æ’åºçµæœå¯åšç‚ºç¬¬å¹¾ä½é›‡å“¡ï¼Œå³å¯æ‹›è˜çš„é›‡å“¡æ•¸é‡ è–ªæ°´æ’åºè¡¨ä¸­ï¼Œä¾æ“šè–ªè³‡ salary å’Œé›‡å“¡ç·¨è™Ÿ employee_id ç´¯åŠ é›‡å“¡è–ªè³‡ï¼›åŒæ™‚ç´¯åŠ é›‡å“¡è–ªè³‡å¯åšç‚ºå·²æ¶ˆè€—çš„é ç®— budget æŸ¥è©¢æ‹›è˜ senior èŠ±è²»çš„é ç®— cumulate_budget ã€‚\nå– cumulate_budget \u0026lt;= budget çš„ record setï¼Œä¸¦å¾ä¸­æ‰¾å‡º max(rn) èˆ‡å°æ‡‰çš„ senior.cumulate_budget è¨ˆç®—å¯åˆ†é…çµ¦Junioræ‹›è˜çš„å‰©é¤˜é ç®— remaining = budget - senior.cumulate_budget ï¼Œå– junior.cumulate_budget \u0026lt;= emaining çš„ record setï¼Œä¸¦å¾ä¸­æ‰¾å‡º max(rn) èˆ‡å°æ‡‰çš„ junior.cumulate_budget è§£æ±ºæ–¹æ¡ˆ with seniors_salary_rank as ( select employee_id, salary, row_number() over(order by salary, employee_id) as rn, sum(salary) over(order by salary, employee_id) as cumulate_budget from candidates where experience = \u0026#39;senior\u0026#39; order by salary ), juniors_salary_rank as ( select employee_id, salary, row_number() over(order by salary, employee_id asc) as rn, sum(salary) over(order by salary, employee_id) as cumulate_budget from candidates where experience = \u0026#39;junior\u0026#39; order by salary ), hire_seniors as ( select b.rn, 70000 - b.cumulate_budget as remain_budget from ( select max(cumulate_budget) as cumulate_budget from seniors_salary_rank where cumulate_budget \u0026lt;= 70000 ) a join seniors_salary_rank b using(cumulate_budget) ), hire_junior as ( select b.rn, ifnull((select remain_budget from hire_seniors limit 1),70000) - b.cumulate_budget as remain_budget from ( select max(cumulate_budget) as cumulate_budget from juniors_salary_rank where cumulate_budget \u0026lt;= ifnull((select remain_budget from hire_seniors limit 1),70000) ) a join juniors_salary_rank b using(cumulate_budget) ) select distinct(experience) as experience, case when experience = \u0026#39;Senior\u0026#39; then ifnull((select rn from hire_seniors limit 1 ),0) when experience = \u0026#39;Junior\u0026#39; then ifnull((select rn from hire_junior limit 1 ),0) end as accepted_candidates from candidates a ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/the-number-of-seniors-and-juniors-to-join-the-company/","summary":"é¡Œç›® Table: Candidates +-------------+------+ | Column Name | Type | +-------------+------+ | employee_id | int | | experience | enum | | salary | int | +-------------+------+ employee_id is the primary key column for this table. experience is an enum with one of the values (\u0026#39;Senior\u0026#39;, \u0026#39;Junior\u0026#39;). Each row of this table indicates the id of a candidate, their monthly salary, and their experience. A company wants to hire","title":"[leetcode][Database][Hard] 2004. The Number of Seniors and Juniors to Join the Company"},{"content":"é¡Œç›® Table: Buses\n+--------------+------+ | Column Name | Type | +--------------+------+ | bus_id | int | | arrival_time | int | | capacity | int | +--------------+------+ bus_id is the primary key column for this table. Each row of this table contains information about the arrival time of a bus at the LeetCode station and its capacity (the number of empty seats it has). No two buses will arrive at the same time and all bus capacities will be positive integers. Table: Passengers\n+--------------+------+ | Column Name | Type | +--------------+------+ | passenger_id | int | | arrival_time | int | +--------------+------+ passenger_id is the primary key column for this table. Each row of this table contains information about the arrival time of a passenger at the LeetCode station. Buses and passengers arrive at the LeetCode station. If a bus arrives at the station at a time tbus and a passenger arrived at a time tpassenger where tpassenger \u0026lt;= tbus and the passenger did not catch any bus, the passenger will use that bus. In addition, each bus has a capacity. If at the moment the bus arrives at the station there are more passengers waiting than its capacity capacity, only capacity passengers will use the bus.\nWrite an SQL query to report the number of users that used each bus.\nReturn the result table ordered by bus_id in ascending order.\nSQL Schema\nCreate table If Not Exists Buses (bus_id int, arrival_time int, capacity int) Create table If Not Exists Passengers (passenger_id int, arrival_time int) Truncate table Buses insert into Buses (bus_id, arrival_time, capacity) values (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;1\u0026#39;) insert into Buses (bus_id, arrival_time, capacity) values (\u0026#39;2\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;10\u0026#39;) insert into Buses (bus_id, arrival_time, capacity) values (\u0026#39;3\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;2\u0026#39;) Truncate table Passengers insert into Passengers (passenger_id, arrival_time) values (\u0026#39;11\u0026#39;, \u0026#39;1\u0026#39;) insert into Passengers (passenger_id, arrival_time) values (\u0026#39;12\u0026#39;, \u0026#39;1\u0026#39;) insert into Passengers (passenger_id, arrival_time) values (\u0026#39;13\u0026#39;, \u0026#39;5\u0026#39;) insert into Passengers (passenger_id, arrival_time) values (\u0026#39;14\u0026#39;, \u0026#39;6\u0026#39;) insert into Passengers (passenger_id, arrival_time) values (\u0026#39;15\u0026#39;, \u0026#39;7\u0026#39;) è§£é¡Œæ€è€ƒ ä¹˜å®¢ passenger çš„æŠµé”æ™‚é–“éœ€è¦åœ¨å…¬è»Š bus æŠµé”ä¹‹å‰ï¼Œè¨ˆç®—æ¯ç­å…¬è»Š bus_id æŠµé”æ™‚ï¼Œå¯èƒ½æ½›åœ¨çš„ä¹˜å®¢ passenger_id ç¸½æ•¸é‡ã€‚\nç”±æ–¼å…¬è»Š bus_id çš„é‹è¼‰èƒ½åŠ› capacity å¯èƒ½ç„¡æ³•æ»¿è¶³ç•¶å‰ç­‰å¾…ä¸­çš„æ‰€æœ‰ä¹˜å®¢ passenger_id ï¼Œ å› æ­¤å…ˆè¡Œè¨ˆç®—æ¯ç­å…¬è»Šå¯èƒ½éœ€è¦è² è·çš„ä¹˜å®¢é‹è¼‰é‡ æ‰¿ä¸Šï¼Œæ¯”è¼ƒç•¶å‰å…¬è»Š bus_idé‹è¼‰èƒ½åŠ› capacity èˆ‡ç­‰å¾…æ­ä¹˜çš„ä¹˜å®¢æ•¸é‡ï¼Œä¸¦å¾å…©è€…ä¸­å–æœ€å°å€¼ï¼Œè¡¨é”æ­ä¹˜è©²ç­æ¬¡å…¬è»Š bus_id çš„å¯¦éš›ä¹˜å®¢æ•¸é‡ å¯èƒ½å­˜åœ¨çš„ä¹˜å®¢æ•¸ - ç´¯ç©çš„ä¹˜å®¢æ•¸ = å¯¦éš›æ­ä¹˜çš„ä¹˜å®¢æ•¸é‡ å»ºç«‹æš«å­˜è¡¨åˆå§‹åŒ– mysql variable ï¼Œç”¨ä»¥ æš«å­˜å¯¦éš›æ­ä¹˜çš„ä¹˜å®¢æ•¸é‡ å’Œ å¯èƒ½å­˜åœ¨çš„ä¹˜å®¢æ•¸ è§£æ±ºæ–¹æ¡ˆ with people_possiable_take_bus as ( /* Finding the possible passengers with each bus regardless of passenger catch the bus or not, that will cumulate all of passengers whoes previous arrival */ select a.bus_id, a.arrival_time, a.capacity, count(b.passenger_id) as possible_passenger_cnt from buses a left join passengers b on b.arrival_time \u0026lt;= a.arrival_time group by a.bus_id order by a.arrival_time ), alloc_people_take_bus as ( /* Calculating how many passengers can loaded by each bus, and accumulate passengers regardless of passenger catch bus or not, due to caulse `people_possiable_take_bus` pre-calculate the possible passengers with each bus, and the situation for the passengers whoes cannot catch currently or pervious bus includes of the statement `least(capacity, possible_passenger_cnt-@accum_passengers)`, that\u0026#39;s why we can directly to calculate `possible_passenger_cnt-@accum_passengers` and compare bus\u0026#39;s capacity and `possible_passenger_cnt-@accum_passengers` to take the least value */ select bus_id, passengers_cnt from ( select a.bus_id, @passengers_cnt := least(capacity, possible_passenger_cnt-@accum_passengers) as passengers_cnt, @accum_passengers := @accum_passengers + @passengers_cnt from people_possiable_take_bus a, (select @passengers_cnt := 0, @accum_passengers :=0) b ) output ) select bus_id, passengers_cnt from alloc_people_take_bus order by bus_id ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/the-number-of-passengers-in-each-bus-ii/","summary":"é¡Œç›® Table: Buses +--------------+------+ | Column Name | Type | +--------------+------+ | bus_id | int | | arrival_time | int | | capacity | int | +--------------+------+ bus_id is the primary key column for this table. Each row of this table contains information about the arrival time of a bus at the LeetCode station and its capacity (the number of empty seats it has). No two buses will arrive","title":"[leetcode][Database][Hard] 2153. The Number of Passengers in Each Bus II"},{"content":"é¡Œç›® Table: Products\n+-------------+---------+ | Column Name | Type | +-------------+---------+ | product_id | int | | store | varchar | | price | int | +-------------+---------+ (product_id, store) is the primary key for this table. Each row of this table indicates the price of product_id in store. There will be at most 30 different stores in the table. price is the price of the product at this store. Important note: This problem targets those who have a good experience with SQL. If you are a beginner, we recommend that you skip it for now.\nImplement the procedure PivotProducts to reorganize the Products table so that each row has the id of one product and its price in each store. The price should be null if the product is not sold in a store. The columns of the table should contain each store and they should be sorted in lexicographical order.\nThe procedure should return the table after reorganizing it.\nReturn the result table in any order.\nSQL Schema\nCreate table If Not Exists Products (product_id int, store varchar(7), price int) Truncate table Products insert into Products (product_id, store, price) values (\u0026#39;1\u0026#39;, \u0026#39;Shop\u0026#39;, \u0026#39;110\u0026#39;) insert into Products (product_id, store, price) values (\u0026#39;1\u0026#39;, \u0026#39;LC_Store\u0026#39;, \u0026#39;100\u0026#39;) insert into Products (product_id, store, price) values (\u0026#39;2\u0026#39;, \u0026#39;Nozama\u0026#39;, \u0026#39;200\u0026#39;) insert into Products (product_id, store, price) values (\u0026#39;2\u0026#39;, \u0026#39;Souq\u0026#39;, \u0026#39;190\u0026#39;) insert into Products (product_id, store, price) values (\u0026#39;3\u0026#39;, \u0026#39;Shop\u0026#39;, \u0026#39;1000\u0026#39;) insert into Products (product_id, store, price) values (\u0026#39;3\u0026#39;, \u0026#39;Souq\u0026#39;, \u0026#39;1900\u0026#39;) è§£é¡Œæ€è€ƒ é¡Œç›®è¦æ±‚è¼¸å‡ºæ¯å€‹ç”¢å“ product åœ¨æ¯é–“å•†åº—çš„å”®åƒ¹ +------------+----------+--------+------+------+ | product_id | LC_Store | Nozama | Shop | Souq | +------------+----------+--------+------+------+ | 1 | 100 | null | 110 | null | | 2 | null | 200 | null | 190 | | 3 | null | null | 1000 | 1900 | +------------+----------+--------+------+------+ ä½¿ç”¨ group_concat() çµ„åˆæ¨ç´è¡¨æ¬„ä½çš„ sql statementï¼Œå› æ¨ç´è¡¨éœ€ä¾æ“š store åˆ—å‡ºæ¬„ä½ï¼Œè€Œ store çš„æ•¸ç›®æ˜¯ä¸å›ºå®šçš„ã€‚ ä½¿ç”¨ prepare statement åŸ·è¡ŒåŒ…å« group_concat() é å…ˆçµ„åˆå¥½çš„ sql statement ä½¿ç”¨ group product_id å°æ¨ç´è¡¨é€²è¡Œç¸½è¨ˆï¼Œå› æ¨ç´è¡¨è¦æ±‚ä¾æ“š product çµ±è¨ˆåœ¨ä¸åŒ store ä¸­çš„å”®åƒ¹ price è§£æ±ºæ–¹æ¡ˆ CREATE PROCEDURE PivotProducts() BEGIN -- Override GROUP_CONCAT length which has a default limit of 1024 SET SESSION group_concat_max_len = 1000000; -- Store case statement for dynamically generated columns in a variable ie case_stmt SET @case_stmt = NULL; SELECT GROUP_CONCAT(DISTINCT CONCAT(\u0026#39;SUM(CASE WHEN store = \u0026#34;\u0026#39;, store, \u0026#39;\u0026#34; THEN price END) AS \u0026#39;, store)) INTO @case_stmt FROM products; -- Insert above statement (@case_stmt) in the following main query to frame final query SET @sql_query = CONCAT(\u0026#39;SELECT product_id, \u0026#39;, @case_stmt, \u0026#39; FROM products GROUP BY product_id\u0026#39;); -- Execute final query PREPARE final_sql_query FROM @sql_query; EXECUTE final_sql_query; DEALLOCATE PREPARE final_sql_query; END ","permalink":"https://blog.zhengweiliu.com/posts/leetcode/database/dynamic-pivoting-of-a-table/","summary":"é¡Œç›® Table: Products +-------------+---------+ | Column Name | Type | +-------------+---------+ | product_id | int | | store | varchar | | price | int | +-------------+---------+ (product_id, store) is the primary key for this table. Each row of this table indicates the price of product_id in store. There will be at most 30 different stores in the table. price is the price of the product at this store.","title":"[leetcode][Database][Hard] 2252. Dynamic Pivoting of a Table"},{"content":"åœ¨ [Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„ (äºŒ)]ä¸­æåˆ°äº† User Behaviorï¼Œä½† User Behavior çš„è³‡æ–™å¾å“ªè£¡ä¾†ï¼Œåˆè©²å¦‚ä½•å®šç¾©å‘¢Â ? Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„ (äºŒ) Date: 2022-03-28 \u0026nbsp; Categories: #Customer Data Platform\u0026nbsp; é¡¯è€Œæ˜“è¦‹ï¼Œè¨è«–å‡ºä¸€å€‹æœ‰å…±è­˜ã€è¦ºå¾—å¯è¡Œçš„æ–¹å¼å°‡å•é¡Œé€²è¡Œè½‰åŒ–ï¼Œé€™å°±å±¬æ–¼æ´å¯Ÿ(Insights)ï¼›è€Œè¢«æå‡ºçš„å•é¡Œæœ¬èº«ï¼Œå‰‡æ˜¯è¢«ç™¼ç¾çš„ç•°å¸¸(Anomaly)ã€‚åŸæ–‡æœ€å¾Œæå‡ºã€Œå…·æœ‰è©•åˆ†ç­‰ç´šçš„ä½¿ç”¨è€…æ¸…å–®ã€å‰‡æ˜¯è²¢ç»(Contribute)ã€‚ æœ‰è¶£çš„æ˜¯ï¼Œç•¶ç‡ŸéŠ·äººå“¡ä¾æ“šæ¸…å–®é€²è¡Œé ç®—æŠ•æ”¾å¾Œï¼Œä¾¿åˆèƒ½ç²å–æ–°ä¸€è¼ªçš„çµæœï¼Œé€™å€‹çµæœé™¤äº†å¯ä¾›é©—è­‰ï¼ŒåŒæ™‚ä¹Ÿå…·å‚™ç™¼ç¾æ–°ç•°å¸¸çš„å¯èƒ½æ€§ã€‚ ...... ä»¥ GA ( Google Analytics ) ç‚ºä¾‹ï¼Œåœ¨ Web æˆ– Mobile APP ä¸­é€²è¡Œ GA åŸ‹ codeï¼Œé€™äº› code å¯ä»¥æ˜¯ GA é è¨­çš„äº‹ä»¶ï¼Œå¦‚Â : Page View ã€ Session Engagement ã€ Activity Userï¼Œæˆ–è€…æ˜¯è‡ªå®šç¾©çš„ event ç­‰ç­‰ã€‚ GCP BigQuery æä¾›çš„ Public datasets ä¸­ä¹Ÿæä¾›å·²å°‡ GA è³‡æ–™è½‰åŒ–ç‚º ecommerce çš„ dataset ï¼Œä¾†æºç‚º Qwiklabs: Predict Visitor Purchases with a Classification Model in BQML\næœ¬ç¯‡æ–‡ç« ä¹Ÿåˆ©ç”¨é€™ä»½å…¬é–‹è³‡æ–™é›†é€²è¡Œèªªæ˜Â :\nWhat Goal We Need Feature and Label Improve and Tune User Behavior æ¯”è¼ƒç›´è§€çš„æ˜¯å° behavior çš„ç†è§£ï¼Œå¯ä»¥æƒ³åƒç•¶æ¶ˆè²»è€…åœ¨ä¸åŒçš„ E-Commerce website é€²è¡Œç€è¦½å•†å“ã€ç²å¾—æ¨è–¦æˆ–æ˜¯è³¼ç‰©è»Šçµå¸³ç­‰æ“ä½œæ™‚ï¼Œç”±æ–¼ website çš„è¨­è¨ˆä¸åŒï¼Œæ¶ˆè²»è€…å¯èƒ½éœ€è¦è·¨è¶Šä¸åŒçš„é é¢ã€é»æ“Šä¸åŒçš„é€£çµï¼Œæˆ–æ˜¯è¼¸å…¥ä¸åŒçš„è³‡æ–™ç­‰ç­‰ã€‚\nå› æ­¤ï¼Œæ¶ˆè²»è€…åœ¨ website A èˆ‡ website B çš„ ã€Œbehaviorã€ä¹Ÿæœƒä¸åŒï¼›å¾å¦å¤–ä¸€å€‹è§’åº¦ä¾†çœ‹Â : åŒä¸€å€‹ website ä¸­ï¼Œæ¶ˆè²»è€…è¦é”æˆç›¸åŒç›®çš„çš„æ“ä½œï¼Œå¿…å®šæœƒåœ¨æœ‰é™å€‹æ•¸çš„æ“ä½œé€”å¾‘ä¸­å®Œæˆã€‚è€Œé€™äº›é€”å¾‘ä¹Ÿå°±æ§‹æˆäº† User Behavior åŸºæœ¬å–®ä½ï¼Œè€Œæœ‰é‡å°æ€§ã€ç›®çš„æ€§çš„å°é€”å¾‘è³‡æ–™é€²è¡ŒæŒ‘é¸ï¼Œä¹Ÿå°±æ§‹æˆäº†ä¸€å€‹ specific behavior çš„å®šç¾©ã€‚\nWhat Goal We NeedÂ ? åœ¨ä¸€é–‹å§‹æœƒæƒ³çŸ¥é“ website è¨ªå•äººæ•¸ã€è³¼è²·æ¬¡æ•¸ä»¥åŠè½‰åŒ–ç‡å„æ˜¯å¤šå°‘ï¼›å¦‚ä¸‹åœ–æ‰€ç¤ºï¼Œåˆ†åˆ¥æ˜¯\nè¨ªå•äººæ•¸Â : ç´„ 74 è¬ è³¼è²·æ¬¡æ•¸Â : ç´„ 2 è¬ è½‰åŒ–ç‡Â : ç´„ 2.7% ç„¶è€Œï¼Œåƒ…å¾çµæœå±¤é¢ç²å¾—çš„è³‡æ–™ï¼Œç„¡æ³•æè¿°æ¯é …å•†å“çš„éŠ·å”®æƒ…æ³ï¼Œå› æ­¤å°æ¯é …å•†å“é€²è¡Œæ’æ¯”\né€™å¯èƒ½å°±æ˜¯å¸¸è¦‹çš„å ±è¡¨å…§å®¹ï¼Œå³å„é …å•†å“çš„éŠ·å”®æƒ…æ³èˆ‡ website çš„æˆæ•ˆæŒ‡æ¨™ï¼›ä½†æ˜¯è‹¥æ›´é€²ä¸€æ­¥çš„æ€è€ƒï¼Œé€™ä»½å ±è¡¨æ‰€è¡¨é”çš„æ˜¯å°è³‡æ–™é€²è¡Œçµ±è¨ˆå¾Œçš„è³‡è¨Šï¼Œæˆ–æ˜¯å¸¸è¦‹çš„ç”¨è© Data Informed ï¼›é‚£éº¼ï¼Œåˆ†æçš„ç›®æ¨™åªæ˜¯ç”¢ç”Ÿå ±è¡¨æ•¸æ“šå—Â ?\næˆ–è€…ï¼Œæ˜¯å¸Œæœ›èƒ½å¾è³‡æ–™ä¸­å”åŠ©è­˜åˆ¥ã€Œå“ªäº›è¨ªå•è€…æ›´å¯èƒ½æœƒä¿ƒæˆè³¼è²·å•†å“çš„äº‹ä»¶ã€å‘¢Â ?\nFeature andÂ Label é¦–å…ˆè€ƒæ…®æœ‰å¤šå°‘è¨ªå•äººæ•¸é€²è¡Œäº†è³¼è²·ï¼ŒåŒ…å«äº†ç¬¬ä¸€æ¬¡ç€è¦½å°±è³¼è²·ä»¥åŠå†æ¬¡è¨ªå•å¾Œé€²è¡Œè³¼è²·\nå…±æœ‰ (11,873 / 741,721) = 1.6% çš„äººæ˜¯åœ¨ç¬¬äºŒæ¬¡è¨ªå•å•†å“é é¢æ™‚ï¼Œæ‰é€²è¡Œè³¼è²·ï¼›é›–ç„¶æ²’æœ‰ä¸€å€‹æ­£ç¢ºç­”æ¡ˆï¼Œä½†æ™®éçš„åŸå› å¯èƒ½æ˜¯æ¶ˆè²»è€…åœ¨è³¼è²·å‰æœƒé€²è¡Œå•†å“çš„æ¯”åƒ¹ã€‚\nä»¥æ­¤ç‚ºä¾‹ï¼Œå¯ä»¥å¾åŸå§‹è³‡æ–™ä¸­åˆ—èˆ‰ä¸€äº›å› ç´ ï¼Œä½œç‚ºåˆ¤æ–·è¨ªå•è€…æ˜¯å¦æœƒé€²è¡Œè³¼è²·çš„ä¾æ“š ( feature )ï¼Œä¸¦å°‡å†æ¬¡å›è¨ªæ˜¯å¦ç”¢ç”Ÿè³¼è²·è¡Œç‚ºä½œç‚ºç­”æ¡ˆ ( label ) å°å…¶è¨“ç·´ä¸€å€‹æ¨¡å‹ ( model )ï¼›æœŸæœ›åœ¨ä¸‹æ¬¡æ”¶é›†åˆ°ç›¸é—œè³‡æ–™æ™‚ï¼Œæ¨¡å‹å¯ä»¥è­˜åˆ¥ä¸¦å‘ŠçŸ¥è¨ªå•è€…æ˜¯å¦æœƒç”¢ç”Ÿè³¼è²·è¡Œç‚ºã€‚\nç¬¬ä¸€æ¬¡æŒ‘é¸ feature æ™‚ï¼Œå°ä»¥ä¸‹å…©å€‹å› ç´ é€²è¡Œåˆ†æ\nbouncesÂ : è¨ªå•è€…æ˜¯å¦ç«‹å³é›¢é–‹ website time_on_siteÂ : è¨ªå•è€…åœ¨ website åœç•™çš„æ™‚é–“ é€šå¸¸åœ¨è¨“ç·´å’Œè©•ä¼°æ¨¡å‹ä¹‹å‰ï¼Œç›´æ¥åˆ¤æ–· feature çš„é¸æ“‡æ˜¯å¥½æˆ–ä¸å¥½éƒ½ç‚ºæ™‚éæ—©ï¼Œä½†åœ¨ time_on_site æ’æ¯”å‰ 10 çš„çµæœä¸­ï¼Œåªæœ‰ 1 å€‹å®¢æˆ¶è¿”å›è³¼è²·ï¼›è€Œæ¨¡å‹æ¸¬è©¦çš„æº–ç¢ºç‡ä¹Ÿç¢ºå¯¦ä¸å¥½ã€‚\nImprove andÂ Tune åœ¨åŸå§‹æ•¸æ“šä¸­ï¼Œå¯èƒ½æœ‰æ›´å¤šçš„ feature å¯ä»¥å¹«åŠ© model é€²è¡Œè­˜åˆ¥è³¼è²·è¡Œç‚ºèµ·åˆ°ä½œç”¨ï¼›è€Œæ‰¾å‡º feature çš„æ–¹æ³•é™¤äº†å°æ‰€æœ‰æ’åˆ—çµ„åˆé€ä¸€é€²è¡Œå˜—è©¦å¤–ï¼Œä¹Ÿå¯ä»¥é€éèˆ‡ç›¸é—œäººå“¡ï¼Œå¦‚Â : ç‡ŸéŠ·äººå“¡ã€UX è¨­è¨ˆå¸«ã€çµ±è¨ˆå°ˆå®¶æˆ–è³‡æ–™ç§‘å­¸å®¶ç­‰ç­‰ï¼Œé€²è¡Œè¨è«–ä¸¦é”æˆå…±è­˜å¾Œå¾—å‡ºã€‚\nåœ¨é€™å€‹æ¡ˆä¾‹ä¸­ï¼Œé™¤äº† bounces èˆ‡ time_on_site ä¹‹å¤–ï¼Œé‚„å¯ä»¥åŠ å…¥ä»¥ä¸‹çš„ feature\nè¨ªå•è€…ç¬¬ä¸€æ¬¡è¨ªå•æ™‚ï¼Œåœ¨çµå¸³éç¨‹ä¸­ç¶“æ­·äº†å¤šå°‘æ¬¡çš„æ“ä½œ (è·é›¢) æµé‡çš„ä¾†æºÂ : é€éæœç´¢æˆ–æ˜¯ referring site ç­‰ç­‰ è¨­å‚™çš„é¡åˆ¥Â : æ‰‹æ©Ÿ ã€ å¹³æ¿ æˆ–æ˜¯ PC åœ°ç†è³‡è¨ŠÂ : ä¾†è‡ªå“ªå€‹åœ‹å®¶ é‡æ–°è¨“ç·´æ¨¡å‹å¾Œæ¸¬è©¦çš„æº–ç¢ºç‡ä¹Ÿæœ‰æ‰€æé«˜ï¼ŒåŒæ™‚æ¨¡å‹ä¹Ÿèƒ½æä¾›ä¸€å€‹é æ¸¬çµæœï¼Œå‘ŠçŸ¥è©²è¨ªå•è€…æ˜¯å¦æœƒé€²è¡Œè³¼è²·è¡Œç‚º\nSummary Qwiklabs: Predict Visitor Purchases with a Classification Model in BQML çš„æ¡ˆä¾‹åœ¨æœ€å¾Œçµ¦å‡ºçš„çµè«–å¦‚ä¸‹\nåœ¨å‰ 6% çš„é¦–æ¬¡è¨ªå•è€…ä¸­ï¼Œè¶…é 6% çš„äººæœƒåœ¨å¾ŒçºŒè¨ªå•æ™‚ç”¢ç”Ÿè³¼è²·è¡Œç‚º æ•´é«”è€Œè¨€ï¼Œåªæœ‰ 0.7% çš„é¦–æ¬¡è¨ªå•è€…ï¼Œæœƒåœ¨å¾ŒçºŒè¨ªå•æ™‚ç”¢ç”Ÿè³¼è²·è¡Œç‚º ç„æº–å‰ 6% çš„ç¬¬ä¸€æ¬¡è¨ªå•è€…åå–®ï¼Œæœƒä½¿ç‡ŸéŠ·æŠ•è³‡å›å ±ç‡æé«˜ 9 å€ å› æ­¤ï¼Œè‹¥æ˜¯èƒ½å¤ åœ¨å¾—åˆ°æ¨¡å‹é æ¸¬çš„çµæœå¾Œï¼Œä¾æ“šç‡ŸéŠ·ç­–ç•¥é€²è¡Œå³æ™‚çš„æŠ•æ”¾è™•ç†ï¼ŒåŒ…å«ä½†ä¸é™æ–¼: EDMå»£å‘Šã€CouponæŠ˜åƒ¹åˆ¸æˆ–æ˜¯é™å®šç¶‘ç¶æŠ˜æ‰£ç­‰ç­‰ï¼Œå»ºæ§‹èµ·ä¸€å€‹è‡ªå‹•åŒ–ç‡ŸéŠ·çš„æ–¹æ³•ï¼›é€™ä¹Ÿæ˜¯ä¸€ç¨® Data Driven çš„æ–¹æ³•ã€‚\næ•´ç¯‡æ–‡ç« å¯«åˆ°é€™è£¡ï¼Œå¾ ã€ŒWhat Goal We Needã€ ä¸­è¾¨åˆ¥æ›´å…·åƒ¹å€¼çš„ç›®æ¨™ã€ã€ŒFeature and Labelã€ä¸­å®šç¾©éœ€ç”¢å‡ºçš„è²¢ç»èˆ‡è©•æ–·æ–¹å¼ï¼Œåˆ°æœ€å¾Œã€ŒImprove and Tuneã€é€éè¨è«–é”æˆå…±è­˜ï¼Œä¸¦é€²è¡Œç›¸å°æ‡‰çš„èª¿æ•´ï¼Œè®“æ•´é«”çµæœèƒ½å¤ ç”¢å‡ºçš„æ›´å¥½è²¢ç»ï¼Œæˆ‘èªç‚ºé€™æ˜¯ä¸€ç¨®ä¸æ–·å„ªåŒ–èˆ‡å»ºç«‹ CDP çš„å¥½æ–¹æ³•ã€‚\n","permalink":"https://blog.zhengweiliu.com/posts/normal/customer-data-platform-3/","summary":"\u003cp\u003eåœ¨æœ€å¾Œçµ¦å‡ºçš„çµè«–å¦‚ä¸‹\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eåœ¨å‰ 6% çš„é¦–æ¬¡è¨ªå•è€…ä¸­ï¼Œè¶…é 6% çš„äººæœƒåœ¨å¾ŒçºŒè¨ªå•æ™‚ç”¢ç”Ÿè³¼è²·è¡Œç‚º\u003c/li\u003e\n\u003cli\u003eæ•´é«”è€Œè¨€ï¼Œåªæœ‰ 0.7% çš„é¦–æ¬¡è¨ªå•è€…ï¼Œæœƒåœ¨å¾ŒçºŒè¨ªå•æ™‚ç”¢ç”Ÿè³¼è²·è¡Œç‚º\u003c/li\u003e\n\u003cli\u003eç„æº–å‰ 6% çš„ç¬¬ä¸€æ¬¡è¨ªå•è€…åå–®ï¼Œæœƒä½¿ç‡ŸéŠ·æŠ•è³‡å›å ±ç‡æé«˜ 9 å€\nå› æ­¤ï¼Œè‹¥æ˜¯èƒ½å¤ åœ¨å¾—åˆ°æ¨¡å‹é æ¸¬çš„çµæœå¾Œï¼Œä¾æ“šç‡ŸéŠ·ç­–ç•¥é€²è¡Œå³æ™‚çš„æŠ•æ”¾è™•ç†ï¼ŒåŒ…å«ä½†ä¸é™æ–¼: EDMå»£å‘Šã€CouponæŠ˜åƒ¹åˆ¸æˆ–æ˜¯é™å®šç¶‘ç¶æŠ˜æ‰£ç­‰ç­‰ï¼Œå»ºæ§‹èµ·ä¸€å€‹è‡ªå‹•åŒ–ç‡ŸéŠ·çš„æ–¹æ³•ï¼›é€™ä¹Ÿæ˜¯ä¸€ç¨® \u003cstrong\u003eData Driven\u003c/strong\u003e çš„æ–¹æ³•ã€‚\u003c/li\u003e\n\u003c/ul\u003e\n","title":"Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„ (ä¸‰)"},{"content":"åœ¨ [Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„]ä¸­æåˆ°ï¼ŒData Platform é€éæ´å¯Ÿèˆ‡ç™¼ç¾ ( Insights Discovery )ã€è²¢ç»èˆ‡é€²åŒ– ( Contribute Evolution) ä»¥åŠç•°å¸¸åµæ¸¬ ( Anomaly Detection) çµ„æˆä¸€å€‹å‘¨è€Œå¾©å§‹çš„æ­£å‘å¾ªç’°ï¼Œè®“è³‡æ–™æä¾›å…·æœ‰è²¢ç»çš„çµæœã€‚ Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„ Date: 2022-03-22 \u0026nbsp; Categories: #Customer Data Platform\u0026nbsp; æåˆ° CDP ( Customer Data Platform ) ï¼Œå¯èƒ½å°±æœƒæƒ³åˆ°åˆ©ç”¨é¡§å®¢ç›¸é—œè³‡æ–™ï¼Œç‚ºé¡§å®¢åˆ†ç¾¤åˆ†é¡è²¼æ¨™ç±¤ï¼Œé€éç¶²ç«™ã€ç¶“ç‡Ÿç¤¾ç¾¤æˆ– APP é€²è¡Œç²¾æº–æŠ•æ”¾å»£å‘Šï¼Œé”åˆ°å†è¡ŒéŠ·çš„æˆæœï¼›ç”šè‡³æ˜¯é€é Machine Learningï¼Œæˆ–çµåˆ CRM ã€ Google Analytics ç­‰è³‡æ–™ï¼Œé”æˆé ä¼°å¸‚å ´è¦æ¨¡ã€å„ªåŒ–æ¨è–¦å•†å“ç­‰ç›®çš„ã€‚ ...... æœ€è¿‘è®€åˆ° How to Optimize KPIs by Distilling Data With Machine Learning é€™ç¯‡æ–‡ç« ï¼ŒåŸæ–‡ä¸­æåŠçš„ä¾‹å­: åˆ©ç”¨ User Behavior é€²è¡Œæ©Ÿå™¨å­¸ç¿’ï¼Œæœ€å¾Œç”¢å‡ºä¸€å€‹å…·å‚™è©•åˆ†çš„å¯äº¤ä»˜åå–®ï¼Œæä¾›çµ¦ç‡ŸéŠ·äººå“¡é€²è¡Œå¾ŒçºŒæ“ä½œï¼›è©³ç´°çš„éƒ¨åˆ†è«‹å†é»é–±åŸæ–‡ï¼Œä»¥ä¸‹æˆ‘æƒ³åˆ†äº«é–±è®€å¾Œçš„å¿ƒå¾—ã€‚\nè²»ç±³ä¼°ç®— ä¾æ“šç¶­åŸºç™¾ç§‘çš„æè¿°\nä¸€å€‹ç¶“å…¸çš„è²»ç±³å•é¡Œçš„ä¾‹å­æ˜¯è²»ç±³æå‡ºçš„ã€Œåœ¨èŠåŠ å“¥æœ‰å¤šå°‘é‹¼ç´èª¿ç´å¸«ã€\næ¯”å¦‚èªªï¼Œæˆ‘å€‘æœƒæ¡ç”¨ä»¥ä¸‹çš„å‡è¨­\n1. å¤§ç´„æœ‰9,000,000 äººç”Ÿæ´»åœ¨èŠåŠ å“¥ã€‚\n2. åœ¨èŠåŠ å“¥å¹³å‡æ¯å€‹å®¶åº­æœ‰2å€‹äººã€‚\n3. å¤§ç´„åœ¨20å€‹å®¶åº­ä¸­æœ‰1å€‹å®¶åº­éœ€è¦å®šæœŸé‹¼ç´èª¿éŸ³ã€‚\n4. å®šæœŸèª¿ç´çš„é‹¼ç´æ¯å¹´éœ€è¦èª¿æ•´ä¸€æ¬¡ã€‚\n5. æ¯å€‹èª¿ç´å¸«å¤§ç´„éœ€è¦2å°æ™‚èª¿ç´ï¼ŒåŒ…æ‹¬è·¯ä¸Šæ™‚é–“ã€‚\n6. æ¯å€‹èª¿ç´å¸«æ¯å¤©å·¥ä½œ8å°æ™‚ï¼Œä¸€å‘¨5å¤©ï¼Œä¸€å¹´50å‘¨ã€‚\næœ€å¾Œç¶“éè¨ˆç®—ï¼Œå¤§ç•¥çš„ä¼°ç®—å‡º 225 å€‹èª¿ç´å¸«åœ¨èŠåŠ å“¥ï¼›åœ¨é€™å€‹å•é¡Œçš„æ™‚ç©ºèƒŒæ™¯ä¸‹ï¼Œäº‹å¯¦ä¸Šï¼Œ ä¸€å…±æœ‰å¤§ç´„ 290 åèª¿ç´å¸«åœ¨èŠåŠ å“¥ã€‚\né‡åŒ–å•é¡Œ åœ¨èª¿ç´å¸«çš„å•é¡Œä¸­ï¼Œåœ¨æ²’æœ‰ä»»ä¸€çµ„ç¹”æˆ–æ¬Šå¨å¯ä»¥æä¾›å®Œæ•´èª¿ç´å¸«æ¸…å–®çš„æƒ…æ³ä¸‹ï¼Œå¾åœç¹èª¿ç´å¸«çš„å› ç´ é€²è¡Œåˆ†æèˆ‡å±•é–‹ï¼Œå°ç›¸é—œçš„æ¢ä»¶è¨‚ä¸‹ä¸€å€‹åŸºæº–æ•¸æ“šï¼Œå†ä¸€æ­¥æ­¥é€¼è¿‘å‘½é¡Œï¼Œæœ€çµ‚ä¼°ç®—å‡ºå¤§ç•¥çš„äººæ•¸ï¼›\nè€ŒåŸæ–‡ä¸­ã€Œå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„ç‡ŸéŠ·é ç®—ã€ï¼Œæ›å€‹æ–¹å¼ä¾†æè¿°å•é¡Œå‰‡è®Šæˆã€Œå°‡ç‡ŸéŠ·é ç®—æŠ•å…¥çµ¦å“ªäº›æ¶ˆè²»è€…ï¼Œå¯ä»¥å–å¾—æœ€å¤§æˆæ•ˆã€Â : é€™ä½¿å¾—å•é¡Œæœ¬èº«å¯ä»¥åœç¹è‘—ã€Œæ¶ˆè²»è€…ã€é€™å€‹å› ç´ é€²è¡Œåˆ†æèˆ‡å±•é–‹ï¼Œæˆ–è¨±æ˜¯åˆ†æä½¿ç”¨è€…æ¶ˆè²»è¡Œç‚ºã€æˆ–è¨±æ˜¯é€é RFM ä¾†é€²è¡Œåˆæ­¥çš„åˆ†æï¼Œæ›´å¯ä»¥å°å…¥æ¶ˆè²»è€…æœƒå“¡ç­‰ç´šæ¬Šç›Šç­‰é¡å¤–è³‡æ–™é€²è¡Œè¼”åŠ©ã€‚\né¡¯è€Œæ˜“è¦‹ï¼Œè¨è«–å‡ºä¸€å€‹æœ‰å…±è­˜ã€è¦ºå¾—å¯è¡Œçš„æ–¹å¼å°‡å•é¡Œé€²è¡Œè½‰åŒ–ï¼Œé€™å°±å±¬æ–¼æ´å¯Ÿ(Insights)ï¼›è€Œè¢«æå‡ºçš„å•é¡Œæœ¬èº«ï¼Œå‰‡æ˜¯è¢«ç™¼ç¾çš„ç•°å¸¸(Anomaly)ã€‚åŸæ–‡æœ€å¾Œæå‡ºã€Œå…·æœ‰è©•åˆ†ç­‰ç´šçš„ä½¿ç”¨è€…æ¸…å–®ã€å‰‡æ˜¯è²¢ç»(Contribute)ã€‚\næœ‰è¶£çš„æ˜¯ï¼Œç•¶ç‡ŸéŠ·äººå“¡ä¾æ“šæ¸…å–®é€²è¡Œé ç®—æŠ•æ”¾å¾Œï¼Œä¾¿åˆèƒ½ç²å–æ–°ä¸€è¼ªçš„çµæœï¼Œé€™å€‹çµæœé™¤äº†å¯ä¾›é©—è­‰ï¼ŒåŒæ™‚ä¹Ÿå…·å‚™ç™¼ç¾æ–°ç•°å¸¸çš„å¯èƒ½æ€§ã€‚\nèƒŒå¾Œçš„æ ¸å¿ƒ åŒæ¨£ä»¥èª¿ç´å¸«çš„å•é¡Œç‚ºä¾‹\næ˜¯å¦æ›¾è€ƒæ…®éï¼Œç‚ºä»€éº¼ã€Œåœ¨èŠåŠ å“¥æœ‰å¤šå°‘é‹¼ç´èª¿ç´å¸«ã€é€™å€‹å•é¡Œæœƒè¢«æå‡ºÂ ?\né€™å°±å…·å‚™ç„¡é™å¤šç¨®å¯èƒ½æ€§ï¼Œå¦‚Â : ã€Œç›®å‰æœ‰ä¸€å€‹å°ˆä¾›èª¿ç´å¸«ä½¿ç”¨çš„ç”¢å“ï¼Œå› æ­¤æƒ³çŸ¥é“èŠåŠ å“¥çš„å¸‚å ´è¦æ¨¡ã€ã€ŒèŠåŠ å“¥æ˜¯å¦é©åˆæ“´å¤§é‹¼ç´çš„è²©å”®è¦æ¨¡ã€ã€Œå¦‚æœæƒ³æŠ•èº«èª¿ç´å¸«çš„è·æ¥­ï¼Œåœ¨èŠåŠ å“¥æ˜¯å¦é©åˆã€ ç­‰ç­‰\nèˆ‡åŸæ–‡æå‡ºçš„ã€Œå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„ç‡ŸéŠ·é ç®—ã€ä¸€è‡´ï¼Œã€Œæ€éº¼åšèƒ½å¤ æå‡ç‡ŸéŠ·æ•¸å­—ã€ã€ŒæŸé¡å‹çš„å•†å“æ˜¯å¦é©åˆæŠ•æ”¾ç‡ŸéŠ·é ç®—ã€ç­‰ç­‰\næˆ‘å€‘å¸Œæœ›å€Ÿé‘‘æˆåŠŸæ¡ˆä¾‹æ™‚ï¼Œä¸å¦¨å…ˆè©¦è‘—å…±åŒè¨è«–\næˆ‘å€‘æ­£é¢å°è‘—ä»€éº¼æ¨£çš„æƒ…æ³Â ?\næˆ‘å€‘å¸Œæœ›èƒ½æ”¹è®Šä»€éº¼æƒ…æ³Â ?\nä»¥æ›´å¥½çš„è¾¨èªç›®å‰çš„å•é¡Œï¼Œå±¬æ–¼å¯ä»¥åˆ†æçš„ã€ŒçœŸè­°é¡Œã€ï¼Œæˆ–è€…åªæ˜¯å±•ç¾ä¸€å€‹è™›æ¦®æ•¸å­—çš„ã€Œå‡è­°é¡Œã€\n","permalink":"https://blog.zhengweiliu.com/posts/normal/customer-data-platform-2/","summary":"é¡¯è€Œæ˜“è¦‹ï¼Œè¨è«–å‡ºä¸€å€‹æœ‰å…±è­˜ã€è¦ºå¾—å¯è¡Œçš„æ–¹å¼å°‡å•é¡Œé€²è¡Œè½‰åŒ–ï¼Œé€™å°±å±¬æ–¼æ´å¯Ÿ(Insights)ï¼›è€Œè¢«æå‡ºçš„å•é¡Œæœ¬èº«ï¼Œå‰‡æ˜¯è¢«ç™¼ç¾çš„ç•°å¸¸(Anomaly)ã€‚åŸæ–‡æœ€å¾Œæå‡ºã€Œå…·æœ‰è©•åˆ†ç­‰ç´šçš„ä½¿ç”¨è€…æ¸…å–®ã€å‰‡æ˜¯è²¢ç»(Contribute)ã€‚\næœ‰è¶£çš„æ˜¯ï¼Œç•¶ç‡ŸéŠ·äººå“¡ä¾æ“šæ¸…å–®é€²è¡Œé ç®—æŠ•æ”¾å¾Œï¼Œä¾¿åˆèƒ½ç²å–æ–°ä¸€è¼ªçš„çµæœï¼Œé€™å€‹çµæœé™¤äº†å¯ä¾›é©—è­‰ï¼ŒåŒæ™‚ä¹Ÿå…·å‚™ç™¼ç¾æ–°ç•°å¸¸çš„å¯èƒ½æ€§ã€‚","title":"Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„ (äºŒ)"},{"content":"æåˆ° CDP ( Customer Data Platform ) ï¼Œå¯èƒ½å°±æœƒæƒ³åˆ°åˆ©ç”¨é¡§å®¢ç›¸é—œè³‡æ–™ï¼Œç‚ºé¡§å®¢åˆ†ç¾¤åˆ†é¡è²¼æ¨™ç±¤ï¼Œé€éç¶²ç«™ã€ç¶“ç‡Ÿç¤¾ç¾¤æˆ– APP é€²è¡Œç²¾æº–æŠ•æ”¾å»£å‘Šï¼Œé”åˆ°å†è¡ŒéŠ·çš„æˆæœï¼›ç”šè‡³æ˜¯é€é Machine Learningï¼Œæˆ–çµåˆ CRM ã€ Google Analytics ç­‰è³‡æ–™ï¼Œé”æˆé ä¼°å¸‚å ´è¦æ¨¡ã€å„ªåŒ–æ¨è–¦å•†å“ç­‰ç›®çš„ã€‚\nä¼¼ä¹åªè¦æœ‰å……åˆ†çš„è³‡æ–™ï¼Œå°±èƒ½é–‹å§‹äº«å— CDP ç‚ºè¡ŒéŠ·å¸¶ä¾†è«¸å¤šå¥½è™•ã€‚ç„¶è€Œï¼Œå…·é«”ä¸Š CDP æ˜¯æ€éº¼é‹ä½œçš„Â ? åˆè©²å¦‚ä½•å–„ç”¨ CDP çš„åŠŸèƒ½å‘¢Â ? æˆ–è¨±å¯ä»¥å¾ç­è§£ CDP æ˜¯å¦‚ä½•æ§‹æˆçš„é–‹å§‹ã€‚\nCustomer and DataÂ Platform ä¸å¦‚ç°¡å–®ç²—æš´çš„ï¼Œè©¦è‘—å¾åç¨±ä¸Šå°‡ Customer èˆ‡ Data Platform åˆ†é–‹ ï¼š\nå°æ–¼ Customer ï¼Œæˆ–è€…èªªæ˜¯èˆ‡é¡§å®¢ç›¸é—œçš„è³‡æ–™ï¼Œå¾æœƒå“¡å¸³è™Ÿçš„å»ºç«‹åˆ°å•†å“è³¼è²·ç´€éŒ„ã€ç¶²é ç€è¦½æ“ä½œç´€éŒ„ï¼Œç”šè‡³æ˜¯æœƒå“¡æ¬Šç›Šåˆ†ç´šç­‰ç­‰ï¼›å› é¡§å®¢çš„ä¸»å‹•è¡Œç‚ºç”¢ç”Ÿï¼Œç„¡è«–æ˜¯å¦å­˜åœ¨èª˜å› ï¼Œä¸¦ä¸”è’é›†èµ·ä¾†å¯¶è²´è³‡æ–™ã€‚\nå¦‚åŒæ¯é“æ–™ç†éƒ½æ˜¯ç”±é£ŸæåŸæ–™çµ„æˆï¼Œåƒ…æœ‰é£ŸæåŸæ–™å»æ²’æœ‰è¾¦æ³•è®Šæˆç¾å‘³çš„æ–™ç†ï¼›Data Platform æ“”ä»»çƒ¹é£ªè€…çš„è§’è‰²ï¼Œå°‡é€™äº›å¯¶è²´è³‡æ–™é€²ä¸€æ­¥è™•ç†ï¼Œç«¯å‡ºä¸€é“åˆä¸€é“çš„ç‡Ÿé¤Šåˆå¯å£çš„ç¾é£Ÿã€‚\nBring Benefits with Data-Platform å›æƒ³ä¸€ä¸‹æ–™ç†çš„çƒ¹é£ªéç¨‹ï¼Œå¾æº–å‚™ææ–™ã€å°é£Ÿæé€²è¡Œæ¸…æ´—ã€å°‡é£Ÿæåˆ‡å‰²æˆé©ç•¶å¤§å°æˆ–é†ƒè£½å…¥å‘³ï¼Œåˆ°è§€å¯Ÿç«å€™ä¸¦ä¾åºåŠ å…¥å°æ‡‰çš„é£Ÿæï¼Œæœ€å¾Œå‡ºé‹ä¸Šèœï¼Œè‹¥ä¸Šèœå¾Œç™¼ç¾å‘³é“ä¸å¥½ï¼Œé‚„å¯ä»¥å†ä¾æ“šé€™æ¬¡çš„ç¶“é©—é€²è¡Œèª¿æ•´èˆ‡ä¿®æ­£ã€‚\nData Platform ä¹Ÿå°è³‡æ–™é€²è¡Œæ¸…ç†ã€å‰è™•ç†ï¼Œå°è™•ç†å¾Œçš„è³‡æ–™é€²è¡Œé‡çµ„ï¼Œæœ€çµ‚ç”¢ç”Ÿå‡ºæœ‰è²¢ç»çš„æ•¸æ“šæˆæœï¼Œä¸¦é€éè½‰è­¯çš„æ–¹å¼é€²è¡Œäº¤ä»˜ï¼›æ•´å€‹æµç¨‹å°±åƒä¸‹åœ–æ‰€æè¿°ï¼š\næ´å¯Ÿèˆ‡ç™¼ç¾ ( Insights Discovery ) \u0026gt; è²¢ç»èˆ‡é€²åŒ– ( Contribute Evolution) \u0026gt; ç•°å¸¸åµæ¸¬ ( Anomaly Detection) \u0026gt; æ´å¯Ÿèˆ‡ç™¼ç¾ ( Insights Discovery ) \u0026gt;Â â€¦\nè€Œåœ¨é€™ä¸€å¾ªç’°çš„æµç¨‹ä¸­ï¼Œéƒ½ç·Šå¯†çš„åœç¹è‘—ä¸€å€‹æ ¸å¿ƒ ( Kernel ) åœ¨é€²è¡Œï¼šå¦‚åŒCDP æ˜¯çš„ Kernel æ˜¯ Customer ã€ éº»å©†è±†è…çš„ Kernel æ˜¯éº»å©†ä¸€æ¨£ ã€‚\nData Platform ä¸­çš„æ‰€æœ‰è™•ç†ã€æ­¥é©Ÿä»¥åŠæµç¨‹ï¼Œéƒ½æ˜¯ç‚ºäº†æ ¸å¿ƒåœ¨æœå‹™ã€‚\næ´å¯Ÿèˆ‡ç™¼ç¾ ( Insights Discovery ) å¦‚æœæˆ‘å€‘ç”¢ç”Ÿä¸€å€‹ç–‘å•ï¼Œå¤§å¤šæ•¸çš„æƒ…æ³ä¸‹åœ¨ç¬¬ä¸€æ™‚é–“ï¼Œæˆ‘å€‘éƒ½æœƒå•Â :ã€Œç™¼ç”Ÿä»€éº¼äº‹Â ?ã€ æˆ–æ˜¯ ã€ŒæŸå€‹äº‹ä»¶æ˜¯ä¸æ˜¯é€ æˆä»€éº¼å½±éŸ¿ã€ï¼Œè€Œä¸æœƒæ˜¯ ã€ŒæŸå€‹å…·é«”çš„é‡(æˆ–è€…æ•¸å­—)æ˜¯å¤šå°‘ã€\né€™äº›å•é¡Œæœ¬èº«å°±æ˜¯ Insight çš„å‚¬åŒ–åŠ‘ï¼Œä¿ƒä½¿æˆ‘å€‘æƒ³é€²ä¸€æ­¥å»åˆ†æã€å»ç†è§£\nè²¢ç»èˆ‡é€²åŒ– ( Contribute Evolution) æå‡ºå•é¡Œä¸¦åœ¨åˆ†æå¾Œï¼Œè‹¥èƒ½æ‰¾åˆ°ä¸€äº›å¯èƒ½çš„ç­”æ¡ˆï¼Œä¾¿èƒ½åˆ©ç”¨ IFTTT ( If This Then That ) é€²è¡Œå•é¡Œç°¡åŒ–ï¼Œå³Â :\nå¦‚æœç™¼ç”Ÿ A ç‹€æ³ï¼Œé‚£éº¼æœƒé€ æˆä»€éº¼çµæœ / éœ€è¦å¦‚ä½•æ‡‰å°\né€™æ˜¯ä¸€ç¨®å°‡æ•¸æ“šçµæœé€²è¡Œç¿»è­¯çš„éç¨‹ï¼Œè®“æ•¸æ“šè®Šæˆä¸€å€‹æ‡‰å°æ¸…å–®ï¼Œä¸¦èƒ½è¼•é¬†çš„äº¤ä»˜çµ¦å…¶ä»–åˆ©ç›Šç›¸é—œè€…ï¼Œä»¥ä¾¿ä»–å€‘å°çµæœé€²è¡Œä¸‹ä¸€æ­¥çš„æ“ä½œã€‚\nç•°å¸¸åµæ¸¬ ( Anomaly Detection) å¾ä¸Šä¸€æ­¥é©Ÿç”¢ç”Ÿçš„æ‡‰å°æ¸…å–®ï¼Œåœ¨åˆ©ç›Šç›¸é—œè€…å°å…¶é€²è¡Œæ“ä½œä¹‹å¾Œï¼Œå¦‚Â : å»£å‘ŠæŠ•æ”¾ ï¼Œ ä¾¿èƒ½å°æ¸…å–®é€²è¡Œé©—è­‰ã€è¨è«–ï¼›æˆ–æ˜¯å°ç‰¹å®šåå–®é€²è¡ŒæŒçºŒçš„è§€æ¸¬ï¼Œçœ‹çœ‹æ˜¯å¦ä»æœ‰èˆ‡æ•¸æ“šçµæœä¸ç¬¦ï¼Œæˆ–è€…ç›¸å°ç•°å¸¸çš„è¡Œç‚ºå‡ºç¾ã€‚\nç•¶ä¸Šè¿°çš„è¡Œç‚ºå‡ºç¾å¾Œï¼Œåœ¨èˆ‡ç›¸é—œåˆ©ç›Šè€…å€‘é€²ä¸€æ­¥è¨è«–åŸå›  ( å›åˆ°äº† Insights Discovery ) ï¼Œç²å–æ–°çš„æˆ–è€…å¢å¼·æ‡‰å°æ¸…å–® ( åˆåˆ°äº† Contribute Evolution ) ï¼Œå†æ¬¡æŠ•å…¥é€²è¡Œæ“ä½œ ( å†æŒçºŒé€²è¡Œ Anomaly Detection )ï¼Œä»¥æ­¤å¾€å¾©ç›´åˆ°é€™å€‹å•é¡Œä¸å†éœ€è¦è™•ç†ï¼Œæˆ–è€…ä¸å†å…·å‚™åƒ¹å€¼æ™‚ï¼Œå°±èƒ½åœæ­¢ã€‚\n","permalink":"https://blog.zhengweiliu.com/posts/normal/customer-data-platform-1/","summary":"æåˆ° CDP ( Customer Data Platform ) ï¼Œå¯èƒ½å°±æœƒæƒ³åˆ°åˆ©ç”¨é¡§å®¢ç›¸é—œè³‡æ–™ï¼Œç‚ºé¡§å®¢åˆ†ç¾¤åˆ†é¡è²¼æ¨™ç±¤ï¼Œé€éç¶²ç«™ã€ç¶“ç‡Ÿç¤¾ç¾¤æˆ– APP é€²è¡Œç²¾æº–æŠ•æ”¾å»£å‘Šï¼Œé”åˆ°å†è¡ŒéŠ·çš„æˆæœï¼›ç”šè‡³æ˜¯é€é Machine Learningï¼Œæˆ–çµåˆ CRM ã€ Google Analytics ç­‰è³‡æ–™ï¼Œé”æˆé ä¼°å¸‚å ´è¦æ¨¡ã€å„ªåŒ–æ¨è–¦å•†å“ç­‰ç›®çš„ã€‚","title":"Customer Data Platform æ˜¯å¦‚ä½•ç…‰æˆçš„"},{"content":"åœ¨ GCP Billing Analytics ä¸­æåˆ°éé—œæ–¼ Cloud Functions çš„è¨ˆè²»è¶…ä¹é æœŸï¼Œé€²ä¸€æ­¥åˆ†æé–‹ç™¼çš„ä½¿ç”¨ç¿’æ…£å¾Œï¼Œä¹Ÿæ‰¾å‡ºéƒ¨åˆ†åŠŸèƒ½æ‡‰è©²å°‡å…¶å¾ Cloud Functions æ¬é·è‡³åŸºæ–¼ GCE instances çš„æœå‹™ä¸Šï¼Œä»¥é”åˆ°ç¯€è²»çš„æœŸæœ›ã€‚ GCP Billing Analysis Date: 2021-12-27 \u0026nbsp; Categories: #Google Cloud Platform\u0026nbsp; #Analysis\u0026nbsp; åœ¨ç”¢å“çš„é–‹ç™¼ä¸­ï¼Œåœ˜éšŠæ¶ˆè€—æˆæœ¬æœ€é«˜çš„å‰å¹¾é …æ’åæ—¢åœ¨æ„æ–™ä¹‹ä¸­ï¼ŒGoogle Compute Engine (GCE)ã€ Cloud Functions ã€ BigQuery ä»¥åŠ Google Cloud Storageï¼Œä½†ç´°é …çš„éƒ¨åˆ†ä¹Ÿåœ¨æ„æ–™ä¹‹å¤–ã€‚ ...... åœ¨åŸå…ˆçš„è¨­è¨ˆä¸­ï¼Œæˆ‘å€‘å°‡ Cloud Functions ä½œç‚º ETL data flow çš„å…¶ä¸­ä¸€å€‹ç’°ç¯€ï¼Œé€é Pub/Sub trigger Cloud Functions çš„æ–¹å¼ä½¿å…¶é‹ä½œï¼›è€ƒæ…®åˆ° Pub/Sub subscriber push/pull çš„ Ack ç­‰å¾…æ™‚é–“æœ‰è‘—æœ€é•· 600 ç§’çš„é™åˆ¶ï¼Œæˆ‘å°‡é€™éƒ¨åˆ†éœ€è¦æ¬é·çš„ Cloud Functions å¤§è‡´åˆ†ç‚ºå…©ç¨®éœ€æ±‚\néœæ…‹è³‡æ–™æº: åœ¨æå–è³‡æ–™æ™‚ï¼Œå¯é æœŸè³‡æ–™æ˜¯å­˜åœ¨ä¸”å¯è¢«å­˜å–çš„ å‹•æ…‹è³‡æ–™æº: å¯èƒ½ç™¼ç”Ÿè³‡æ–™ä¸å­˜åœ¨ï¼Œæˆ–è€…æ˜¯ç„¡æ³•å­˜å–çš„æƒ…æ³ æœ¬ç¯‡æ–‡ç« æ˜¯è¨˜éŒ„\nç”¨ Kubernetes Pod æ›¿ä»£ Cloud Function ç’°ç¯€ä»¥è™•ç†å‹•æ…‹è³‡æ–™æºçš„æ–¹æ³• Google Kubernetes Engine: Ingress \u0026amp; Service ASGI èˆ‡FastAPI Dockerize \u0026amp; Deployment éœæ…‹è³‡æ–™æºçš„è™•ç†æ–¹æ¡ˆ \u0026gt; Migrate Google Cloud Functions to Airflow Migrate Google Cloud Functions to Airflow Date: 2022-01-22 \u0026nbsp; Categories: #Google Cloud Platform\u0026nbsp; #Data Engineering\u0026nbsp; æœ¬ç¯‡æ–‡ç« æ˜¯è¨˜éŒ„ ç”¨ Airflow DAG (Directed Acyclic Graph) æ›¿ä»£ Cloud Function ç’°ç¯€ä»¥è™•ç†éœæ…‹è³‡æ–™æºçš„æ–¹æ³• Airflow GCP Operators ä½¿ç”¨ åœ¨ DAG ä¸­å¹³è¡Œè™•ç†(parallel processing)çš„æ–¹å¼ ...... Design Change Figure 1 æ˜¯ä¸€å€‹å¸¸è¦‹çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œæˆ‘å°‡ Cloud Function çš„åŸ·è¡Œé‚è¼¯ç°¡ç•¥ç‚º 4 å€‹éƒ¨ä»½ä¾†é€²è¡Œæè¿°ï¼Œå³: ç­‰å¾… Request (Accept Request) ã€ è™•ç†é‚è¼¯ (Process)ã€ç”¢å‡ºçµæœ (Result) ï¼Œä»¥åŠå›å¾© Ack (Response HTTP Status Code)\nProcess çš„å€å¡Šä¸­ï¼Œè‹¥éœ€è¦å‘å¤–éƒ¨è³‡æ–™æºæå‡ºå­˜å–è«‹æ±‚ï¼Œå¦‚: 3rd-party API ã€çˆ¬èŸ²ã€ç¶²è·¯ç£ç¢Ÿæ©Ÿç­‰ï¼Œç²å–ç›¸é—œçš„è³‡è¨Šå¾Œæ‰èƒ½ç¹¼çºŒé€²è¡Œè™•ç†çš„å·¥ä½œï¼Œåœ¨æœ¬ç¯‡æ–‡ç« ä¸­å‰‡ä»¥å‹•æ…‹è³‡æ–™æºä¾†ç¨±å‘¼é€™äº›å¤–éƒ¨è³‡æ–™æº\nå°æ–¼ Runtime æ™‚å¯èƒ½é­é‡éŒ¯èª¤çš„è³‡æ–™æºï¼Œå¯èƒ½é‡åˆ°è«‹æ±‚è¢«æ‹’çµ•(Reject)ï¼Œå¦‚: 403ã€404æˆ–è€…5ç³»åˆ—çš„éŒ¯èª¤ä»£ç¢¼ï¼Œæˆ–æ˜¯é‡åˆ°è«‹æ±‚çš„è³‡æºæœ¬èº«ä¸å­˜åœ¨ã€‚\nGoogle Kubernetes Engine: Ingress \u0026amp;Â Service Figure 2 ä½¿ç”¨ Kubernetes Pod æ›¿ä»£ Cloud Function ï¼Œ å› åœ˜éšŠå…ˆå‰å·²æ¡ç”¨ Google Kubernetes Engine (GKE) é€²è¡Œå®¹å™¨åŒ–çš„éƒ¨ç½²ï¼Œé€™é‚Šä¹Ÿå°±å»¶çºŒåœ˜éšŠæˆæœã€‚\næˆ‘ä¹Ÿå°‡ Pub/Sub çš„æ¨¡å¼å¾ trigger æ›´æ”¹ç‚º Push MessageÂ : ç•¶ Pub/Sub Subscriber Queue å­˜åœ¨è¨Šæ¯æ™‚ï¼Œ Subscriber æœƒæ¨é€ Message åˆ°è¨­å®šå¥½çš„ Webhook URLï¼Œä¸¦ä¸”éµå¾ª Ack ç­‰å¾…æ™‚é–“æœ‰è‘—æœ€é•· 600 ç§’çš„é™åˆ¶ã€‚\né—œæ–¼ Deployment çš„éƒ¨åˆ†æœƒåœ¨ç¨å¾Œæåˆ°ï¼Œé€™é‚Šå…ˆè¨è«– Ingress å’Œ Service çš„è¨­ç½®\nService Type: NodePort\napiVersion: v1kind: Servicemetadata: name: my-servicespec: type: NodePort selector: app: MyApp ports: # By default and for convenience, the `targetPort` is set to the same value as the `port` field. - port: 80 targetPort: 80 nodePort: 30080 Ingress\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-service-backend annotations: ingress.gcp.kubernetes.io/pre-shared-cert: \u0026#34;k8s-example-com\u0026#34; kubernetes.io/ingress.allow-http: \u0026#34;false\u0026#34; kubernetes.io/ingress.global-static-ip-name: k8s-example-com spec: defaultBackend: service: name: my-services port: number: 80 rules: - host: k8s.example.com http: paths: - path: /my-service pathType: Prefix backend: service: name: my-service port: number: 80 é€™æ¨£ä¾¿èƒ½å°‡ Ingress å’Œ Service è¨­ç½®å®Œæˆï¼ŒIngress å’Œ Service éœ€è¦åœ¨åŒä¸€å€‹ namespace ã€‚\nASGI \u0026amp;Â FastAPI è€ƒé‡åˆ°åœ˜éšŠé–‹ç™¼å¤§éƒ¨ä»½ä¾è³´ Python frameworkï¼Œå› æ­¤åœ¨æ›¿ä»£ Cloud Function HTTP Server çš„é¸æ“‡ä¸Šï¼Œæœ€å¾Œæˆ‘æ¡ç”¨äº†åŸºæ–¼ ASGI (Asynchronous Server Gateway Interface) çš„ FastAPI ï¼Œä»¥æ‡‰ä»˜åœ˜éšŠä¸­é™¤äº† Pub/Sub ä¹‹å¤–çš„éœ€æ±‚ã€‚\nå°æ–¼ WSGI å’Œ ASGI çš„æ¯”è¼ƒï¼Œæˆ‘è¦ºå¾—é€™ç¯‡åšå®¢ WSGIä¸ASGIçš„åŒºåˆ«ä¸è”ç³» èªªçš„å¾ˆæ¸…æ¥šï¼Œæ¨è–¦å¤§å®¶å¯ä»¥çœ‹ä¸€ä¸‹ã€‚\nFastAPI çš„æ–‡ä»¶ä¸­ä¹Ÿè©³ç´°æä¾›äº†è£½ä½œ Container Image çš„æ–¹æ³•ï¼ŒåŒæ™‚ä¹Ÿæåˆ°äº†é—œæ–¼éƒ¨ç½²åœ¨ Kubernetes ä¸Šçš„æ³¨æ„äº‹é …ï¼Œæœ‰ä¸€ä»½è©³ç´°ã€å®¹æ˜“ä½¿ç”¨çš„å®˜æ–¹æ–‡ä»¶ï¼Œä¹Ÿæ˜¯æˆ‘é¸æ“‡ FastAPI çš„åŸå› ä¹‹ä¸€ï¼Œä¸¦ä¸” FastAPI ä¹Ÿå…§å»ºäº† Swagger UI å’Œ ReDoc å…©ç¨®æ–‡ä»¶æ¨¡å¼ï¼Œé€™ä¹Ÿæ˜¯ä¸€å€‹åŠ åˆ†å¤§é …ã€‚\nDockerize \u0026amp; Deployment Dockerfile\nä¾æ“š FastAPI æ–‡ä»¶æä¾› Dockerfile æ’°å¯«å³å¯ï¼Œéœ€æ³¨æ„åœ¨ uvicorn çš„ commandåŠ ä¸Š --proxy-headers ã€‚\nFROM python:3.8 WORKDIR / COPY ./requirements.txt /requirements.txt RUN pip install --no-cache-dir --upgrade -r /requirements.txt COPY ./ / CMD [\u0026#34;uvicorn\u0026#34;, \u0026#34;main:app\u0026#34;, \u0026#34;--proxy-headers\u0026#34;, \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;--port\u0026#34;, \u0026#34;80\u0026#34;] ä¾éœ€æ±‚æ›´æ”¹ Dockerfile æ™‚éœ€è¦æ³¨æ„ Docker Build Cacheï¼Œç”±æ–¼ Docker Build Image æ™‚æœƒä¸€å±¤ä¸€å±¤çš„å¾€ä¸Šè¿­ä»£(æ¯ä¸€è¡ŒæŒ‡ä»¤å°±æ˜¯ä¸€å±¤)ï¼Œ è€Œæ¯ä¸€æ¬¡ Build Image éƒ½æœƒæª¢æŸ¥èˆ‡ä¸Šä¸€æ¬¡çš„å·®ç•°ï¼Œä¸¦å¾å½±éŸ¿å·®ç•°çš„ æœ€ä½å±¤ é‡æ–°è¿­ä»£ï¼Œå¦‚: ç•¶ requirements.txt å…§å®¹æœ‰æ‰€è®Šæ›´æ™‚ï¼Œå³ä¾¿ source code æ²’æœ‰æ”¹è®Šï¼Œè©²æ¬¡çš„ Docker Build ä¹Ÿæœƒå¾ COPYÂ ./requirements.txt /requirements.txt` é–‹å§‹å¾æ–°è¿­ä»£ã€‚\nMain.py\nåœ¨ main.py æä¾› domain host ä¹‹å¾Œçš„å®Œæ•´ URL path ï¼Œè®“ app çš„ route å¯ä»¥æ‰¾åˆ°å°æ‡‰çš„ç«¯å£ï¼Œä¸¦æä¾› /my-service/health çµ¦ Load Balancer é€²è¡Œ health checkã€‚\nfrom typing import Optional, Dict from fastapi import (FastAPI, status) from fastapi.encoders import jsonable_encoder from pydantic import BaseModel class Message(BaseModel): attrs: Optional[Dict] = None data: str message_id: str publish_time: str class PubSubMessage(BaseModel): message: Message subscription: str app = FastAPI() [@app](http://twitter.com/app \u0026#34;Twitter profile for @app\u0026#34;).get(\u0026#39;/\u0026#39;, status_code=status.HTTP_200_OK) def home(): pass [@app](http://twitter.com/app \u0026#34;Twitter profile for @app\u0026#34;).get(\u0026#39;/my-service/health\u0026#39;, status_code=status.HTTP_200_OK) def health(): pass @app.post(\u0026#39;/my-service/subscriber-webhook\u0026#39;, status_code=status.HTTP_200_OK) def subscriber_webhook(message: PubSubMessage): message_data: Dict = jsonable_encoder(message) return message_data Deployment\nä¾æ“š Kubertenes å®˜æ–¹æä¾›çš„æ¨¡æ¿æ’°å¯«ï¼Œå†ä¾éœ€æ±‚é€²è¡Œæ›´æ”¹å³å¯ã€‚\napiVersion: apps/v1 kind: Deployment metadata: name: subscriber-webhook-deployment labels: app: subscriber-webhook spec: replicas: 3 selector: matchLabels: app: subscriber-webhook template: metadata: labels: app: subscriber-webhook spec: containers: - name: subscriber-webhook image: {REPLACE_YOUR_REGISTRY}/subscriber-webhook:1.0 ports: - containerPort: 80 å¯è¦–éœ€è¦åŠ å…¥ readinessProbe æˆ– livenessProbe\nå¦‚æœæœ‰ Autoscaling çš„éœ€æ±‚ï¼Œåƒè€ƒ Horizontal Pod Autoscaling (HPA) èˆ‡ ç¯„ä¾‹ ä¿®æ”¹å³å¯ã€‚\n","permalink":"https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/","summary":"\u003cp\u003eæœ¬ç¯‡æ–‡ç« æ˜¯è¨˜éŒ„\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#1234\"\u003eç”¨ \u003ccode\u003eKubernetes Pod\u003c/code\u003e æ›¿ä»£ \u003ccode\u003eCloud Function\u003c/code\u003e ç’°ç¯€ä»¥è™•ç†\u003ccode\u003eå‹•æ…‹è³‡æ–™æº\u003c/code\u003eçš„æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#dee1\"\u003e\u003ccode\u003eGoogle Kubernetes Engine: Ingress \u0026amp; Service\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#fa5e\"\u003e\u003ccode\u003eASGI èˆ‡FastAPI\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#b458\"\u003e\u003ccode\u003eDockerize \u0026amp; Deployment\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","title":"Migrate Google Cloud Functions to Kubernetes"},{"content":"åœ¨ [GCP Billing Analytics] ä¸­æåˆ°éé—œæ–¼ Cloud Functions çš„è¨ˆè²»è¶…ä¹é æœŸï¼Œé€²ä¸€æ­¥åˆ†æé–‹ç™¼çš„ä½¿ç”¨ç¿’æ…£å¾Œï¼Œä¹Ÿæ‰¾å‡ºéƒ¨åˆ†åŠŸèƒ½æ‡‰è©²å°‡å…¶å¾ Cloud Functions æ¬é·è‡³åŸºæ–¼ GCE instances çš„æœå‹™ä¸Šï¼Œä»¥é”åˆ°ç¯€è²»çš„æœŸæœ›ã€‚ GCP Billing Analysis Date: 2021-12-27 \u0026nbsp; Categories: #Google Cloud Platform\u0026nbsp; #Analysis\u0026nbsp; åœ¨ç”¢å“çš„é–‹ç™¼ä¸­ï¼Œåœ˜éšŠæ¶ˆè€—æˆæœ¬æœ€é«˜çš„å‰å¹¾é …æ’åæ—¢åœ¨æ„æ–™ä¹‹ä¸­ï¼ŒGoogle Compute Engine (GCE)ã€ Cloud Functions ã€ BigQuery ä»¥åŠ Google Cloud Storageï¼Œä½†ç´°é …çš„éƒ¨åˆ†ä¹Ÿåœ¨æ„æ–™ä¹‹å¤–ã€‚ ...... åœ¨åŸå…ˆçš„è¨­è¨ˆä¸­ï¼Œæˆ‘å€‘å°‡ Cloud Functions ä½œç‚º ETL data flow çš„å…¶ä¸­ä¸€å€‹ç’°ç¯€ï¼Œé€é Pub/Sub trigger Cloud Functions çš„æ–¹å¼ä½¿å…¶é‹ä½œï¼›è€ƒæ…®åˆ° Pub/Sub subscriber push/pull çš„ Ack ç­‰å¾…æ™‚é–“æœ‰è‘—æœ€é•· 600 ç§’çš„é™åˆ¶ï¼Œæˆ‘å°‡é€™éƒ¨åˆ†éœ€è¦æ¬é·çš„ Cloud Functions å¤§è‡´åˆ†ç‚ºå…©ç¨®éœ€æ±‚\néœæ…‹è³‡æ–™æº: åœ¨æå–è³‡æ–™æ™‚ï¼Œå¯é æœŸè³‡æ–™æ˜¯å­˜åœ¨ä¸”å¯è¢«å­˜å–çš„ å‹•æ…‹è³‡æ–™æº: å¯èƒ½ç™¼ç”Ÿè³‡æ–™ä¸å­˜åœ¨ï¼Œæˆ–è€…æ˜¯ç„¡æ³•å­˜å–çš„æƒ…æ³ æœ¬ç¯‡æ–‡ç« æ˜¯è¨˜éŒ„\nç”¨ Airflow DAG (Directed Acyclic Graph) æ›¿ä»£ Cloud Function ç’°ç¯€ä»¥è™•ç†éœæ…‹è³‡æ–™æºçš„æ–¹æ³• Airflow GCP Operators ä½¿ç”¨ åœ¨ DAG ä¸­å¹³è¡Œè™•ç†(parallel processing)çš„æ–¹å¼ å‹•æ…‹è³‡æ–™æºçš„è™•ç†æ–¹æ¡ˆ \u0026gt; Migrate Google Cloud Functions to Kubernetes\nDesign Change Figure 1 æ˜¯ä¸€å€‹ç¶“å…¸çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œé€é GCS notification çš„æ©Ÿåˆ¶ï¼Œç•¶ bucket ä¸­æœ‰æª”æ¡ˆ (Object) ç•°å‹•æ™‚ï¼Œå°‡ç•°å‹•çš„è³‡è¨Š publish åˆ°æŒ‡å®šçš„ Pub/Sub Topicã€‚ éƒ¨ç½² Cloud Function å¯ä»¥æŒ‡å®š--trigger-topic æ¥å— Topic çš„è§¸ç™¼ï¼Œä½¿å¾— Cloud Function å¯ä»¥æ¥æ”¶ç•°å‹•æª”æ¡ˆçš„è³‡è¨Šï¼Œå¦‚: bucket nameã€object path ï¼Œ é€²è¡Œè½‰ç½® (Transform) è™•ç†å¾Œå°‡çµæœå­˜æ”¾åˆ° Big Query ã€‚\né€™ä¹Ÿæ˜¯æˆ‘ç¨±å‘¼ç‚ºéœæ…‹è³‡æ–™æºçš„åŸå› \nç”±æ–¼è¨Šæ¯å‚³éçš„æ™‚é–“ç›¸å°è¿…é€Ÿï¼Œç•¶ Cloud Function éœ€è¦æ“·å–å°æ‡‰çš„æª”æ¡ˆæ™‚ï¼Œè©²æª”æ¡ˆå­˜åœ¨æ–¼ GCS ä¸Šçš„å°æ‡‰ä½ç½®\nAirflow DAG \u0026amp; Operators Figure 2 å‰‡ç”¨ Airflow 2.0 DAG æ›¿ä»£ Cloud Function ï¼Œ Airflow æ˜¯ Python based çš„å·¥ä½œæµç®¡ç†ç³»çµ±ï¼Œå¯ä»¥å¹«åŠ©é–‹ç™¼è€…å°‡å·¥ä½œæµç¨‹æ¨™æº–åŒ–ä»¥åŠåŸ·è¡Œé‡è¤‡æ€§çš„å·¥ä½œï¼Œæˆ‘èªç‚ºæ»¿é©åˆæ‡‰ç”¨æ–¼éœæ…‹è³‡æ–™æºçš„å ´æ™¯ä¸Šã€‚\nä¸¦ä¸” Airflow å®˜æ–¹ä¹Ÿæä¾›å°æ‡‰ GCP æœå‹™ Operators çš„æ–‡ä»¶ èˆ‡ å®‰è£æ–¹å¼ã€‚å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥åƒè€ƒ Operators çš„ Source Code ä¾†é‡æ–°ç·¨å¯«è‡ªå®šç¾©çš„ Operatorï¼›å¦‚ Figure 2 çš„ PubSubPullOperator ä¾¿èƒ½ç›´æ¥ä½¿ç”¨å®˜æ–¹æä¾›çš„ packages ï¼Œè€Œ TransformOperatorèˆ‡ BatchInsertOperator ä¹Ÿå¯ä»¥å°‹æ‰¾åˆ°å°æ‡‰ operator source code ä»¥é€²è¡Œåƒè€ƒèˆ‡æ”¹å¯«ï¼Œä»¥å¾Œæœ‰æ©Ÿæœƒçš„è©±åœ¨å¦å¤–æ’°å¯«æ–‡ç« è¨˜éŒ„ã€‚\nParallel Processing inÂ DAG åœ¨ Figure 2 ä¸­æ”¹ç‚ºä½¿ç”¨ pull message çš„æ–¹å¼ï¼Œå› æ­¤å¯ä»¥é€é PubSubPullOperator ä¾†è¨­ç½®æ¯æ¬¡æ‹‰å–è¨Šæ¯æ•¸é‡çš„ä¸Šé™ï¼›\nç„¶è€Œï¼Œè€ƒæ…®åˆ° Airflow schedule çš„æœ€å°é–“éš”å–®ä½ç‚º 1 åˆ†é˜ï¼Œä¸€æ—¦ publish message çš„æ•¸é‡èˆ‡æ—¥é½å¢ã€æˆ–æ˜¯å‡ºç¾ burst çš„æƒ…å½¢æ™‚ï¼Œåƒ…æ†‘ä¸€çµ„ PubSubPullOperator \u0026gt; TransformOperator \u0026gt; BatchInsertOperator çš„å·¥ä½œæµç¨‹è¨­ç½®å¯èƒ½ç„¡æ³•æ¶ˆåŒ–ï¼›å› æ­¤å°±éœ€è¦è€ƒé‡åœ¨ DAG ä¸­å»ºç«‹å¤šçµ„çš„å·¥ä½œæµç¨‹ï¼Œä»¥é€²è¡Œå¹³è¡Œè™•ç†ã€‚\nFigure 3 æ˜¯æˆ‘ç†è§£ Pub/Sub æ‹‰å–è¨Šæ¯çš„å·¥ä½œåŸç†(è‹¥æœ‰éŒ¯èª¤ä¹Ÿç…©è«‹æŒ‡æ­£ï¼Œæ„Ÿè¬)ï¼Œè¨Šæ¯çš„å‚³éæ­¥é©Ÿç•¥å¯ç°¡è¿°ç‚º:\nStep 1. Publish message to Topic\nStep 2. Message push into subscriber group queue by fanout mode\nStep 3. Single/Multi puller to pull message from a subscriber group queue\né€™æ¨£ä¸€æƒ³å°±æ¯”è¼ƒç°¡å–®äº†ï¼Œåªè¦åœ¨ DAG ä¸­å»ºç«‹å¤šçµ„çš„ PubSubPullOperator \u0026gt; TransformOperator \u0026gt; BatchInsertOperator å·¥ä½œæµç¨‹ï¼Œæ¯å€‹ PubSubPullOperator éƒ½æ‰®æ¼”è‘— Puller çš„è§’è‰²ã€‚\nå¦‚ Figure 4 å±•ç¤ºçš„å·¥ä½œæµç¨‹è¨­ç½®ï¼Œé€™æ¨£å°±èƒ½é”æˆå¹³è¡Œè™•ç†çš„æ§‹æƒ³å•¦! åŒæ™‚ï¼Œæˆ‘ä¹Ÿæ¡ç”¨äº† DummyOperator ä½œç‚ºæ•´å€‹ DAG çš„èµ·å§‹èˆ‡å®Œæˆï¼Œä¸»è¦æ˜¯å¸Œæœ›åœ¨ä½¿ç”¨ Airflow UI æ™‚èƒ½å¤ æ¯”è¼ƒå¥½çš„è¡¨é” DAG çš„å·¥ä½œç‹€æ…‹ã€‚\nPython example code for parallel processing in DAG PARALLEL: int = 5 start = DummyOperator(task_id=\u0026#39;start\u0026#39;) complete = DummyOperator(task_id=\u0026#39;complete\u0026#39;) for i in range(PARALLEL): pull_message = PubSubPullOperator(task_id=f\u0026#39;pull_message_{i}\u0026#39;) transform = TramsformOperator(task_id=f\u0026#39;transform_{i}\u0026#39;) insert_to_bq = BatchInsertOperator(task_id=f\u0026#39;insert_to_bq_{i}\u0026#39;) start \u0026gt;\u0026gt; pull_message \u0026gt;\u0026gt; transform \u0026gt;\u0026gt; insert_to_bq \u0026gt;\u0026gt; complete å¦å¤–ï¼Œåœ¨èƒ½ä¼°ç®—å‡ºå–®ä½æ™‚é–“ publish çš„ message æ•¸é‡ï¼Œä¾¿èƒ½ç°¡å–®åœ°å°‡ schedule é–“éš”æ™‚é–“ã€å–®æ¬¡æ‹‰å–è¨Šæ¯çš„æ•¸é‡ä¸Šé™ï¼Œä»¥åŠå·¥ä½œæµç¨‹çµ„æ•¸è¦–ç‚ºèª¿æ•´åƒæ•¸ï¼Œä»¥èª¿æ•´å·¥ä½œæµç¨‹çš„è™•ç†æ•ˆç‡ã€‚\n","permalink":"https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-airflow/","summary":"\u003cp\u003eæœ¬ç¯‡æ–‡ç« æ˜¯è¨˜éŒ„\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#a63a\"\u003eç”¨ \u003ccode\u003eAirflow DAG\u003c/code\u003e (Directed Acyclic Graph) æ›¿ä»£ \u003ccode\u003eCloud Function\u003c/code\u003e ç’°ç¯€ä»¥è™•ç†\u003ccode\u003eéœæ…‹è³‡æ–™æº\u003c/code\u003eçš„æ–¹æ³•\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#7077\"\u003e\u003ccode\u003eAirflow GCP Operators\u003c/code\u003e ä½¿ç”¨\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#0481\"\u003eåœ¨ \u003ccode\u003eDAG ä¸­å¹³è¡Œè™•ç†(parallel processing)\u003c/code\u003eçš„æ–¹å¼\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","title":"Migrate Google Cloud Functions to Airflow"},{"content":"æœ€è¿‘åˆ©ç”¨ GA4 ã€ UA ï¼Œä»¥åŠåœ˜éšŠçš„é–‹ç™¼ç”¢å“æ‰€è’é›†åˆ°çš„è³‡æ–™ï¼Œå”åŠ©åœ˜éšŠé€²ä¸€æ­¥äº†è§£ç”¢å“çš„æˆæ•ˆèˆ‡æˆæœ¬çš„åˆ©ç”¨æƒ…æ³ã€‚åœ˜éšŠçš„é–‹ç™¼èˆ‡ç”¢å“ç’°å¢ƒçš†å»ºç«‹åœ¨ Google Cloud Platform (GCP) ä¸Šï¼Œåœ¨åˆ†æ GCP billing report çš„åŸå§‹è³‡æ–™æ™‚ï¼Œä¹Ÿå¼•ç™¼äº†æˆ‘ \u0026ldquo;å°æ–¼åŒä»å€‘å°æ–¼å¦‚ä½•åˆ©ç”¨é–‹ç™¼ç’°å¢ƒ\u0026rdquo; æ„Ÿåˆ°å¥½å¥‡ï¼Œå¯«ä¸‹é€™ç¯‡æ–‡ç« ä½œç‚ºç´€éŒ„ã€‚\nåœ¨ç”¢å“çš„é–‹ç™¼ä¸­ï¼Œåœ˜éšŠæ¶ˆè€—æˆæœ¬æœ€é«˜çš„å‰å¹¾é …æ’åæ—¢åœ¨æ„æ–™ä¹‹ä¸­ï¼ŒGoogle Compute Engine (GCE)ã€ Cloud Functions ã€ BigQuery ä»¥åŠ Google Cloud Storageï¼Œä½†ç´°é …çš„éƒ¨åˆ†ä¹Ÿåœ¨æ„æ–™ä¹‹å¤–ã€‚\nGoogle Compute EngineÂ (GCE) åœ¨ GCP ä¸Šï¼Œç„¡è«–æˆ‘å€‘é–‹å•Ÿçš„æ˜¯ä¸€èˆ¬çš„ VM æ©Ÿå™¨ï¼Œåˆæˆ–è€…æ˜¯ Google Kubernetes Engine (GKE) çš„ Node ï¼Œ æœ¬èº«æ‰€ä½¿ç”¨çš„è³‡æºå–®ä½éƒ½å¯ä»¥ç¨±ç‚º Instance ï¼› æ›å¥è©±èªªï¼Œå¯ä»¥ç°¡å–®çš„å°‡ Instance ç†è§£ç‚ºèƒ½å¤ æä¾›çµ•å¤§éƒ¨åˆ† VM ç›¸é—œåŠŸèƒ½çš„è³‡æºï¼Œå¦‚Â : vCPUã€Memoryã€Diskã€Netwroking ä»¥åŠæ©Ÿå™¨å­¸ç¿’æœ€éœ€è¦çš„ GPU (TPU)ç­‰ç­‰ï¼Œå› æ­¤é€™ä¸€éƒ¨ä»½çš„è³‡æºç”¨é‡ä¹Ÿéƒ½æœƒè¢«æ­¸å› åˆ° GCE ä¸Šã€‚\nå°‡ billing report data ä¾æ“š SKU é€²è¡ŒåŠ ç¸½ä¸¦å‘½åç‚º ã€ŒCostã€æ¬„ä½ï¼Œå†å° ã€ŒCostã€æ¬„ä½åš kernel density estimation (kde) å¾Œå¯ä»¥å¾—åˆ° ã€ŒCostã€çš„ç¾¤èšå¯†åº¦ï¼ŒåŒæ™‚ä¹Ÿèƒ½ç²å–ä¸€çµ„è¼ƒç‚ºåˆç†çš„ä¸Šä¸‹é‚Šç•Œä»¥åˆ©å–å¾—é›¢ç¾¤å€¼ï¼Œã€ŒCostã€çš„é›¢ç¾¤å€¼å°æ–¼ billing report çš„æ„ç¾©å‰‡åœ¨æ–¼æ‰¾å‡ºç•°å¸¸çš„è²»ç”¨ï¼›ä»¥ ä¸‹å°‡å›ºå®šä½¿ç”¨ kde å–é›¢ç¾¤å€¼çš„ä½œæ³•ï¼Œå› æ­¤ä¸å†ä¸€ä¸€è´…è¿°ã€‚\nå¾é›¢ç¾¤å€¼å¾—çŸ¥ï¼ŒInstance Core ã€ Instance Ram ä»¥åŠ GPU çš„è²»ç”¨éƒ½æ˜¯æ¯”è¼ƒå¯è§€çš„\nInstance: ä¾æ“š Figure 1. GCE charged detail çµ¦å‡ºçš„è³‡è¨Šï¼ŒInstance åˆ†ç‚º Custom èˆ‡ N1-Predefined å…©ç¨®é¡åˆ¥ï¼Œé€™å…©ç¨®é¡åˆ¥åœ¨åœ˜éšŠä¸­åˆ†åˆ¥ä½œç‚º GKE Node èˆ‡ GCE instance ä¾†ä½¿ç”¨ã€‚ä¾æ“š Google åœ¨ GCE å®šåƒ¹çš„æ–‡ä»¶ä¸­å¯ä»¥å¾—çŸ¥ï¼Œ 1. Instance çš„ CPU èˆ‡ Memory æ˜¯åˆ†åˆ¥ä»¥ \u0026ldquo;running time\u0026rdquo; é€²è¡Œæ”¶è²»ï¼Œ 2. custom machine type æœƒæ¯” predefined machine type æ”¶å–æ›´å¤šè²»ç”¨ã€‚\nè§€å¯Ÿ Custom Instance Core ã€ N1 Predefined Instance Core ä»¥åŠ N1 Predefined Instance Ram çš„å †ç–Šåœ–ä¹Ÿå¯ä»¥ç™¼ç¾ï¼Œä¸‰è€…åœ¨ 8 æœˆè‡³ 11 æœˆçš„è²»ç”¨ä¸¦æ²’æœ‰å‡ºç¾ burst peak ï¼Œ åè€Œåœ¨è®ŠåŒ–ä¸Šå‘ˆç¾ç›¸å°å¹³æ»‘çš„ç‹€æ³ï¼›å°æ–¼é–‹ç™¼åœ˜éšŠä¾†èªªï¼Œé€™å…¶å¯¦ä¸æ˜¯ä¸€å€‹æ­£å¸¸çš„è¡¨ç¾: æœ‰é™çš„äººåŠ›ä¼´éš¨è‘—é–‹ç™¼è¿­ä»£é€±æœŸï¼Œæœƒå‡ºç¾å¤§é‡ä½¿ç”¨ CPU è¨ˆç®—ä»¥é©—è­‰ feature çš„é–‹ç™¼æƒ…æ³ï¼Œä¹Ÿæœƒé€²è¡Œä¼´éš¨è‘—å£“åŠ›æ¸¬è©¦å‡ºç¾å¤§é‡è¼‰å…¥è³‡æ–™è¿«ä½¿ Memory ä½¿ç”¨é‡å¢åŠ çš„æƒ…æ³ã€‚\nå› æ­¤ï¼Œæœ€å¯èƒ½çš„æƒ…æ³å…¶å¯¦æ˜¯: åœ˜éšŠä½¿ç”¨äº†è¶…ééœ€æ±‚é‡çš„è³‡æºã€‚å› ç‚ºä¾›éæ–¼æ±‚ï¼Œå°è‡´æ”¶è²»ä¸¦æ²’æœ‰ç™¼ç”Ÿè®ŠåŒ–ï¼Œå°¤å…¶æ˜¯ GKE Node æ‡‰è©²è¦æœ‰å»æ²’æœ‰å‘ˆç¾çš„ auto-scaling æ•ˆç›Šï¼Œæœ€çµ‚çš„çµè«–ä¾¿æ˜¯è³‡æºæº¢å‡ºé€ æˆçš„æµªè²»ï¼Œæˆ‘å€‘ä¹Ÿåœ¨ç™¼ç¾å¾Œçš„ç¬¬ä¸€æ™‚é–“å³æ™‚åšå‡ºèª¿æ•´èˆ‡æ”¹å–„ã€‚\nGPU: åœ˜éšŠæ‰€é–‹ç™¼çš„ç”¢å“ ADsvantage | AI æ™ºæ…§å¯«æ‰‹ æ˜¯ä¸€æ¬¾ AI æ™ºèƒ½å»£å‘Šå·¥å…·ï¼Œ24 å°æ™‚æ™ºèƒ½ç›£æ§ï¼Œè®“ä½ ä¸å¿…éš¨æ™‚åœ¨ç·šï¼ŒAI å¹«ä½ é¡§å»£å‘Šï¼Œ å› æ­¤éœ€è¦ GPU ä¾†è¨“ç·´ model ä»¥åŠæ‡‰ç”¨ä¹Ÿæ˜¯å¾ˆåˆç†çš„äº‹æƒ… (é˜²ä¸å‹é˜²ï¼Œè‡ªå·±çš„æ¥­é…è‡ªå·±å¯«XD)\nCloud Functions å’Œ GCE Instance æ”¶è²»ç›¸åŒï¼Œ Cloud Functions ä¹Ÿæ˜¯ä»¥ CPU å’Œ Memory çš„ \u0026ldquo;running time\u0026rdquo; åˆ†åˆ¥é€²è¡Œæ”¶è²»ï¼›å·®åˆ¥åœ¨æ–¼ GCE æ”¶è²»æ˜¯ä»¥ Hour ä½œå–®ä½ï¼Œè€Œ Cloud Functions å‰‡æ˜¯ä»¥ 100 æ¯«ç§’(ms) ä½œç‚ºè¨ˆè²»å–®ä½ï¼›å³ä½¿ Cloud Function èª¿ç”¨ (Invocations) æ¬¡æ•¸é”åˆ°åƒè¬æ¬¡ï¼Œå°æ–¼èª¿ç”¨çš„æ”¶è²»ä¹Ÿé é å°æ–¼ CPU å’Œ Memoryã€‚\né€™é‚Šä¹Ÿå¤šæä¸€å¥ï¼Œåƒè¬ä¸è¦æŠŠ Cloud Functions ç•¶ä½œ API ä¾†ä½¿ç”¨ï¼Œ Cloud Functions æœ‰å®ƒé©åˆçš„å ´æ™¯ï¼Œä½†é¡¯ç„¶ä¸æ˜¯\u0026quot;æ°¸ä¿åœ¨ç·š\u0026quot;çš„æœå‹™ã€‚\nBigQuery Long-Term Storage èˆ‡ Active Storage çš„è­˜åˆ¥æ¢ä»¶: è¶…é90å¤©æ²’æœ‰ modify / 90 å¤©å…§ä»æœ‰ modify çš„è³‡æ–™è¡¨ï¼› Analysis å‰‡æ˜¯ç›¸å°ç›´è¦ºçš„ Query è²»ç”¨ã€‚\nFigure 3. BigQuery charged detail å‘Šè¨´æˆ‘å€‘ï¼Œç›®å‰é–‹ç™¼ç’°å¢ƒä¸­çš„ BigQuery æœ‰å¤ªå¤š Long-Term çš„è³‡æ–™è¢«å„²å­˜è‘—ï¼Œé€™éƒ¨åˆ†æœ‰å±¬æ–¼ machine learning çš„ train data set ï¼Œç•¶ç„¶ä¹Ÿæœ‰å¤ªä¹…æ²’æœ‰ä½¿ç”¨éçš„è³‡æ–™ï¼›åŒæ™‚è³‡æ–™çš„å¤šå¯¡ä¹Ÿå½±éŸ¿äº† Analysis æ¯æ¬¡çš„æ”¶è²»ï¼Œå› æ­¤æˆ‘å€‘å°è³‡æ–™é›†é€²è¡Œäº†ä¸€æ¬¡è©•ä¼°èˆ‡å¯©æ ¸ï¼Œå‰”é™¤æ‰å·²ä¸å†éœ€è¦çš„è³‡æ–™ï¼Œä»¥æœŸç¯€çœè²»ç”¨ã€‚\nGoogle Cloud StorageÂ (GCS) GCS æä¾›äº†å¯å° å„²å­˜æ¡¶(bucket) å…§çš„æª”æ¡ˆ (objects) å¯¦æ–½ ç”Ÿå‘½é€±æœŸ(life-cycle)ç®¡ç†çš„åŠŸèƒ½: é€éè¦å‰‡çš„è¨­å®šï¼Œå¯ä»¥å°‡ç¬¦åˆè¦å‰‡å¤©æ•¸çš„ objects å¾ standard (nearline / coldline) ç­‰ç´šè®Šæ›´ç‚º nearlineã€coldline ä»¥åŠ archive ç­‰ç´šï¼Œå„ç­‰ç´šæœ‰ä¸åŒçš„æ”¶è²»æ¨™æº–ã€‚å¦‚: archive å„²å­˜çš„è²»ç”¨ç›¸å°æœ€ä½ï¼Œä½† access çš„è²»ç”¨æœ€é«˜ï¼Œ standard çš„å„²å­˜æ”¶è²»ç›¸å°æœ€é«˜ï¼Œä½†ä¸æ”¶å– access çš„è²»ç”¨ (å¦‚æœæœ‰ç”¢ç”Ÿ traffic å‰‡æœ‰å¯èƒ½æœƒé€²è¡Œ bandwidth çš„æ”¶è²»)ã€‚\nåœ¨éå¾€çš„ç¶“æ­·ä¸­ï¼Œå³ä½¿è³‡æ–™å·²ç¶“æ²’æœ‰è¢«ä½¿ç”¨åˆ°äº†ä»ç„¶æœƒ\u0026quot;ç¿’æ…£æ€§\u0026quot;çš„å°‡å…¶é€²è¡Œå°å­˜ï¼Œä»¥å¾…æŸå¤©æœƒå†åº¦ä½¿ç”¨ã€‚ç„¶è€Œå¤šçš„æ˜¯ï¼Œæˆ‘ä¸çŸ¥é“çš„ archive ä¸€ç›´åœ¨è¢« access çš„äº‹\u0026hellip;\næƒ³ç•¶ç„¶æ˜¯é¦¬ä¸Šå° objects é€²è¡Œç›¤é»ï¼Œä¸¦åŠ å…¥åˆ°è³‡æ–™å¯©æ ¸èˆ‡å‰ƒé™¤çš„æµç¨‹ä¸­å•¦!!\nSummary ç¶“éé€™æ¬¡çš„åˆ†æï¼Œä¹Ÿç¢ºå¯¦æ‰¾å‡ºå¾ˆå¤šä»¥å¾€åœ¨é–‹ç™¼ä¸­ç¸½ä¸ç¶“æ„å¿½ç•¥çš„å°äº‹ï¼Œç„¶è€Œæ­£æ˜¯é€™äº›æœ€é‡è¦çš„å°äº‹ï¼Œåœ¨æ”¶è²»ä¸Šå»å¾€å¾€è®Šæˆäº†å¤§äº‹ã€‚\nèˆ‡ä¸€èµ·è¸©éé›·çš„åŒè¡Œå…±å‹‰ä¹‹ï¼Œä¹Ÿå¸Œæœ›é€™æ¬¡çš„åˆ†æèƒ½å¤ å°æ–¼æ—¥å¾Œä½¿ç”¨é›²ç«¯å¹³å°è³‡æºæ›´åŠ è­¦æ…ã€‚\n","permalink":"https://blog.zhengweiliu.com/posts/normal/gcp-billing-analytics/","summary":"åœ¨ç”¢å“çš„é–‹ç™¼ä¸­ï¼Œåœ˜éšŠæ¶ˆè€—æˆæœ¬æœ€é«˜çš„å‰å¹¾é …æ’åæ—¢åœ¨æ„æ–™ä¹‹ä¸­ï¼ŒGoogle Compute Engine (GCE)ã€ Cloud Functions ã€ BigQuery ä»¥åŠ Google Cloud Storageï¼Œä½†ç´°é …çš„éƒ¨åˆ†ä¹Ÿåœ¨æ„æ–™ä¹‹å¤–ã€‚","title":"GCP Billing Analysis"},{"content":"æ—¢ä¸Šæ¬¡ç™¼å¸ƒ [Google Certified èˆ‡ Cloud]å¾Œï¼Œå’Œ Ryan è¨è«–äººæµåµæ¸¬ç³»çµ±ä¸­çš„è³‡æ–™æµï¼Œä»¥åŠæ„Ÿæ¸¬è¨­å‚™æ˜¯å¦å­˜æ´»çš„è­°é¡Œï¼› Ryan çš„å·¥ä½œèƒŒæ™¯æ˜¯ Compute Vision ç›¸é—œï¼Œç›¸å°æ–¼ ETL è³‡æ–™è™•ç†æµç¨‹ä¸­å±¬æ–¼æä¾› E ( extract ) ç«¯æœå‹™çš„è§’è‰²ï¼Œä¹Ÿç‰¹åˆ¥é‡è¦– extract çš„åŠŸèƒ½æ˜¯å¦éƒ½èƒ½å¦‚æœŸç™¼æ®ä½œç”¨ã€‚ Google Certified èˆ‡ Cloud Date: 2021-09-22 \u0026nbsp; Categories: #Google Cloud Platform\u0026nbsp; #Certified\u0026nbsp; é€éå¹¾å€‹å•é¡Œçš„äº¤æµéç¨‹ï¼Œè¨˜éŒ„æˆ‘å°ä½¿ç”¨é›²ç«¯å¹³å°ä»¥åŠä¸Šé›²é€™ä»¶äº‹æƒ…çš„æƒ³æ³• æ‹¿èªè­‰å°å·¥ä½œå¯¦æˆ°çš„å¹«åŠ©ä»¥åŠå°è·æ¶¯çš„å¹«åŠ©ï¼Œé‚„æ˜¯èªªæœ‰ä½¿ç”¨ç¶“é©—å…¶å¯¦ä¸ä¸€å®šè¦æ‹¿èªè­‰ï¼Œä»¥å¯¦ç”¨æ€§ä¾†èªªæ˜¯ä¸æ˜¯ç†Ÿæ‚‰å…¶ä¸­å¹¾é …æœå‹™å°±è¶³å¤ äº†Â ? è€ƒå–èªè­‰åƒ…è­‰æ˜ä½ ç¢ºå¯¦ç†è§£å®˜æ–¹åœ¨é€™å¼µèªè­‰é ˜åŸŸä¸Šæ‰€æå‡ºçš„ Best Practiceï¼Œä¸¦ä¸”å…·å‚™å°‡å…¶è½‰æ›æ‡‰ç”¨åˆ°å¯¦å‹™ä¸Šçš„åŸºç¤èƒ½åŠ›, æ¨è–¦çš„å­¸ç¿’è·¯å¾‘å’Œå­¸ç¿’è³‡æº ï¼šæœƒå»ºè­°å…ˆå»æ‹¿åŠ©ç†èªè­‰ï¼Œé‚„æ˜¯å¯ä»¥ç›´è¡å°ˆå®¶èªè­‰Â ? ...... ETL | ELT æ˜¯æµç¨‹é‚„æ˜¯ç³»çµ±Â ?\nETL ( Extract-Transform-Load ) èˆ‡ ELT ( Extract-Load-Transform ) æ˜¯è³‡æ–™è™•ç†ä¸­å¸¸è¦‹çš„è™•ç†æµç¨‹ä»£åè©ï¼›å€‹äººèªç‚º ETL â‰  ELT ï¼Œ L | T çš„å…ˆå¾Œé †åºé™¤äº†å½±éŸ¿è™•ç†æµç¨‹çš„è…³æœ¬ä¹‹å¤–ï¼Œå…¶å¯¦ä¹Ÿéœ€è¦æ­é… scenario ä¾†ä¸€èµ·è¨è«–ï¼ŒåŒæ™‚ä¹Ÿå¯èƒ½éœ€è¦ä¾è³´æ‡‰ç”¨ç³»çµ±çš„å—çœ¾ç¾¤é«”ç‰¹å¾µï¼Œæ­å»ºå‡ºå°æ‡‰çš„è™•ç†æ¡†æ¶ï¼Œä»¥æœŸåœ¨åˆç†çš„æ•ˆèƒ½ä¸‹é”æˆæä¾›è³‡æ–™çš„ç›®çš„ã€‚\nåœ¨ä¸Šè¿°éç¨‹ä¸­å¯ä»¥çœ‹å‡ºï¼ŒETL | ELT æœƒä¾æ“šå¯¦éš›ç‹€æ³è€Œå°æ–¼æ¡†æ¶è¨­è¨ˆæœ‰æ‰€æ”¹è®Šï¼Œ ETL | ELT æ‡‰å±¬æ–¼æµç¨‹ï¼Œåœ¨å¯¦ä½œå®Œæˆå¾Œæ‰æœƒè®Šæˆå…·é«”çš„ç³»çµ±ï¼›è€Œæµç¨‹å‰‡å¯ä»¥è¢«ç¨ç«‹æå‡ºé€²è¡Œè¨è«–ã€‚\nExtract æ˜¯å¦æœ‰åœ¨å¥½å¥½é‹ä½œÂ ? è³‡æ–™éºå¤±æ˜¯å¦å¯ä»¥é¿å…Â ?\nåœ¨ Ryan æå‡ºçš„è­°é¡Œä¸­ï¼Œextract çš„æœå‹™ç”±å…·é«”çš„æ„Ÿæ‡‰åµæ¸¬è¨­å‚™ç”¢ç”Ÿ log è³‡æ–™ï¼Œä¸¦ä¸æ–·çš„å¾€å¾Œæ®µé€²è¡Œå‚³é€ï¼Œä»¥ä¾¿é€²è¡Œåˆ†ææˆ–å„²å­˜ï¼›ç•¶ extract device é›¢ç·šæˆ–è€…æ˜¯ç™¼ç”Ÿæ•…éšœï¼Œè‹¥æ²’æœ‰åœ¨ç¬¬ä¸€æ™‚é–“é€²è¡Œç¢ºèªèˆ‡é€šçŸ¥ç›¸é—œäººå“¡ï¼Œå¾€å¾€è¦ç­‰åˆ°é€²è¡Œè³‡æ–™çµ±è¨ˆæ™‚æ‰æœƒç™¼ç¾è³‡æ–™éºå¤±ã€‚\nç‚ºæ­¤ï¼Œä¸»å‹•é€²è¡Œ Check Sensor Is Alive çš„æ©Ÿåˆ¶çœ‹èµ·ä¾†ä¸å¯é¿å…ï¼Œæˆ–æ˜¯æœ‰å…¶ä»–çš„é€”å¾‘å¯ä»¥é”æˆç›¸åŒçš„ç›®çš„å‘¢Â ?\nExtract Device çš„è³‡è¨Šå±¬æ–¼å·²çŸ¥æˆ–è€…æœªçŸ¥Â ?\nå›åˆ°äººæµåµæ¸¬çš„å ´æ™¯ä¸­ï¼Œæˆ‘æœ¬èº«å°æ–¼é€™å€‹æ‡‰ç”¨å ´æ™¯è¼ƒç‚ºé™Œç”Ÿï¼Œå› æ­¤åƒè€ƒäº†ã€ŠåŸºæ–¼å½±åƒè™•ç†åŠæ·±åº¦å­¸ç¿’çš„å…©éšæ®µäººæµåµæ¸¬ç³»çµ±ã€‹[1]\nå‚³çµ±è¨ˆç®—äººæµçš„æ–¹æ³•å¯èƒ½æœƒåœ¨å…¥å£è™•åˆ©ç”¨è¨ˆæ•¸ å™¨æ‰‹å‹•è¨ˆç®—ï¼Œæˆ–è€…é€éé–˜é–€å¼æ©Ÿæ¢°è¨­å‚™é€ä¸€è¨ˆç®—ï¼Œå¸¸ è¦‹çš„æ–¹æ³•ç‚ºç´…å¤–ç·šæ„Ÿæ‡‰æˆ–æ—‹è½‰é–€è¨ˆæ•¸ï¼Œä½†æ˜¯å°æ–¼å…¬è»Š å€™è»Šäº­ç­‰é–‹æ”¾å¼ã€åŠé–‹æ”¾å¼çš„å ´åŸŸè€Œè¨€ï¼Œç¼ºå°‘å›ºå®šå…¥ å£ä¾†å”åŠ©é€ä¸€è¨ˆç®—ï¼Œå› æ­¤æœ¬ç ”ç©¶åˆ©ç”¨å½±åƒè™•ç†æ–¹æ³•é” åˆ°æ™ºæ…§ç›£æ§çš„ç›®çš„ã€‚\né€éå½±åƒè™•ç†æ–¹æ³•ï¼Œå° Camera è’é›†åˆ°çš„ç•«é¢ç‰¹å¾µæ“·å–ä¸¦å°‡ ROI ( Region of interest ) ä½œç‚ºæ©Ÿå™¨å­¸ç¿’çš„ input data ä¹‹ä¸€ï¼›å¾é€™æ®µæè¿°ä¸­å¯ä»¥åˆ†æå‡ºå…©å€‹å…ˆæ±ºæ¢ä»¶\n1\\. Camera ä½œç‚ºè’é›†å½±åƒçš„è¨­å‚™ï¼Œå°æ‡‰äº† extract device çš„è§’è‰²\n2\\. Camera çš„éƒ¨ç½²åœ°é»æ˜¯å·²çŸ¥æ¢ä»¶ï¼Œæ›å¥è©±èªª : extract device å·²ç´€éŒ„åœ¨æ¡ˆ\nå·²çŸ¥æ¢ä»¶çš„ extract device åœ¨è™•ç†ä¸Šæœƒç›¸å°ä¾¿åˆ©ï¼šç”±æ–¼å·²ç¶“ç¢ºèªè©² device æœ‰é€±æœŸæ€§æˆ–è€…éœ€è¦ä¸é–“æ–·çš„è’é›†è³‡æ–™ä¸¦å›å‚³ï¼Œé€éè¨­è¨ˆ Slots çš„æ–¹å¼ä¾†å®šæœŸæ”¶å–è³‡æ–™ï¼Œä¸¦çµ¦äºˆä¸€äº›å®¹è¨±å€¼ï¼›å°æ–¼è¶…å‡ºå®¹è¨±å€¼çš„ device æˆ–è¨±å°±èƒ½å¤ å…ˆé€²è¡Œ Is Alive çš„åˆ¤æ–·æ©Ÿåˆ¶ï¼Œä¸¦ç›¡æ—©çš„é€šçŸ¥ç›¸é—œäººå“¡æˆ–é€²è¡Œå°æ‡‰çš„è™•ç†ã€‚\nç‚ºä»€éº¼éœ€è¦å®¹è¨±å€¼Â ?\nç‚ºäº†æ–¹ä¾¿è¨­è¨ˆ ETL | ELT ï¼Œåœ¨è¨­è¨ˆçš„æœ€åˆé€šå¸¸æœƒå‡è¨­ extract device è’é›†ä¸¦æä¾›çš„è³‡æ–™é‡æ˜¯ 100% ï¼Œå³æ²’æœ‰ä»»ä½•è³‡æ–™éºå¤±ã€‚ç„¶è€Œ 100% çš„è³‡æ–™å‚³éè¡¨ç¤ºå¯¦ä½œå¥½çš„ç³»çµ±ä¸­ï¼Œå„å€‹ç’°ç¯€éƒ½ä¸æœƒæœ‰ä»»ä½•æ„å¤–ç‹€æ³ç™¼ç”Ÿï¼Œå¦‚ï¼šextract device æ°¸é ä¸æ•…éšœæˆ–è€…ä¸éœ€è¦æ±°èˆŠæ›æ–°ã€åµæ¸¬å€åŸŸçš„åœ°é»æ°¸é ä¸æœƒæœ‰æ–½å·¥èˆ‡ç’°å¢ƒç‰©è®Šæ›´ã€æ°¸é éƒ½æœ‰äººæµç¶“é ROIæˆ–æ˜¯ ROI æ°¸é ä¸è®Šæ›´\u0026hellip;ç­‰ï¼Œå¾€å¾€åœ¨å¯¦éš›æ“ä½œçš„ç¶“é©—ä¸Šï¼Œéƒ½æœƒé¢è‡¨å› å„ç¨®èª¿æ•´äº‹ä»¶è€Œé€ æˆçš„ incident ã€‚\nå› æ­¤ï¼Œé€éè¨è«–é”æˆå…±è­˜ä¸¦çµ¦å®šä¸€å€‹å®¹è¨±å€¼ï¼Œå¯ä»¥è®“æ•´å€‹ç³»çµ±åœ¨é”æˆåŸå…ˆè¨­ç«‹ç›®çš„çš„åŒæ™‚å…·å‚™ä¸€äº›å½ˆæ€§ï¼Œä¸¦å¯ä»¥åœ¨å¾ŒçºŒçš„è™•ç† ( Process ) ä¸Šè€ƒæ…®åŠ å…¥å®¹è¨±å€¼æ¢ä»¶ä»¥é€²è¡Œèª¿æ•´ã€‚\nCloud IoT Core \u0026amp; Monitoring\nGCP ( Google Cloud Platform ) ä¸Šæä¾›äº† Cloud IoT Core çš„æœå‹™ï¼Œè®“ Device å¯ä»¥ç›´æ¥æˆ–è€…é–“æ¥å°‡è³‡æ–™å›å‚³è‡³ GCP resources ï¼Œä¸¦ä¸”ä¹Ÿæä¾›äº† monitoring çš„åŠŸèƒ½ä¾†æª¢è¦– resource ï¼ŒåŒ…å«å·²è¨˜éŒ„åœ¨æ¡ˆçš„ device ï¼Œ ä¸¦æä¾›è¦–è¦ºåŒ–çš„åœ–å½¢å ±è¡¨ä»¥æ–¹ä¾¿æª¢è¦–åŠŸèƒ½é‹ä½œçš„ç‹€æ³ï¼Œå¦‚ï¼šuptime checkã€‚\nAWS ã€Azure æˆ–æ˜¯å…¶ä»–é›²ç«¯å¹³å°å¯èƒ½ä¹Ÿæœ‰æä¾›ç›¸å°æ‡‰çš„åŠŸèƒ½çµ„åˆæˆ–è€…æœå‹™ï¼Œè‹¥æ²’æœ‰é ­ç·’çš„è©±å¯ä»¥åƒè€ƒ GCP çµ¦å‡ºçš„ç¯„ä¾‹ï¼Œä¸¦å˜—è©¦åœ¨ä¸åŒçš„é›²å¹³å°ä¸­è¨è«–åˆé©çš„è§£æ±ºæ–¹æ¡ˆèˆ‡æ¶æ§‹ã€‚\nReference [1] åŸºæ–¼å½±åƒè™•ç†åŠæ·±åº¦å­¸ç¿’çš„å…©éšæ®µäººæµåµæ¸¬ç³»çµ±, æ—æ³“é‚¦ 1 *ã€æ—ä»ä¿¡ 2 ã€å»–ä¼¯ç¿” 3, ä¸­è¯æ°‘åœ‹è‡ªå‹•æ©Ÿå·¥ç¨‹å­¸æœƒç¬¬äºŒåäº”å±†è»Šè¼›å·¥ç¨‹å­¸è¡“ç ”è¨æœƒè«–æ–‡é›†, ä¸­è¯æ°‘åœ‹ä¸€ç™¾é›¶ä¹å¹´åæœˆä¸‰åæ—¥\n","permalink":"https://blog.zhengweiliu.com/posts/normal/etl-elt-iot-device-alive-check/","summary":"åœ¨ç”¢å“çš„é–‹ç™¼ä¸­ï¼Œåœ˜éšŠæ¶ˆè€—æˆæœ¬æœ€é«˜çš„å‰å¹¾é …æ’åæ—¢åœ¨æ„æ–™ä¹‹ä¸­ï¼ŒGoogle Compute Engine (GCE)ã€ Cloud Functions ã€ BigQuery ä»¥åŠ Google Cloud Storageï¼Œä½†ç´°é …çš„éƒ¨åˆ†ä¹Ÿåœ¨æ„æ–™ä¹‹å¤–ã€‚","title":"ETL | ELT èˆ‡ IoT Device Alive Check"},{"content":"è½‰æ›åˆ°é›²ç«¯é ˜åŸŸå·¥ä½œä¹Ÿéäº†å¤§åŠå¹´ï¼Œé€™æ®µä¸ç®—é•·ä¸”é‚„åœ¨é€²è¡Œä¸­æ—…ç¨‹ä¸­ä¹Ÿç²å–äº†ä¸‰å¼µ Google Cloud Platform ( GCP ) çš„ CertifiedÂ : Associate Cloud Engineer | Professional Cloud Architect | Professional Cloud Network Engineer\næ¯æ¯åœ¨è€ƒå–èªè­‰çš„ç•¶ä¸‹ï¼Œä¹Ÿè©¦è‘—å°‡é€™ä»½å–œæ‚…åˆ†äº«çµ¦ç¤¾ç¾¤å¥½å‹ï¼Œä¹Ÿå› æ­¤æˆç‚ºäº†é–‹å•Ÿèˆ‡å¥½å‹äº¤æµé›²ç«¯ä½¿ç”¨ç¶“é©—çš„å¥‘æ©Ÿã€‚\næœ€è¿‘ï¼Œå’Œ Enzo èŠåˆ°åœ¨å·¥ä½œé ˜åŸŸæ·±è€•çš„è©±é¡Œã€‚Enzo å°è³‡æ–™ç§‘å­¸çš„é ˜åŸŸå…·æœ‰é«˜åº¦ç†±å¿±ï¼Œä¹Ÿå¸Œæœ›æœè‘— Senior Data Engineer çš„è§’è‰²ç™¼å±•ï¼›ç›®å‰å°æ–¼ Senior Data Engineer çš„å°ˆæ¥­éœ€æ±‚ä¸­ï¼Œç¶“å¸¸çœ‹åˆ°éœ€è¦å…·å‚™é›²ç«¯å¹³å°çš„æœå‹™æˆ–å·¥å…·ç­‰ä½¿ç”¨ç¶“é©—ï¼›Enzo é™¤äº†ä½¿ç”¨ä¸­çš„ Google Compute Engine ( GCE ) Virtual Machine æœå‹™ä¹‹å¤–ï¼Œä¹Ÿå¸Œæœ›é€²ä¸€æ­¥äº†è§£è‡ªå­¸ GCP çš„å¿…è¦æ€§èˆ‡å¯èƒ½æ€§ï¼ŒåŒæ™‚é€éè€ƒå–èªè­‰çš„æ–¹å¼ç¢ºèªè‡ªå·±å­¸ç¿’çš„æˆæœï¼Œä»¥åŠå¸Œæœ›å°‡å…¶ä½œç‚ºå°å¤–è­‰æ˜çš„ä¸€èˆ‰å…©å¾—å¥½æ–¹å¼ã€‚\nå’Œ Enzo äº¤æµè¨è«–çš„éç¨‹ä¸­ï¼Œæˆ‘ä¹Ÿå¾ä¸­ç™¼ç¾ä¸€äº›å€¼å¾—ç´€éŒ„çš„è§€é»ã€‚ç„¡è«–æœªä¾†çš„æˆ‘å°é€™å€‹è§€é»æ˜¯æŠ±æŒè‘—è´ŠåŒçš„æ…‹åº¦ï¼Œä¹Ÿæˆ–è€…å¤§ç›¸å¾‘åº­ï¼Œéƒ½æ˜¯ä¸€ç¨®å€¼å¾—å›å‘³çš„æ€è€ƒã€‚\nä»¥ä¸‹é€éå¹¾å€‹å•é¡Œçš„äº¤æµéç¨‹ï¼Œè¨˜éŒ„æˆ‘å°ä½¿ç”¨é›²ç«¯å¹³å°ä»¥åŠä¸Šé›²é€™ä»¶äº‹æƒ…çš„æƒ³æ³•\næ‹¿èªè­‰å°å·¥ä½œå¯¦æˆ°çš„å¹«åŠ©ä»¥åŠå°è·æ¶¯çš„å¹«åŠ©ï¼Œé‚„æ˜¯èªªæœ‰ä½¿ç”¨ç¶“é©—å…¶å¯¦ä¸ä¸€å®šè¦æ‹¿èªè­‰ï¼Œä»¥å¯¦ç”¨æ€§ä¾†èªªæ˜¯ä¸æ˜¯ç†Ÿæ‚‰å…¶ä¸­å¹¾é …æœå‹™å°±è¶³å¤ äº†Â ?\nç•¶åˆè€ƒæ…®è½‰æ›å·¥ä½œé ˜åŸŸæ™‚ï¼Œæˆ‘ä¹Ÿæ›¾æ€è€ƒéé€™å€‹å•é¡Œï¼›å†é™¸çºŒè€ƒå–èªè­‰çš„éç¨‹ä¸­ï¼Œä¹Ÿæ‰¾åˆ°äº†ä¸€å€‹è‡ªå·±èªç‚ºåˆé©çš„ç­”æ¡ˆã€‚\nè€ƒå–èªè­‰åƒ…è­‰æ˜ä½ ç¢ºå¯¦ç†è§£å®˜æ–¹åœ¨é€™å¼µèªè­‰é ˜åŸŸä¸Šæ‰€æå‡ºçš„ Best Practiceï¼Œä¸¦ä¸”å…·å‚™å°‡å…¶è½‰æ›æ‡‰ç”¨åˆ°å¯¦å‹™ä¸Šçš„åŸºç¤èƒ½åŠ›\næ›å¥è©±èªªÂ : èªè­‰æ˜¯ä¸€å€‹æ•²é–€ç£šã€‚\nå°å¤–ä¾†èªªç¢ºå¯¦ä¹Ÿæ˜¯ä¸€å€‹ä¸éŒ¯çš„è­‰æ˜ï¼Œé¢å°éç›¸åŒå°ˆæ¥­é ˜åŸŸçš„äººè€Œè¨€ï¼Œé€™ä¹Ÿä»£è¡¨äº†å®˜æ–¹çš„èƒŒæ›¸ã€‚\næ¨è–¦çš„å­¸ç¿’è·¯å¾‘å’Œå­¸ç¿’è³‡æº ï¼šæœƒå»ºè­°å…ˆå»æ‹¿åŠ©ç†èªè­‰ï¼Œé‚„æ˜¯å¯ä»¥ç›´è¡å°ˆå®¶èªè­‰Â ?\nå› ç‚ºé•·æœŸä½¿ç”¨ GCE çš„ç¶“é©—ï¼Œä¿ƒä½¿ Enzo å¸Œæœ›å¾ GCP çš„èªè­‰ä½œç‚ºèµ·æ­¥ã€‚\nå°æ–¼å¸Œæœ›å­¸ç¿’ GCP çš„äººè€Œè¨€ï¼Œ Associate Cloud Engineer ( ACE ) ç¢ºå¯¦æ˜¯å¹«åŠ©å…¥é–€ Cloud çš„å¥½é€”å¾‘ï¼šç”±æ–¼ Cloud çš„è³‡æºçœ¾å¤šï¼Œè‹¥å¸Œæœ›åŸ·è¡Œæ¬é·ä¸Šé›²çš„è¨ˆç•«ï¼Œ ACE æœƒä»¥è¼ƒç‚ºå…·é«”çš„åŸ·è¡Œæ–¹æ¡ˆå¸¶ä½ é ˜ç•¥å„å€‹ GCP è³‡æºçš„ä½¿ç”¨è—åœ–ä»¥åŠé™åˆ¶ã€‚\nèˆ‰ Data ç›¸é—œçš„å·¥ä½œç‚ºä¾‹ï¼Œå€‹äººæ·ºè¦‹èªç‚ºä¸ç®¡å¾äº‹çš„å·¥ä½œå…§å®¹æ˜¯ è³‡æ–™ç§‘å­¸å®¶ | è³‡æ–™åˆ†æå¸« | è³‡æ–™å·¥ç¨‹å¸« ï¼Œéƒ½ç„¡å¯é¿å…çš„éœ€è¦æ˜ç¢ºçš„çŸ¥é“è³‡æ–™å¾å“ªè£¡ä¾†ã€è³‡æ–™æ ¼å¼é•·ç›¸å¦‚ä½•ï¼Œä»¥åŠè™•ç†éçš„è³‡æ–™æœ€çµ‚éœ€è¦å¾€å“ªé‚Šå»ã€‚\nå› æ­¤ï¼Œå¯ä»¥å¾—åˆ°ä¸€å€‹è¼ƒç‚ºç›´è¦ºçš„è«–é»\nè³‡æ–™æµ ( Dataflow ) èˆ‡ è³‡æ–™è™•ç† ( Process ) å¯ä»¥å–®ç¨å­˜åœ¨èˆ‡å–®ç¨è¨è«–\nåœ¨éå¾€çš„é–‹ç™¼å·¥ä½œé€²è¡Œæ™‚ï¼Œé€šå¸¸æ‰€ä½¿ç”¨çš„è¨­å‚™è³‡æºéƒ½æ˜¯å®Œæ•´å¯è¦‹çš„ç¡¬é«”è¨­æ–½ï¼Œè€Œæˆ‘å€‘åœ¨é€™äº›è¨­æ–½ä¸Šå®Œæˆç›¸é—œçš„é–‹ç™¼ä½œæ¥­ï¼›å¾Œä¾†ï¼Œç•¶ç™¼ç¾å„å®¶é›²å¹³å°éƒ½æœ‰æä¾› Virtual Machine çš„è³‡æºæ™‚ï¼Œæœ€ç›´è¦ºçš„ä¸Šé›²å°±æ˜¯å°‡å·¥ä½œæ¬å¾€é›²å¹³å°çš„ Virtual Machine ï¼Œè—‰æ­¤çœä¸‹çš„ç¡¬é«”è¨­æ–½çš„è²»ç”¨ã€‚\nè‡³æ­¤ï¼Œå¦‚æœä½ å•æˆ‘ä½¿ç”¨é›²å¹³å°çš„ Virtual Machine ç®—ä¸ç®—ä¸Šé›²äº†ï¼Œæˆ‘çš„å›ç­”æ˜¯çœ‹ç‹€æ³\né›²ç«¯èˆ‡åœ°ç«¯çš„å€åˆ¥åœ¨å“ªè£¡Â ?\nè‹¥æˆ‘å€‘ä»¥æœ€å»£ç‚ºäººçŸ¥çš„å®šç¾©ä¾†è¨è«–é›²ç«¯èˆ‡åœ°ç«¯ï¼Œå‰‡åœ°ç«¯å±¬æ–¼å…¬å¸å…§éƒ¨è¨­å‚™ï¼Œä½¿ç”¨å…§éƒ¨ç¶²è·¯ä¾†éš”é›¢èˆ‡å¤–éƒ¨ç¶²è·¯çš„æ¥è§¸ï¼Œä¸¦é€éå±¤å±¤ä¿è­·è¨­æ–½ä¾†ä¿è­·å…§éƒ¨æœå‹™èˆ‡è³‡æ–™ä¸æœƒè¼•æ˜“çš„è¢«æœªæˆæ¬Šçš„ä½¿ç”¨è€…å­˜å–ï¼›\nè€Œé›²ç«¯å‰‡æ˜¯ä½¿ç”¨é›²å¹³å°æä¾›åŒç­‰ç¡¬é«”è¨­æ–½çš„è™›æ“¬è³‡æºï¼Œå¦‚ï¼š GCEã€GKEï¼Œæˆ–è€…æ˜¯é›²å¹³å°æä¾›çš„è™›æ“¬ç¶²è·¯å®šç¾©ï¼Œå¦‚ï¼šVPC ( Virtual Private Cloud ) ï¼ŒåŒæ™‚é›²å¹³å°ä¹Ÿæä¾›åº•å±¤çš„å°åŒ…åŠ è§£å¯†ã€å¯†é‘°ç®¡ç†ä»¥åŠ Security Command Center ç­‰ç­‰æœå‹™ã€‚\nåœ¨ä½¿ç”¨é›²å¹³å°çš„ç¶“é©—ä¸­ï¼Œå¯ä»¥çœä¸‹å¤§é‡éœ€è¦äººåŠ›é€²è¡Œåº•å±¤è¨­æ–½ ( Infrastructure ) æ›´æ›ä»¥åŠä½ˆç½²çš„æ™‚é–“ã€‚\nç„¶è€Œï¼Œå¦‚æœæˆ‘å€‘ç”¨é›²å¹³å°çš„è³‡æºï¼Œåšè‘—èˆ‡åœ°ç«¯æ™‚æœŸç›¸åŒçš„å·¥ä½œï¼ŒçœŸçš„å°±æ˜¯ä¸Šé›²äº†å—Â ?\nç¡¬é«”ä¸Šé›²èˆ‡æœå‹™ä¸Šé›²\nåœ¨æ™ºæ…§æ‰‹æ©Ÿä¸å¦‚ç¾åœ¨åŠŸèƒ½å¼·å¤§çš„åå¹¾å¹´å‰ï¼Œæˆ‘å€‘å¤§å¤šåœ¨å€‹äººé›»è…¦ä¸Šä½¿ç”¨ç¤¾ç¾¤åª’é«”ä¾†èˆ‡æœ‹å‹é€²è¡Œäº¤æµï¼›è€Œç¾åœ¨ï¼Œæˆ‘å€‘åˆ©ç”¨æ™ºæ…§æ‰‹æ©Ÿä¾†åˆ·ç¤¾ç¾¤åª’é«”çš„æ™‚é–“å¯èƒ½æ¯”ååœ¨é›»è…¦å‰çš„æ™‚é–“é‚„å¤šã€‚\nèª ç„¶ï¼Œæˆ‘å€‘å°‡åœ°ç«¯æ™‚æœŸçš„å·¥ä½œæ¬é·åˆ°é›²å¹³å°ä¸Šï¼Œå¯ä»¥ç¯€çœç¡¬é«”è¨­æ–½ç­‰ç›¸é—œè²»ç”¨ï¼Œä½†å·¥ä½œä¸Šçš„æ€è€ƒä»ç„¶åœç•™åœ¨åœ°ç«¯æ™‚æœŸï¼Œæˆ‘å€‘åªæ˜¯å°‡å·¥ä½œæ¬é·åˆ°å¦å¤–ä¸€å€‹ç’°å¢ƒä¸Šè€Œå·²ã€‚\nåŒæ¨£æ˜¯ä»¥ Dataflow èˆ‡ Process çš„è§’åº¦ä¾†çœ‹\nåœ°ç«¯æ™‚æœŸï¼Œè³‡æ–™æµä¸­çš„æ¯å€‹ç«¯é»ï¼Œå¦‚ï¼š NASã€SFTP æˆ–æ˜¯å…¶ä»–ä¼ºæœå™¨æœå‹™ï¼Œéƒ½æ˜¯æ˜ç¢ºçš„åŸ·è¡Œåœ¨å…·é«”ä¸€å°ä¼ºæœå™¨è¨­å‚™ï¼Œæˆ–æ˜¯ç‰¹å®šçš„å¢é›†ä¼ºæœå™¨æ©Ÿç¾¤ï¼›é€™æ¨£æ˜ç¢ºçš„è¨­å‚™ç«¯åˆ°è¨­å‚™ç«¯çš„è³‡æ–™æµå‘ä¹Ÿæ˜¯åœ°ç«¯æ™‚æœŸçš„æ˜é¡¯ç‰¹å¾µä¹‹ä¸€ã€‚\né›²å¹³å°æä¾›äº† Virtual Machine çš„è³‡æºï¼Œæä¾›äº†å¾åœ°ç«¯ä¸Šé›²çš„å¯èƒ½æ€§ï¼›ç„¶è€Œï¼Œæˆ‘å€‘æœƒç™¼ç¾åœ¨é€™å€‹æ¨¡å¼çš„é‹ä½œä¸‹ï¼Œ Dataflow èˆ‡ Process ä»ç„¶ä¾è³´è‘—è¨­å‚™ç«¯åˆ°è¨­å‚™ç«¯çš„æ¨¡å¼ã€‚\né‚„è¨˜å¾—å‰é¢æåˆ°çš„ è³‡æ–™æµ ( Dataflow ) èˆ‡ è³‡æ–™è™•ç† ( Process ) å¯ä»¥å–®ç¨å­˜åœ¨èˆ‡å–®ç¨è¨è«– å—Â ? é€™è¡¨ç¤ºå®ƒå€‘å…¶å¯¦ä¸¦ä¸éœ€è¦ä¾è³´ç‰¹å®šçš„è¨­å‚™ç«¯ï¼Œæ˜ç¢ºåœ°èªª\nä¸¦ä¸åƒ…åƒ…åªèƒ½åœ¨ Virtual MachineÂ ä¸Šå¯¦ç¾\nçœ¾å¤šæœå‹™ç‚ºä½•åªå– Virtual MachineÂ ?\né›²å¹³å°æä¾›äº†çœ¾å¤šçš„è³‡æºï¼Œå¹¾ä¹å¯ä»¥æ»¿è¶³çµ•å¤§éƒ¨åˆ†çš„è³‡æ–™æµè¨­è¨ˆèˆ‡è„«é›¢ Virtual Machine åŸ·è¡Œ Process çš„æ–¹å¼ï¼Œå³ serverlessï¼Œä»¥ä¸‹åˆ—èˆ‰å¹¾å€‹é›²å¹³å°ä¸­èˆ‡ Data ç›¸é—œçš„è³‡æº\nData Storage Google Cloud Storage æä¾› Bucket è³‡æºå¯ä»¥å„²å­˜å¤§é‡æ–‡ä»¶è³‡æ–™ Google Cloud Pub/Sub æä¾› MQTT æœå‹™ï¼Œä½œç‚ºè³‡æ–™æµæ¸ é“è§’è‰²ï¼ŒåŒæ™‚ä¹Ÿå…·å‚™å„²å­˜æ‰¹æ¬¡è³‡æ–™çš„èƒ½åŠ› Firebase æä¾›äº†æœ€é©åˆ Web èˆ‡ Mobile App éœ€è¦çš„å„²å­˜ç©ºé–“ Serverless Cloud Functions æä¾›äº† serverless çš„æœå‹™ï¼Œé©ç”¨æ–¼åŸ·è¡Œå¾®æœå‹™ functionã€ stateless function æˆ–æ˜¯å–®ç´”çš„ API endpoints Data Process Dataprep æä¾›äº†è¦–è¦ºåŒ–èˆ‡ç°¡æ˜“ç·¨è¼¯çš„ Transform åŠŸèƒ½ï¼Œä¹Ÿå°±æ˜¯ ETL | ELT ä¸­ç¶“å¸¸è¢«æåˆ°çš„ â€œ T â€ Dataflow æä¾›äº†æ•´å€‹è³‡æ–™æµçš„ç·¨æ’åŠŸèƒ½ï¼Œå¯ä»¥é€éè¦–è¦ºåŒ–å·¥å…·ä¾†ç·¨æ’è³‡æ–™æµçš„ä¾†æºã€è™•ç†ä»¥åŠç›®çš„åœ°ï¼›åŒæ™‚ä¹Ÿæ”¯æ´å°‡é›²å¹³å°ä¸­èˆ‡è³‡æ–™ç›¸é—œçš„è³‡æºä½œç‚ºä¾†æºç«¯æˆ–ç›®çš„åœ°ç«¯ï¼Œä¹Ÿæ”¯æ´å¾å…¶ä»–é›²å¹³å°å¼•å…¥è³‡æ–™ é›²ç«¯ä¸€è§’\nè‡³æ­¤ä¾¿èƒ½ç¸½çµå‡ºå¹¾é …è¦é»ï¼Œç”¨ä»¥æè¿°æˆ‘å°é›²ç«¯çš„è§€é»\nå°‡ workload æŠ½é›¢å°æ–¼è³‡æºçš„ä¾è³´æ€§ï¼›workload æ‡‰å¯è¢«å–®ç¨è¨­è¨ˆèˆ‡è¨è«– é›²ç«¯è³‡æºçš„æä¾›è€…ä¸¦éåƒ…æœ‰ä¸€å®¶ã€‚é›²ç«¯èˆ‡åœ°ç«¯éƒ½èƒ½ä½œç‚ºè³‡æ–™æµä¾†æºï¼ŒåŒæ™‚ä¹Ÿèƒ½ä½œç‚ºè³‡æ–™æµå»è™• ç¯€çœç¡¬é«”èˆ‡åº•å±¤è³‡æºçš„ä½ˆå»ºä½ˆç½²ç­‰æˆæœ¬ è³‡æ–™çš„å°¾å·´\nç‚ºä»€éº¼é€šç¯‡éƒ½ä»¥è³‡æ–™æµä½œç‚ºèˆ‰ä¾‹ï¼Œä¸¦ä¸æ–·åœ°æèµ·å‘¢Â ?\nEvery company is a data company ä¸­çµ¦å‡ºäº†å¾ˆå¥½çš„è§£é‡‹ï¼Œæœ‰ç©ºçš„è©±å¯ä»¥çœ‹çœ‹\n","permalink":"https://blog.zhengweiliu.com/posts/normal/google-certified-cloud/","summary":"é€éå¹¾å€‹å•é¡Œçš„äº¤æµéç¨‹ï¼Œè¨˜éŒ„æˆ‘å°ä½¿ç”¨é›²ç«¯å¹³å°ä»¥åŠä¸Šé›²é€™ä»¶äº‹æƒ…çš„æƒ³æ³•\næ‹¿èªè­‰å°å·¥ä½œå¯¦æˆ°çš„å¹«åŠ©ä»¥åŠå°è·æ¶¯çš„å¹«åŠ©ï¼Œé‚„æ˜¯èªªæœ‰ä½¿ç”¨ç¶“é©—å…¶å¯¦ä¸ä¸€å®šè¦æ‹¿èªè­‰ï¼Œä»¥å¯¦ç”¨æ€§ä¾†èªªæ˜¯ä¸æ˜¯ç†Ÿæ‚‰å…¶ä¸­å¹¾é …æœå‹™å°±è¶³å¤ äº†Â ?\nè€ƒå–èªè­‰åƒ…è­‰æ˜ä½ ç¢ºå¯¦ç†è§£å®˜æ–¹åœ¨é€™å¼µèªè­‰é ˜åŸŸä¸Šæ‰€æå‡ºçš„ Best Practiceï¼Œä¸¦ä¸”å…·å‚™å°‡å…¶è½‰æ›æ‡‰ç”¨åˆ°å¯¦å‹™ä¸Šçš„åŸºç¤èƒ½åŠ›,\næ¨è–¦çš„å­¸ç¿’è·¯å¾‘å’Œå­¸ç¿’è³‡æº ï¼šæœƒå»ºè­°å…ˆå»æ‹¿åŠ©ç†èªè­‰ï¼Œé‚„æ˜¯å¯ä»¥ç›´è¡å°ˆå®¶èªè­‰Â ?","title":"Google Certified èˆ‡ Cloud"}]