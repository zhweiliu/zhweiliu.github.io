<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Google Cloud Platform on ZhengWei Liu&#39;s blogs</title>
    <link>https://blog.zhengweiliu.com/categories/google-cloud-platform/</link>
    <description>Recent content in Google Cloud Platform on ZhengWei Liu&#39;s blogs</description>
    <image>
      <url>https://blog.zhengweiliu.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://blog.zhengweiliu.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 23 Jan 2022 05:59:52 +0000</lastBuildDate><atom:link href="https://blog.zhengweiliu.com/categories/google-cloud-platform/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Migrate Google Cloud Functions to Kubernetes</title>
      <link>https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/</link>
      <pubDate>Sun, 23 Jan 2022 05:59:52 +0000</pubDate>
      
      <guid>https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-kubernetes/</guid>
      <description>在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。
在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求
靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄
用 Kubernetes Pod 替代 Cloud Function 環節以處理動態資料源的方法 Google Kubernetes Engine: Ingress &amp;amp; Service ASGI 與FastAPI Dockerize &amp;amp; Deployment 靜態資料源的處理方案 &amp;gt; Migrate Google Cloud Functions to Airflow
Design Change Figure 1 是一個常見的使用案例，我將 Cloud Function 的執行邏輯簡略為 4 個部份來進行描述，即: 等待 Request (Accept Request) 、 處理邏輯 (Process)、產出結果 (Result) ，以及回復 Ack (Response HTTP Status Code)</description>
    </item>
    
    <item>
      <title>Migrate Google Cloud Functions to Airflow</title>
      <link>https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-airflow/</link>
      <pubDate>Sat, 22 Jan 2022 05:10:20 +0000</pubDate>
      
      <guid>https://blog.zhengweiliu.com/posts/normal/migrate-google-cloud-functions-to-airflow/</guid>
      <description>在 GCP Billing Analytics 中提到過關於 Cloud Functions 的計費超乎預期，進一步分析開發的使用習慣後，也找出部分功能應該將其從 Cloud Functions 搬遷至基於 GCE instances 的服務上，以達到節費的期望。
在原先的設計中，我們將 Cloud Functions 作為 ETL data flow 的其中一個環節，透過 Pub/Sub trigger Cloud Functions 的方式使其運作；考慮到 Pub/Sub subscriber push/pull 的 Ack 等待時間有著最長 600 秒的限制，我將這部分需要搬遷的 Cloud Functions 大致分為兩種需求
靜態資料源: 在提取資料時，可預期資料是存在且可被存取的 動態資料源: 可能發生資料不存在，或者是無法存取的情況 本篇文章是記錄
用 Airflow DAG (Directed Acyclic Graph) 替代 Cloud Function 環節以處理靜態資料源的方法 Airflow GCP Operators 使用 在 DAG 中平行處理(parallel processing)的方式 動態資料源的處理方案 &amp;gt; Migrate Google Cloud Functions to Kubernetes
Design Change Figure 1 是一個經典的使用案例，透過 GCS notification 的機制，當 bucket 中有檔案 (Object) 異動時，將異動的資訊 publish 到指定的 Pub/Sub Topic。 部署 Cloud Function 可以指定--trigger-topic 接受 Topic 的觸發，使得 Cloud Function 可以接收異動檔案的資訊，如: bucket name、object path ， 進行轉置 (Transform) 處理後將結果存放到 Big Query 。</description>
    </item>
    
    <item>
      <title>GCP Billing Analysis</title>
      <link>https://blog.zhengweiliu.com/posts/normal/gcp-billing-analytics/</link>
      <pubDate>Mon, 27 Dec 2021 14:13:51 +0000</pubDate>
      
      <guid>https://blog.zhengweiliu.com/posts/normal/gcp-billing-analytics/</guid>
      <description>最近利用 GA4 、 UA ，以及團隊的開發產品所蒐集到的資料，協助團隊進一步了解產品的成效與成本的利用情況。團隊的開發與產品環境皆建立在 Google Cloud Platform (GCP) 上，在分析 GCP billing report 的原始資料時，也引發了我 &amp;ldquo;對於同仁們對於如何利用開發環境&amp;rdquo; 感到好奇，寫下這篇文章作為紀錄。
在產品的開發中，團隊消耗成本最高的前幾項排名既在意料之中，Google Compute Engine (GCE)、 Cloud Functions 、 BigQuery 以及 Google Cloud Storage，但細項的部分也在意料之外。
Google Compute Engine (GCE) 在 GCP 上，無論我們開啟的是一般的 VM 機器，又或者是 Google Kubernetes Engine (GKE) 的 Node ， 本身所使用的資源單位都可以稱為 Instance ； 換句話說，可以簡單的將 Instance 理解為能夠提供絕大部分 VM 相關功能的資源，如 : vCPU、Memory、Disk、Netwroking 以及機器學習最需要的 GPU (TPU)等等，因此這一部份的資源用量也都會被歸因到 GCE 上。
將 billing report data 依據 SKU 進行加總並命名為 「Cost」欄位，再對 「Cost」欄位做 kernel density estimation (kde) 後可以得到 「Cost」的群聚密度，同時也能獲取一組較為合理的上下邊界以利取得離群值，「Cost」的離群值對於 billing report 的意義則在於找出異常的費用；以 下將固定使用 kde 取離群值的作法，因此不再一一贅述。</description>
    </item>
    
    <item>
      <title>Google Certified 與 Cloud</title>
      <link>https://blog.zhengweiliu.com/posts/normal/google-certified-cloud/</link>
      <pubDate>Wed, 22 Sep 2021 14:14:13 +0000</pubDate>
      
      <guid>https://blog.zhengweiliu.com/posts/normal/google-certified-cloud/</guid>
      <description>轉換到雲端領域工作也過了大半年，這段不算長且還在進行中旅程中也獲取了三張 Google Cloud Platform ( GCP ) 的 Certified : Associate Cloud Engineer | Professional Cloud Architect | Professional Cloud Network Engineer
每每在考取認證的當下，也試著將這份喜悅分享給社群好友，也因此成為了開啟與好友交流雲端使用經驗的契機。
最近，和 Enzo 聊到在工作領域深耕的話題。Enzo 對資料科學的領域具有高度熱忱，也希望朝著 Senior Data Engineer 的角色發展；目前對於 Senior Data Engineer 的專業需求中，經常看到需要具備雲端平台的服務或工具等使用經驗；Enzo 除了使用中的 Google Compute Engine ( GCE ) Virtual Machine 服務之外，也希望進一步了解自學 GCP 的必要性與可能性，同時透過考取認證的方式確認自己學習的成果，以及希望將其作為對外證明的一舉兩得好方式。
和 Enzo 交流討論的過程中，我也從中發現一些值得紀錄的觀點。無論未來的我對這個觀點是抱持著贊同的態度，也或者大相徑庭，都是一種值得回味的思考。
以下透過幾個問題的交流過程，記錄我對使用雲端平台以及上雲這件事情的想法
拿認證對工作實戰的幫助以及對職涯的幫助，還是說有使用經驗其實不一定要拿認證，以實用性來說是不是熟悉其中幾項服務就足夠了 ?
當初考慮轉換工作領域時，我也曾思考過這個問題；再陸續考取認證的過程中，也找到了一個自己認為合適的答案。
_考取認證僅證明你確實理解官方在這張認證領域上所提出的 Best Practice，並且具備將其轉換應用到實務上的基礎能力_
換句話說 : 認證是一個敲門磚。
對外來說確實也是一個不錯的證明，面對非相同專業領域的人而言，這也代表了官方的背書。
推薦的學習路徑和學習資源 ：會建議先去拿助理認證，還是可以直衝專家認證 ?
因為長期使用 GCE 的經驗，促使 Enzo 希望從 GCP 的認證作為起步。</description>
    </item>
    
  </channel>
</rss>
